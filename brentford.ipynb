{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "import dateutil\n",
    "from scipy.sparse import lil_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = [],[],[]\n",
    "\n",
    "# f = gzip.open(\"data/review-Hawaii_10.json.gz\", mode=\"rt\")\n",
    "\n",
    "# for l in f.read():\n",
    "#     d = eval(l)\n",
    "#     dataset.append(d)\n",
    "#     # if len(dataset) >= 20000:\n",
    "#     #     break\n",
    "        \n",
    "# f.close()\n",
    "with open(\"data/filter_all_t.json\") as f:\n",
    "    l = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'val', 'test'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87013, 10860, 11015)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for d in l[\"train\"]:\n",
    "    train_dataset.append(d)\n",
    "\n",
    "for d in l[\"val\"]:\n",
    "    val_dataset.append(d)\n",
    "\n",
    "for d in l[\"test\"]:\n",
    "    test_dataset.append(d)\n",
    "    \n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business_id': '60567465d335d0abfb415b26',\n",
       " 'user_id': '101074926318992653684',\n",
       " 'rating': 4,\n",
       " 'review_text': 'The tang of the tomato sauce is outstanding. And the crust is a meal, as it should be. Order a whole pie fresh.',\n",
       " 'pics': ['AF1QipM-2IRmvitARbcJr7deWfe5hyVBg_ArPMQSYvq0',\n",
       "  'AF1QipPWhe1OP80YPU40J6-XIdxbJIe57vKm8TTjve31',\n",
       "  'AF1QipNuKWM65S9ZFQykvdIhKUliE6K1VBxssTUYyl8d',\n",
       "  'AF1QipOJng1JS_1hmpfhAVrr7hE89dcoOtdy-Z6cOO9x'],\n",
       " 'history_reviews': [['101074926318992653684_6056272797d555cc6fb0d147',\n",
       "   'The pizza here is the real deal, perfect in every way except for the crust, which was more cracker crisp than chewy bread. Also recommend the meatball parmigiana hero, beefy, fluffy, overflowing, tangy, chunky tomato sauce, toothsome bread.'],\n",
       "  ['101074926318992653684_604a65c2c6dc737bce7e5a3d',\n",
       "   'Omg the tomato sauce is everything, in the meatball appetizer, pizza & as a dip for that scratch-made focaccia. Farm-fresh salad. A variety of artisan toppings. Ask for the chili oil! Goes great with the focaccia bread.'],\n",
       "  ['101074926318992653684_60433b8d8be5d4454df9cc51',\n",
       "   'First time around last year, we stuck to eggs and Benedict, which were okay not outstanding. Ours included bleskiver, a delightful Danish pancake donut, crepe, and potato pancake with German sausage. The bleskiver is fluffy yet yeasty but not too sweet.'],\n",
       "  ['101074926318992653684_6055ebe4f69c7b117806fdaa',\n",
       "   'Food was lukewarm, including fried calamari.'],\n",
       "  ['101074926318992653684_6056ff1b8cd0e3d69a522681',\n",
       "   \"My favorite is the zeppole. I'd come here just for pasta fagiole & donuts.\"],\n",
       "  ['101074926318992653684_6056ff89f69c7b117807028c',\n",
       "   \"My vegan Prosciutto-wrapped dates, with a smoked Gouda filling, on Shakshuka sauce was quite a mouthful, deeply flavored, interesting, and slightly on the sweet side. My husband's Parmesan-crusted cauliflower with the whole gravy mashed potato treatment also went over well; he hardly missed the meat. I can't recommend the mac 'n cheese, frites, humuus, biscotti w/French pressed , everything enough.\"],\n",
       "  ['101074926318992653684_6042e523aab4c25a4e74c19c',\n",
       "   'Love the pillowy buns, juicy, grass-fed beef, crispy crinkle fries and thick, old-fashioned chocolate milkshake. We like to watch the ball game at Safeco while eating burgers, fries, and shakes, too.'],\n",
       "  ['101074926318992653684_604f26dd9755094ba8abe0df',\n",
       "   'I could eat the curry of the Butter Chicken alone. And the garlic naan bread is luscious, better than most other Indian restaurants. I just wish they used chicken thighs for a softer tender texture.'],\n",
       "  ['101074926318992653684_60496c68aaa2b0649c59bff5',\n",
       "   'Sushi & ramen are great -- if you can handle the bad service.'],\n",
       "  ['101074926318992653684_60528531d8c08f462b93e958',\n",
       "   \"He's the frontman who charmed us into trying our first legit Little Italy meal featuring something other than pizza. I might add more zing to some dishes, like the Caesar & the tomato sauce. Try the osso bucco & other, non-tomato-based pastas next time.\"],\n",
       "  ['101074926318992653684_604f27ab8ba95eba01a00b9c',\n",
       "   \"Pizza is great. Doughy bread. Meatballs needed more tomato sauce, less melted cheese (but the fluffy garlic bread is addictive). The homemade S'mores made up for the disappointment; they are insane with dark chocolate.\"]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29596, 27896, 87013)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = {}\n",
    "business = {}\n",
    "interactions = []\n",
    "\n",
    "for d in train_dataset:\n",
    "    if d[\"user_id\"] not in users.keys(): users[d[\"user_id\"]] = len(users)\n",
    "    if d[\"business_id\"] not in business.keys(): business[d[\"business_id\"]] = len(business)\n",
    "    interactions.append((d[\"user_id\"], d[\"business_id\"], d[\"rating\"]))\n",
    "    \n",
    "len(users), len(business), len(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(interactions)\n",
    "mean_rating = sum([r for _,_,r in interactions])/len(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brentford(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, user_size,item_size):\n",
    "        self.K = K\n",
    "        self.beta_user = torch.from_numpy(np.random.normal(size=user_size)).type(dtype= torch.float32)\n",
    "        self.beta_item = torch.from_numpy(np.random.normal(size=item_size)).type(dtype= torch.float32)\n",
    "        self.gamma_user = torch.from_numpy(np.random.normal(size=(user_size,K))).type(dtype= torch.float32)\n",
    "        self.gamma_item = torch.from_numpy(np.random.normal(size=(item_size,K))).type(dtype= torch.float32)\n",
    "        self.alpha = torch.tensor([0.0]).type(dtype= torch.float32) ## zero initialization of alpha\n",
    "        \n",
    "        \n",
    "        self.beta_user.requires_grad = True\n",
    "        self.beta_item.requires_grad = True\n",
    "        self.gamma_user.requires_grad = True\n",
    "        self.gamma_item.requires_grad = True\n",
    "        self.alpha.requires_grad = True\n",
    "    \n",
    "    def forward(self,bu,bi,gu,gi):\n",
    "        \n",
    "        return self.alpha + bu + bi+ torch.dot(gu, gi)\n",
    "            \n",
    "            \n",
    "def train(model,lr,lam,train_set,users,items):\n",
    "    \n",
    "    device = None\n",
    "    # check availability of gpu\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    print (\"Running on: \", device)\n",
    "\n",
    "    optimizer = torch.optim.SGD([model.beta_user, model.beta_item, model.gamma_user, model.gamma_item], lr= lr)\n",
    "    ##criterion = nn.MSELoss()\n",
    "    #model = model.to(device)\n",
    "    #steps = len(train_set)\n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, steps)\n",
    "    losses = []\n",
    "    \n",
    "    ts = time.time() \n",
    "    loss_tot = []\n",
    "    for idx, (u,i,r) in enumerate(train_set):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        beta_u = model.beta_user[users[u]]\n",
    "        beta_i = model.beta_item[items[i]]\n",
    "        gamma_u = model.gamma_user[users[u],:]\n",
    "        gamma_i = model.gamma_item[items[i],:]\n",
    "        \n",
    "        # print(beta_u,beta_i,gamma_u,gamma_i)\n",
    "        y = torch.tensor([float(r)])\n",
    "        pred = model.forward(beta_u,beta_i,gamma_u,gamma_i)\n",
    "        #loss = (pred-y)**2+lam*(torch.sum(model.beta_user)+\\\n",
    "        #       torch.sum(model.beta_item)+ torch.sum(torch.norm(model.gamma_user))+torch.sum(torch.norm(model.gamma_item)))\n",
    "        \n",
    "        loss = (pred-y)**2+lam*(beta_u+\\\n",
    "                beta_i+ torch.norm(gamma_u)+torch.norm(gamma_i))\n",
    "        loss.backward()\n",
    "        # model.beta_user[users[u]] -= lr*beta_u.grad\n",
    "        # model.beta_item[items[i]] -= lr*beta_i.grad\n",
    "        # model.gamma_user[users[u],:] -= lr*gamma_u.grad\n",
    "        # model.gamma_item[items[i],:] -= lr*gamma_i.grad\n",
    "        \n",
    "        #print(model.beta_user[users[u]],model.beta_item[items[i]],model.gamma_user[users[u],:],model.gamma_item[items[i],:])\n",
    "        optimizer.step()\n",
    "        loss_tot.append(loss)\n",
    "        if idx % 100 == 0:\n",
    "                print(\"iter {}, loss: {}\".format(idx, loss.item()))\n",
    "                print(model.beta_user[users[u]],model.beta_item[items[i]],model.gamma_user[users[u],:],model.gamma_item[items[i],:])\n",
    "                losses.append(torch.mean(torch.tensor(loss_tot)).item())\n",
    "                loss_tot = []\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider Batching!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_lfm = Brentford(2,len(users),len(business))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on:  cpu\n",
      "iter 0, loss: 65.83424377441406\n",
      "tensor(-0.2299, grad_fn=<SelectBackward0>) tensor(0.4477, grad_fn=<SelectBackward0>) tensor([1.9484, 0.7123], grad_fn=<SliceBackward0>) tensor([-1.0386,  0.1406], grad_fn=<SliceBackward0>)\n",
      "iter 100, loss: 1.3383771181106567\n",
      "tensor(0.7365, grad_fn=<SelectBackward0>) tensor(-0.3620, grad_fn=<SelectBackward0>) tensor([-0.4551, -1.7026], grad_fn=<SliceBackward0>) tensor([-1.2833, -1.8289], grad_fn=<SliceBackward0>)\n",
      "iter 200, loss: 21.439716339111328\n",
      "tensor(-1.2848, grad_fn=<SelectBackward0>) tensor(1.5079, grad_fn=<SelectBackward0>) tensor([ 0.1648, -0.0701], grad_fn=<SliceBackward0>) tensor([-1.8843,  0.1374], grad_fn=<SliceBackward0>)\n",
      "iter 300, loss: 23.036314010620117\n",
      "tensor(1.0879, grad_fn=<SelectBackward0>) tensor(1.1516, grad_fn=<SelectBackward0>) tensor([-0.0206,  1.1056], grad_fn=<SliceBackward0>) tensor([-0.7050, -1.3363], grad_fn=<SliceBackward0>)\n",
      "iter 400, loss: 1.9282883405685425\n",
      "tensor(1.2375, grad_fn=<SelectBackward0>) tensor(0.6654, grad_fn=<SelectBackward0>) tensor([-0.8572, -0.0360], grad_fn=<SliceBackward0>) tensor([-0.9792, -1.8537], grad_fn=<SliceBackward0>)\n",
      "iter 500, loss: 20.252044677734375\n",
      "tensor(0.2943, grad_fn=<SelectBackward0>) tensor(0.4258, grad_fn=<SelectBackward0>) tensor([0.0371, 0.3442], grad_fn=<SliceBackward0>) tensor([ 0.1653, -0.0917], grad_fn=<SliceBackward0>)\n",
      "iter 600, loss: 1.9510643482208252\n",
      "tensor(0.7767, grad_fn=<SelectBackward0>) tensor(-0.0951, grad_fn=<SelectBackward0>) tensor([-2.7991,  0.0884], grad_fn=<SliceBackward0>) tensor([-1.1344,  0.7676], grad_fn=<SliceBackward0>)\n",
      "iter 700, loss: 5.687506198883057\n",
      "tensor(0.0360, grad_fn=<SelectBackward0>) tensor(0.9244, grad_fn=<SelectBackward0>) tensor([ 0.0837, -1.0082], grad_fn=<SliceBackward0>) tensor([ 1.7651, -1.9537], grad_fn=<SliceBackward0>)\n",
      "iter 800, loss: 8.312501907348633\n",
      "tensor(-0.5120, grad_fn=<SelectBackward0>) tensor(1.3200, grad_fn=<SelectBackward0>) tensor([ 0.6000, -0.5324], grad_fn=<SliceBackward0>) tensor([1.5545, 0.5937], grad_fn=<SliceBackward0>)\n",
      "iter 900, loss: 28.262052536010742\n",
      "tensor(-0.5763, grad_fn=<SelectBackward0>) tensor(1.1950, grad_fn=<SelectBackward0>) tensor([-0.8451,  0.1529], grad_fn=<SliceBackward0>) tensor([-0.3040, -2.2359], grad_fn=<SliceBackward0>)\n",
      "iter 1000, loss: 37.392333984375\n",
      "tensor(-2.2143, grad_fn=<SelectBackward0>) tensor(1.1352, grad_fn=<SelectBackward0>) tensor([ 2.0029, -0.1949], grad_fn=<SliceBackward0>) tensor([0.4792, 0.8294], grad_fn=<SliceBackward0>)\n",
      "iter 1100, loss: 29.826269149780273\n",
      "tensor(0.3696, grad_fn=<SelectBackward0>) tensor(-1.1934, grad_fn=<SelectBackward0>) tensor([-1.1606,  1.5278], grad_fn=<SliceBackward0>) tensor([-1.3547, -0.2674], grad_fn=<SliceBackward0>)\n",
      "iter 1200, loss: 44.23665237426758\n",
      "tensor(-1.4380, grad_fn=<SelectBackward0>) tensor(0.3830, grad_fn=<SelectBackward0>) tensor([-0.3176,  1.7898], grad_fn=<SliceBackward0>) tensor([0.5818, 0.1974], grad_fn=<SliceBackward0>)\n",
      "iter 1300, loss: 51.86146545410156\n",
      "tensor(0.1392, grad_fn=<SelectBackward0>) tensor(0.3599, grad_fn=<SelectBackward0>) tensor([-1.0150,  0.6807], grad_fn=<SliceBackward0>) tensor([ 1.6267, -0.0452], grad_fn=<SliceBackward0>)\n",
      "iter 1400, loss: 23.119773864746094\n",
      "tensor(-0.1413, grad_fn=<SelectBackward0>) tensor(-0.3738, grad_fn=<SelectBackward0>) tensor([ 0.9061, -0.6104], grad_fn=<SliceBackward0>) tensor([2.4138, 0.9219], grad_fn=<SliceBackward0>)\n",
      "iter 1500, loss: 25.198699951171875\n",
      "tensor(0.6630, grad_fn=<SelectBackward0>) tensor(-0.3393, grad_fn=<SelectBackward0>) tensor([ 0.0580, -0.2767], grad_fn=<SliceBackward0>) tensor([0.3826, 0.4320], grad_fn=<SliceBackward0>)\n",
      "iter 1600, loss: 7.773594379425049\n",
      "tensor(-0.5038, grad_fn=<SelectBackward0>) tensor(0.7431, grad_fn=<SelectBackward0>) tensor([-0.8170, -0.3178], grad_fn=<SliceBackward0>) tensor([0.9241, 0.1885], grad_fn=<SliceBackward0>)\n",
      "iter 1700, loss: 7.059256553649902\n",
      "tensor(1.2129, grad_fn=<SelectBackward0>) tensor(1.1827, grad_fn=<SelectBackward0>) tensor([ 1.8808, -0.3932], grad_fn=<SliceBackward0>) tensor([-0.3628,  0.1309], grad_fn=<SliceBackward0>)\n",
      "iter 1800, loss: 4.412759304046631\n",
      "tensor(0.3953, grad_fn=<SelectBackward0>) tensor(0.2449, grad_fn=<SelectBackward0>) tensor([-1.0015, -1.1417], grad_fn=<SliceBackward0>) tensor([-0.8903, -0.5134], grad_fn=<SliceBackward0>)\n",
      "iter 1900, loss: 3.706678867340088\n",
      "tensor(0.1166, grad_fn=<SelectBackward0>) tensor(0.6588, grad_fn=<SelectBackward0>) tensor([-0.8816, -2.0926], grad_fn=<SliceBackward0>) tensor([ 0.3486, -0.4266], grad_fn=<SliceBackward0>)\n",
      "iter 2000, loss: 34.52456283569336\n",
      "tensor(0.5428, grad_fn=<SelectBackward0>) tensor(-0.3542, grad_fn=<SelectBackward0>) tensor([ 0.3186, -1.9322], grad_fn=<SliceBackward0>) tensor([-0.7100,  0.0342], grad_fn=<SliceBackward0>)\n",
      "iter 2100, loss: 2.652176856994629\n",
      "tensor(0.9763, grad_fn=<SelectBackward0>) tensor(-0.4037, grad_fn=<SelectBackward0>) tensor([ 1.7657, -1.0312], grad_fn=<SliceBackward0>) tensor([1.5220, 0.5875], grad_fn=<SliceBackward0>)\n",
      "iter 2200, loss: 5.074891567230225\n",
      "tensor(2.0090, grad_fn=<SelectBackward0>) tensor(-0.2828, grad_fn=<SelectBackward0>) tensor([-0.6876, -1.5977], grad_fn=<SliceBackward0>) tensor([ 0.0757, -0.1884], grad_fn=<SliceBackward0>)\n",
      "iter 2300, loss: 14.396306037902832\n",
      "tensor(-0.6889, grad_fn=<SelectBackward0>) tensor(0.6260, grad_fn=<SelectBackward0>) tensor([-0.8890,  0.8835], grad_fn=<SliceBackward0>) tensor([0.4155, 1.1474], grad_fn=<SliceBackward0>)\n",
      "iter 2400, loss: 3.0159151554107666\n",
      "tensor(1.3578, grad_fn=<SelectBackward0>) tensor(0.0413, grad_fn=<SelectBackward0>) tensor([ 1.6623, -2.6925], grad_fn=<SliceBackward0>) tensor([-0.0758, -0.9023], grad_fn=<SliceBackward0>)\n",
      "iter 2500, loss: 10.072361946105957\n",
      "tensor(0.7598, grad_fn=<SelectBackward0>) tensor(0.3681, grad_fn=<SelectBackward0>) tensor([0.4870, 1.3411], grad_fn=<SliceBackward0>) tensor([ 0.7845, -0.2844], grad_fn=<SliceBackward0>)\n",
      "iter 2600, loss: 2.1855084896087646\n",
      "tensor(1.5534, grad_fn=<SelectBackward0>) tensor(0.7296, grad_fn=<SelectBackward0>) tensor([-0.3425,  1.7885], grad_fn=<SliceBackward0>) tensor([-0.2616,  0.7393], grad_fn=<SliceBackward0>)\n",
      "iter 2700, loss: 7.232421875\n",
      "tensor(1.0086, grad_fn=<SelectBackward0>) tensor(0.0648, grad_fn=<SelectBackward0>) tensor([0.8377, 0.8063], grad_fn=<SliceBackward0>) tensor([1.1565, 0.6605], grad_fn=<SliceBackward0>)\n",
      "iter 2800, loss: 21.701923370361328\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>) tensor(0.4169, grad_fn=<SelectBackward0>) tensor([-0.2338, -1.0511], grad_fn=<SliceBackward0>) tensor([ 0.6805, -0.4754], grad_fn=<SliceBackward0>)\n",
      "iter 2900, loss: 42.53872299194336\n",
      "tensor(-0.2686, grad_fn=<SelectBackward0>) tensor(-1.3316, grad_fn=<SelectBackward0>) tensor([-0.9361, -0.2111], grad_fn=<SliceBackward0>) tensor([-0.6394,  0.4033], grad_fn=<SliceBackward0>)\n",
      "iter 3000, loss: 16.991212844848633\n",
      "tensor(0.8106, grad_fn=<SelectBackward0>) tensor(-0.5623, grad_fn=<SelectBackward0>) tensor([-0.6996,  0.6654], grad_fn=<SliceBackward0>) tensor([-1.7332, -1.3989], grad_fn=<SliceBackward0>)\n",
      "iter 3100, loss: 17.18342399597168\n",
      "tensor(0.0833, grad_fn=<SelectBackward0>) tensor(-0.0022, grad_fn=<SelectBackward0>) tensor([-0.8090, -0.4504], grad_fn=<SliceBackward0>) tensor([-1.7989,  0.4087], grad_fn=<SliceBackward0>)\n",
      "iter 3200, loss: 13.686036109924316\n",
      "tensor(0.4237, grad_fn=<SelectBackward0>) tensor(0.2825, grad_fn=<SelectBackward0>) tensor([-0.0624, -0.5592], grad_fn=<SliceBackward0>) tensor([-0.1428,  0.4032], grad_fn=<SliceBackward0>)\n",
      "iter 3300, loss: 66.4745101928711\n",
      "tensor(-1.4917, grad_fn=<SelectBackward0>) tensor(-1.3629, grad_fn=<SelectBackward0>) tensor([-0.9677, -1.0346], grad_fn=<SliceBackward0>) tensor([ 0.8395, -0.3530], grad_fn=<SliceBackward0>)\n",
      "iter 3400, loss: 40.23489761352539\n",
      "tensor(-0.5487, grad_fn=<SelectBackward0>) tensor(0.1837, grad_fn=<SelectBackward0>) tensor([ 1.7484, -0.8926], grad_fn=<SliceBackward0>) tensor([-0.3188, -0.4305], grad_fn=<SliceBackward0>)\n",
      "iter 3500, loss: 3.6057844161987305\n",
      "tensor(-1.1297, grad_fn=<SelectBackward0>) tensor(1.7548, grad_fn=<SelectBackward0>) tensor([-0.4917, -1.8472], grad_fn=<SliceBackward0>) tensor([-0.2258, -1.4342], grad_fn=<SliceBackward0>)\n",
      "iter 3600, loss: 0.1971769779920578\n",
      "tensor(0.0631, grad_fn=<SelectBackward0>) tensor(1.1516, grad_fn=<SelectBackward0>) tensor([-1.0914,  1.5139], grad_fn=<SliceBackward0>) tensor([-0.3462,  0.0109], grad_fn=<SliceBackward0>)\n",
      "iter 3700, loss: 30.400253295898438\n",
      "tensor(-0.2736, grad_fn=<SelectBackward0>) tensor(-0.3433, grad_fn=<SelectBackward0>) tensor([ 0.1524, -0.4034], grad_fn=<SliceBackward0>) tensor([ 0.5534, -2.7694], grad_fn=<SliceBackward0>)\n",
      "iter 3800, loss: 12.122455596923828\n",
      "tensor(0.9800, grad_fn=<SelectBackward0>) tensor(1.4157, grad_fn=<SelectBackward0>) tensor([ 0.2176, -0.3701], grad_fn=<SliceBackward0>) tensor([-1.3518,  0.7006], grad_fn=<SliceBackward0>)\n",
      "iter 3900, loss: 34.1942138671875\n",
      "tensor(-1.3302, grad_fn=<SelectBackward0>) tensor(0.5884, grad_fn=<SelectBackward0>) tensor([0.8795, 1.0813], grad_fn=<SliceBackward0>) tensor([ 0.7586, -0.2290], grad_fn=<SliceBackward0>)\n",
      "iter 4000, loss: 27.182483673095703\n",
      "tensor(0.1409, grad_fn=<SelectBackward0>) tensor(0.8713, grad_fn=<SelectBackward0>) tensor([-0.0727, -0.2965], grad_fn=<SliceBackward0>) tensor([1.3179, 1.5376], grad_fn=<SliceBackward0>)\n",
      "iter 4100, loss: 0.2934693396091461\n",
      "tensor(-1.7952, grad_fn=<SelectBackward0>) tensor(-0.5040, grad_fn=<SelectBackward0>) tensor([ 0.5461, -2.3653], grad_fn=<SliceBackward0>) tensor([-0.7763, -2.6852], grad_fn=<SliceBackward0>)\n",
      "iter 4200, loss: 13.8540678024292\n",
      "tensor(-0.3315, grad_fn=<SelectBackward0>) tensor(0.7953, grad_fn=<SelectBackward0>) tensor([ 0.3282, -0.0037], grad_fn=<SliceBackward0>) tensor([0.2692, 1.2009], grad_fn=<SliceBackward0>)\n",
      "iter 4300, loss: 8.451682090759277\n",
      "tensor(-0.0998, grad_fn=<SelectBackward0>) tensor(0.7016, grad_fn=<SelectBackward0>) tensor([-0.4398,  0.7830], grad_fn=<SliceBackward0>) tensor([0.6723, 1.3800], grad_fn=<SliceBackward0>)\n",
      "iter 4400, loss: 2.6084368228912354\n",
      "tensor(0.8448, grad_fn=<SelectBackward0>) tensor(-0.2799, grad_fn=<SelectBackward0>) tensor([0.1511, 2.2797], grad_fn=<SliceBackward0>) tensor([-0.5925,  1.4081], grad_fn=<SliceBackward0>)\n",
      "iter 4500, loss: 2.6720352172851562\n",
      "tensor(-0.1285, grad_fn=<SelectBackward0>) tensor(1.5830, grad_fn=<SelectBackward0>) tensor([-0.3912,  0.7855], grad_fn=<SliceBackward0>) tensor([-0.8430, -0.3813], grad_fn=<SliceBackward0>)\n",
      "iter 4600, loss: 42.51472854614258\n",
      "tensor(0.7645, grad_fn=<SelectBackward0>) tensor(0.8148, grad_fn=<SelectBackward0>) tensor([-1.1622,  0.0344], grad_fn=<SliceBackward0>) tensor([1.6144, 1.7027], grad_fn=<SliceBackward0>)\n",
      "iter 4700, loss: 36.67378234863281\n",
      "tensor(-0.2606, grad_fn=<SelectBackward0>) tensor(-0.3184, grad_fn=<SelectBackward0>) tensor([-1.2045, -0.1130], grad_fn=<SliceBackward0>) tensor([ 0.0489, -0.0918], grad_fn=<SliceBackward0>)\n",
      "iter 4800, loss: 20.878978729248047\n",
      "tensor(-0.1539, grad_fn=<SelectBackward0>) tensor(1.1857, grad_fn=<SelectBackward0>) tensor([-1.1534,  0.0496], grad_fn=<SliceBackward0>) tensor([0.1578, 1.3722], grad_fn=<SliceBackward0>)\n",
      "iter 4900, loss: 1.4135851860046387\n",
      "tensor(0.0997, grad_fn=<SelectBackward0>) tensor(1.2569, grad_fn=<SelectBackward0>) tensor([ 0.5058, -2.1141], grad_fn=<SliceBackward0>) tensor([-0.0042, -0.7707], grad_fn=<SliceBackward0>)\n",
      "iter 5000, loss: 5.592844009399414\n",
      "tensor(-1.3438, grad_fn=<SelectBackward0>) tensor(-0.3818, grad_fn=<SelectBackward0>) tensor([ 1.4355, -1.7031], grad_fn=<SliceBackward0>) tensor([ 0.5343, -1.8002], grad_fn=<SliceBackward0>)\n",
      "iter 5100, loss: 6.795183181762695\n",
      "tensor(-0.6119, grad_fn=<SelectBackward0>) tensor(1.6756, grad_fn=<SelectBackward0>) tensor([-0.4347,  0.5980], grad_fn=<SliceBackward0>) tensor([-0.5673,  0.3970], grad_fn=<SliceBackward0>)\n",
      "iter 5200, loss: 32.77332305908203\n",
      "tensor(0.4616, grad_fn=<SelectBackward0>) tensor(-1.1164, grad_fn=<SelectBackward0>) tensor([0.0737, 0.5886], grad_fn=<SliceBackward0>) tensor([-1.2592,  0.9698], grad_fn=<SliceBackward0>)\n",
      "iter 5300, loss: 2.086500883102417\n",
      "tensor(-0.1048, grad_fn=<SelectBackward0>) tensor(2.6504, grad_fn=<SelectBackward0>) tensor([0.5109, 0.1181], grad_fn=<SliceBackward0>) tensor([ 2.7485, -0.7924], grad_fn=<SliceBackward0>)\n",
      "iter 5400, loss: 5.352628707885742\n",
      "tensor(0.5933, grad_fn=<SelectBackward0>) tensor(0.8487, grad_fn=<SelectBackward0>) tensor([-1.7822, -0.2938], grad_fn=<SliceBackward0>) tensor([-0.3853,  0.6022], grad_fn=<SliceBackward0>)\n",
      "iter 5500, loss: 48.818382263183594\n",
      "tensor(-1.5200, grad_fn=<SelectBackward0>) tensor(0.6776, grad_fn=<SelectBackward0>) tensor([ 0.3263, -1.0410], grad_fn=<SliceBackward0>) tensor([0.4694, 0.6836], grad_fn=<SliceBackward0>)\n",
      "iter 5600, loss: 16.688325881958008\n",
      "tensor(2.0199, grad_fn=<SelectBackward0>) tensor(-0.5186, grad_fn=<SelectBackward0>) tensor([-0.6315,  0.4306], grad_fn=<SliceBackward0>) tensor([1.0118, 1.0212], grad_fn=<SliceBackward0>)\n",
      "iter 5700, loss: 31.80946159362793\n",
      "tensor(-1.2769, grad_fn=<SelectBackward0>) tensor(0.6037, grad_fn=<SelectBackward0>) tensor([-0.4111, -3.5757], grad_fn=<SliceBackward0>) tensor([-0.6781, -0.4150], grad_fn=<SliceBackward0>)\n",
      "iter 5800, loss: 4.5224456787109375\n",
      "tensor(0.1036, grad_fn=<SelectBackward0>) tensor(1.9487, grad_fn=<SelectBackward0>) tensor([-0.4789, -0.4072], grad_fn=<SliceBackward0>) tensor([0.0972, 0.0707], grad_fn=<SliceBackward0>)\n",
      "iter 5900, loss: 0.5016657114028931\n",
      "tensor(0.9277, grad_fn=<SelectBackward0>) tensor(1.0323, grad_fn=<SelectBackward0>) tensor([-1.0115, -1.0887], grad_fn=<SliceBackward0>) tensor([-0.4628, -1.9813], grad_fn=<SliceBackward0>)\n",
      "iter 6000, loss: 15.350972175598145\n",
      "tensor(-0.0738, grad_fn=<SelectBackward0>) tensor(0.3886, grad_fn=<SelectBackward0>) tensor([0.2696, 0.7161], grad_fn=<SliceBackward0>) tensor([ 0.0034, -0.0416], grad_fn=<SliceBackward0>)\n",
      "iter 6100, loss: 4.522409439086914\n",
      "tensor(1.3755, grad_fn=<SelectBackward0>) tensor(0.5759, grad_fn=<SelectBackward0>) tensor([-0.0025,  0.4698], grad_fn=<SliceBackward0>) tensor([-0.4645,  0.0536], grad_fn=<SliceBackward0>)\n",
      "iter 6200, loss: 3.244044542312622\n",
      "tensor(0.5338, grad_fn=<SelectBackward0>) tensor(0.7804, grad_fn=<SelectBackward0>) tensor([0.6911, 2.6514], grad_fn=<SliceBackward0>) tensor([0.6777, 0.6731], grad_fn=<SliceBackward0>)\n",
      "iter 6300, loss: 72.23444366455078\n",
      "tensor(-0.3843, grad_fn=<SelectBackward0>) tensor(-0.4247, grad_fn=<SelectBackward0>) tensor([0.7216, 1.6276], grad_fn=<SliceBackward0>) tensor([-1.2835, -0.2585], grad_fn=<SliceBackward0>)\n",
      "iter 6400, loss: 31.8985538482666\n",
      "tensor(-1.1673, grad_fn=<SelectBackward0>) tensor(0.9558, grad_fn=<SelectBackward0>) tensor([-0.8884,  0.0026], grad_fn=<SliceBackward0>) tensor([-0.1169, -1.3820], grad_fn=<SliceBackward0>)\n",
      "iter 6500, loss: 35.67483901977539\n",
      "tensor(-0.7180, grad_fn=<SelectBackward0>) tensor(0.3173, grad_fn=<SelectBackward0>) tensor([-0.5693, -0.2646], grad_fn=<SliceBackward0>) tensor([0.3692, 0.1638], grad_fn=<SliceBackward0>)\n",
      "iter 6600, loss: 63.755401611328125\n",
      "tensor(-3.6780, grad_fn=<SelectBackward0>) tensor(0.4024, grad_fn=<SelectBackward0>) tensor([ 0.3294, -1.2020], grad_fn=<SliceBackward0>) tensor([-0.6729,  0.5825], grad_fn=<SliceBackward0>)\n",
      "iter 6700, loss: 29.402713775634766\n",
      "tensor(0.1308, grad_fn=<SelectBackward0>) tensor(-1.2940, grad_fn=<SelectBackward0>) tensor([-1.0864,  1.1847], grad_fn=<SliceBackward0>) tensor([-0.3457,  0.7602], grad_fn=<SliceBackward0>)\n",
      "iter 6800, loss: 12.835807800292969\n",
      "tensor(0.3509, grad_fn=<SelectBackward0>) tensor(0.1903, grad_fn=<SelectBackward0>) tensor([ 1.2947, -0.1912], grad_fn=<SliceBackward0>) tensor([0.2609, 0.7767], grad_fn=<SliceBackward0>)\n",
      "iter 6900, loss: 26.69816780090332\n",
      "tensor(0.1844, grad_fn=<SelectBackward0>) tensor(0.2204, grad_fn=<SelectBackward0>) tensor([-0.1666, -1.3277], grad_fn=<SliceBackward0>) tensor([0.2640, 1.3980], grad_fn=<SliceBackward0>)\n",
      "iter 7000, loss: 24.05983543395996\n",
      "tensor(-0.4133, grad_fn=<SelectBackward0>) tensor(-1.4418, grad_fn=<SelectBackward0>) tensor([-0.9351, -1.3643], grad_fn=<SliceBackward0>) tensor([-0.6499, -1.4595], grad_fn=<SliceBackward0>)\n",
      "iter 7100, loss: 38.363014221191406\n",
      "tensor(-0.0418, grad_fn=<SelectBackward0>) tensor(-0.7330, grad_fn=<SelectBackward0>) tensor([-0.9676, -0.9658], grad_fn=<SliceBackward0>) tensor([ 0.5962, -0.7874], grad_fn=<SliceBackward0>)\n",
      "iter 7200, loss: 9.080249786376953\n",
      "tensor(-0.0802, grad_fn=<SelectBackward0>) tensor(0.9987, grad_fn=<SelectBackward0>) tensor([-0.8150,  0.1352], grad_fn=<SliceBackward0>) tensor([-0.2761,  0.0570], grad_fn=<SliceBackward0>)\n",
      "iter 7300, loss: 9.264578819274902\n",
      "tensor(0.0424, grad_fn=<SelectBackward0>) tensor(1.5972, grad_fn=<SelectBackward0>) tensor([-0.4396, -0.4125], grad_fn=<SliceBackward0>) tensor([ 0.0120, -1.4113], grad_fn=<SliceBackward0>)\n",
      "iter 7400, loss: 50.98180389404297\n",
      "tensor(-0.4462, grad_fn=<SelectBackward0>) tensor(-1.1218, grad_fn=<SelectBackward0>) tensor([1.7841, 0.0483], grad_fn=<SliceBackward0>) tensor([ 0.1237, -0.4041], grad_fn=<SliceBackward0>)\n",
      "iter 7500, loss: 12.485888481140137\n",
      "tensor(0.6342, grad_fn=<SelectBackward0>) tensor(2.2788, grad_fn=<SelectBackward0>) tensor([-2.5437,  0.1978], grad_fn=<SliceBackward0>) tensor([0.3702, 0.9439], grad_fn=<SliceBackward0>)\n",
      "iter 7600, loss: 8.33526611328125\n",
      "tensor(-0.1325, grad_fn=<SelectBackward0>) tensor(1.8267, grad_fn=<SelectBackward0>) tensor([ 0.2238, -0.3668], grad_fn=<SliceBackward0>) tensor([ 1.6584, -1.0726], grad_fn=<SliceBackward0>)\n",
      "iter 7700, loss: 22.896709442138672\n",
      "tensor(1.2836, grad_fn=<SelectBackward0>) tensor(-0.3380, grad_fn=<SelectBackward0>) tensor([ 0.1402, -0.9369], grad_fn=<SliceBackward0>) tensor([-1.1701,  0.1528], grad_fn=<SliceBackward0>)\n",
      "iter 7800, loss: 42.86675262451172\n",
      "tensor(0.1660, grad_fn=<SelectBackward0>) tensor(0.8113, grad_fn=<SelectBackward0>) tensor([ 0.7391, -1.2649], grad_fn=<SliceBackward0>) tensor([-0.4207,  1.0945], grad_fn=<SliceBackward0>)\n",
      "iter 7900, loss: 38.61155700683594\n",
      "tensor(-0.7959, grad_fn=<SelectBackward0>) tensor(-1.3606, grad_fn=<SelectBackward0>) tensor([2.4921, 2.1576], grad_fn=<SliceBackward0>) tensor([ 1.4890, -0.4397], grad_fn=<SliceBackward0>)\n",
      "iter 8000, loss: 12.94344425201416\n",
      "tensor(-0.5979, grad_fn=<SelectBackward0>) tensor(0.8948, grad_fn=<SelectBackward0>) tensor([-0.1620,  0.8311], grad_fn=<SliceBackward0>) tensor([-1.7193,  0.2840], grad_fn=<SliceBackward0>)\n",
      "iter 8100, loss: 1.8747919797897339\n",
      "tensor(1.4522, grad_fn=<SelectBackward0>) tensor(2.6415, grad_fn=<SelectBackward0>) tensor([ 1.2706, -1.1015], grad_fn=<SliceBackward0>) tensor([-0.5602, -0.3597], grad_fn=<SliceBackward0>)\n",
      "iter 8200, loss: 32.38522720336914\n",
      "tensor(0.8190, grad_fn=<SelectBackward0>) tensor(0.2595, grad_fn=<SelectBackward0>) tensor([ 0.1080, -0.9624], grad_fn=<SliceBackward0>) tensor([0.3601, 1.2684], grad_fn=<SliceBackward0>)\n",
      "iter 8300, loss: 9.137307167053223\n",
      "tensor(0.8678, grad_fn=<SelectBackward0>) tensor(1.2215, grad_fn=<SelectBackward0>) tensor([-0.4654,  0.7431], grad_fn=<SliceBackward0>) tensor([1.1929, 1.0219], grad_fn=<SliceBackward0>)\n",
      "iter 8400, loss: 1.9248418807983398\n",
      "tensor(1.0944, grad_fn=<SelectBackward0>) tensor(1.7112, grad_fn=<SelectBackward0>) tensor([ 0.4168, -1.2541], grad_fn=<SliceBackward0>) tensor([-0.9161, -1.4157], grad_fn=<SliceBackward0>)\n",
      "iter 8500, loss: 14.882368087768555\n",
      "tensor(-0.7930, grad_fn=<SelectBackward0>) tensor(-0.1166, grad_fn=<SelectBackward0>) tensor([-0.4342,  1.3227], grad_fn=<SliceBackward0>) tensor([0.5248, 1.2935], grad_fn=<SliceBackward0>)\n",
      "iter 8600, loss: 1.3524812459945679\n",
      "tensor(0.6434, grad_fn=<SelectBackward0>) tensor(1.4818, grad_fn=<SelectBackward0>) tensor([-0.5731, -0.9089], grad_fn=<SliceBackward0>) tensor([-1.4271, -0.0167], grad_fn=<SliceBackward0>)\n",
      "iter 8700, loss: 18.434606552124023\n",
      "tensor(-2.3714, grad_fn=<SelectBackward0>) tensor(0.5766, grad_fn=<SelectBackward0>) tensor([-0.2821, -0.2014], grad_fn=<SliceBackward0>) tensor([0.8475, 0.0455], grad_fn=<SliceBackward0>)\n",
      "iter 8800, loss: 46.19263458251953\n",
      "tensor(-0.3461, grad_fn=<SelectBackward0>) tensor(-0.0508, grad_fn=<SelectBackward0>) tensor([-0.5192, -0.5894], grad_fn=<SliceBackward0>) tensor([1.1089, 0.3818], grad_fn=<SliceBackward0>)\n",
      "iter 8900, loss: 18.030540466308594\n",
      "tensor(-0.3158, grad_fn=<SelectBackward0>) tensor(0.3955, grad_fn=<SelectBackward0>) tensor([-0.8166,  0.4983], grad_fn=<SliceBackward0>) tensor([-0.8562,  0.5929], grad_fn=<SliceBackward0>)\n",
      "iter 9000, loss: 43.56646728515625\n",
      "tensor(-0.6647, grad_fn=<SelectBackward0>) tensor(-0.3354, grad_fn=<SelectBackward0>) tensor([-0.0751, -0.6484], grad_fn=<SliceBackward0>) tensor([-1.4983,  0.1280], grad_fn=<SliceBackward0>)\n",
      "iter 9100, loss: 2.238771438598633\n",
      "tensor(-0.3756, grad_fn=<SelectBackward0>) tensor(1.0628, grad_fn=<SelectBackward0>) tensor([ 2.2862, -0.6974], grad_fn=<SliceBackward0>) tensor([ 0.0492, -1.4260], grad_fn=<SliceBackward0>)\n",
      "iter 9200, loss: 22.107152938842773\n",
      "tensor(-1.0993, grad_fn=<SelectBackward0>) tensor(0.1001, grad_fn=<SelectBackward0>) tensor([0.7976, 2.2718], grad_fn=<SliceBackward0>) tensor([2.1049, 0.3217], grad_fn=<SliceBackward0>)\n",
      "iter 9300, loss: 15.479500770568848\n",
      "tensor(0.4087, grad_fn=<SelectBackward0>) tensor(-0.2438, grad_fn=<SelectBackward0>) tensor([-0.1625,  1.5486], grad_fn=<SliceBackward0>) tensor([-0.5947, -1.0925], grad_fn=<SliceBackward0>)\n",
      "iter 9400, loss: 13.932645797729492\n",
      "tensor(0.3314, grad_fn=<SelectBackward0>) tensor(1.0571, grad_fn=<SelectBackward0>) tensor([-0.4638,  0.8460], grad_fn=<SliceBackward0>) tensor([0.4313, 0.3802], grad_fn=<SliceBackward0>)\n",
      "iter 9500, loss: 11.569327354431152\n",
      "tensor(1.9782, grad_fn=<SelectBackward0>) tensor(0.4165, grad_fn=<SelectBackward0>) tensor([0.3937, 0.6433], grad_fn=<SliceBackward0>) tensor([-0.2510, -0.7342], grad_fn=<SliceBackward0>)\n",
      "iter 9600, loss: 31.3216552734375\n",
      "tensor(-2.0779, grad_fn=<SelectBackward0>) tensor(-1.1744, grad_fn=<SelectBackward0>) tensor([-1.4283, -1.0280], grad_fn=<SliceBackward0>) tensor([ 1.0361, -0.9317], grad_fn=<SliceBackward0>)\n",
      "iter 9700, loss: 6.21135139465332\n",
      "tensor(1.5167, grad_fn=<SelectBackward0>) tensor(-1.8088, grad_fn=<SelectBackward0>) tensor([-1.6806, -1.3825], grad_fn=<SliceBackward0>) tensor([-1.0109, -0.3466], grad_fn=<SliceBackward0>)\n",
      "iter 9800, loss: 16.302650451660156\n",
      "tensor(-0.6949, grad_fn=<SelectBackward0>) tensor(1.2053, grad_fn=<SelectBackward0>) tensor([-2.3730, -1.4321], grad_fn=<SliceBackward0>) tensor([-0.5189, -0.0059], grad_fn=<SliceBackward0>)\n",
      "iter 9900, loss: 5.221828460693359\n",
      "tensor(0.6780, grad_fn=<SelectBackward0>) tensor(0.6460, grad_fn=<SelectBackward0>) tensor([-0.8426,  0.2626], grad_fn=<SliceBackward0>) tensor([ 0.0330, -1.3830], grad_fn=<SliceBackward0>)\n",
      "iter 10000, loss: 21.64432716369629\n",
      "tensor(1.5541, grad_fn=<SelectBackward0>) tensor(-1.1115, grad_fn=<SelectBackward0>) tensor([0.7109, 0.8604], grad_fn=<SliceBackward0>) tensor([-0.8488,  1.1599], grad_fn=<SliceBackward0>)\n",
      "iter 10100, loss: 33.73056411743164\n",
      "tensor(0.1063, grad_fn=<SelectBackward0>) tensor(-0.3136, grad_fn=<SelectBackward0>) tensor([2.0885, 0.5320], grad_fn=<SliceBackward0>) tensor([ 0.1567, -1.5564], grad_fn=<SliceBackward0>)\n",
      "iter 10200, loss: 12.986841201782227\n",
      "tensor(0.3864, grad_fn=<SelectBackward0>) tensor(-0.7205, grad_fn=<SelectBackward0>) tensor([0.1420, 0.0271], grad_fn=<SliceBackward0>) tensor([-0.6515,  0.3375], grad_fn=<SliceBackward0>)\n",
      "iter 10300, loss: 0.4115256071090698\n",
      "tensor(-0.3427, grad_fn=<SelectBackward0>) tensor(1.4731, grad_fn=<SelectBackward0>) tensor([ 1.0448, -0.6355], grad_fn=<SliceBackward0>) tensor([ 0.2053, -0.0956], grad_fn=<SliceBackward0>)\n",
      "iter 10400, loss: 14.261616706848145\n",
      "tensor(0.0868, grad_fn=<SelectBackward0>) tensor(-0.5906, grad_fn=<SelectBackward0>) tensor([0.6311, 1.0375], grad_fn=<SliceBackward0>) tensor([2.1518, 0.9828], grad_fn=<SliceBackward0>)\n",
      "iter 10500, loss: 38.249942779541016\n",
      "tensor(0.1629, grad_fn=<SelectBackward0>) tensor(-0.5632, grad_fn=<SelectBackward0>) tensor([-0.9464, -0.1135], grad_fn=<SliceBackward0>) tensor([1.2054, 0.2680], grad_fn=<SliceBackward0>)\n",
      "iter 10600, loss: 18.271373748779297\n",
      "tensor(1.1717, grad_fn=<SelectBackward0>) tensor(-0.1467, grad_fn=<SelectBackward0>) tensor([-0.8659, -0.9898], grad_fn=<SliceBackward0>) tensor([-0.0661,  0.0359], grad_fn=<SliceBackward0>)\n",
      "iter 10700, loss: 10.13133716583252\n",
      "tensor(1.6180, grad_fn=<SelectBackward0>) tensor(0.7265, grad_fn=<SelectBackward0>) tensor([-0.7185, -0.2235], grad_fn=<SliceBackward0>) tensor([ 0.6713, -0.9223], grad_fn=<SliceBackward0>)\n",
      "iter 10800, loss: 1.6736676692962646\n",
      "tensor(0.1451, grad_fn=<SelectBackward0>) tensor(2.6274, grad_fn=<SelectBackward0>) tensor([ 0.0487, -0.5625], grad_fn=<SliceBackward0>) tensor([-0.0172,  0.0074], grad_fn=<SliceBackward0>)\n",
      "iter 10900, loss: 23.381078720092773\n",
      "tensor(0.8768, grad_fn=<SelectBackward0>) tensor(0.1698, grad_fn=<SelectBackward0>) tensor([ 0.6203, -0.3766], grad_fn=<SliceBackward0>) tensor([-0.9466, -0.1495], grad_fn=<SliceBackward0>)\n",
      "iter 11000, loss: 33.210784912109375\n",
      "tensor(-0.1498, grad_fn=<SelectBackward0>) tensor(-0.3785, grad_fn=<SelectBackward0>) tensor([-1.1571,  0.9115], grad_fn=<SliceBackward0>) tensor([-0.1250,  0.1114], grad_fn=<SliceBackward0>)\n",
      "iter 11100, loss: 33.2478141784668\n",
      "tensor(-0.6824, grad_fn=<SelectBackward0>) tensor(-0.1417, grad_fn=<SelectBackward0>) tensor([0.3225, 0.3925], grad_fn=<SliceBackward0>) tensor([ 0.7949, -1.4914], grad_fn=<SliceBackward0>)\n",
      "iter 11200, loss: 12.445940971374512\n",
      "tensor(0.8834, grad_fn=<SelectBackward0>) tensor(-0.2321, grad_fn=<SelectBackward0>) tensor([ 0.3269, -1.1248], grad_fn=<SliceBackward0>) tensor([1.2169, 0.2059], grad_fn=<SliceBackward0>)\n",
      "iter 11300, loss: 37.34079360961914\n",
      "tensor(0.6021, grad_fn=<SelectBackward0>) tensor(-2.0295, grad_fn=<SelectBackward0>) tensor([-0.7313, -0.9062], grad_fn=<SliceBackward0>) tensor([-0.3553,  0.5172], grad_fn=<SliceBackward0>)\n",
      "iter 11400, loss: 12.304177284240723\n",
      "tensor(1.5328, grad_fn=<SelectBackward0>) tensor(-0.0201, grad_fn=<SelectBackward0>) tensor([0.0975, 0.1672], grad_fn=<SliceBackward0>) tensor([1.1039, 1.3419], grad_fn=<SliceBackward0>)\n",
      "iter 11500, loss: 38.611446380615234\n",
      "tensor(-0.1160, grad_fn=<SelectBackward0>) tensor(0.1477, grad_fn=<SelectBackward0>) tensor([1.4003, 0.6440], grad_fn=<SliceBackward0>) tensor([-0.3409, -0.2509], grad_fn=<SliceBackward0>)\n",
      "iter 11600, loss: 54.740577697753906\n",
      "tensor(0.2957, grad_fn=<SelectBackward0>) tensor(-1.0794, grad_fn=<SelectBackward0>) tensor([ 1.1292, -0.9019], grad_fn=<SliceBackward0>) tensor([-0.4852,  0.3668], grad_fn=<SliceBackward0>)\n",
      "iter 11700, loss: 23.271820068359375\n",
      "tensor(0.7944, grad_fn=<SelectBackward0>) tensor(0.1723, grad_fn=<SelectBackward0>) tensor([ 0.1452, -0.2383], grad_fn=<SliceBackward0>) tensor([-1.2426,  0.7842], grad_fn=<SliceBackward0>)\n",
      "iter 11800, loss: 6.450972557067871\n",
      "tensor(0.8189, grad_fn=<SelectBackward0>) tensor(0.1771, grad_fn=<SelectBackward0>) tensor([1.0070, 0.8522], grad_fn=<SliceBackward0>) tensor([ 2.1644, -0.3445], grad_fn=<SliceBackward0>)\n",
      "iter 11900, loss: 7.878790855407715\n",
      "tensor(-0.7811, grad_fn=<SelectBackward0>) tensor(0.0856, grad_fn=<SelectBackward0>) tensor([-0.7365, -0.2835], grad_fn=<SliceBackward0>) tensor([ 0.2981, -1.2053], grad_fn=<SliceBackward0>)\n",
      "iter 12000, loss: 0.47283226251602173\n",
      "tensor(1.2883, grad_fn=<SelectBackward0>) tensor(2.5400, grad_fn=<SelectBackward0>) tensor([-0.8036, -1.0193], grad_fn=<SliceBackward0>) tensor([-0.1325, -0.4262], grad_fn=<SliceBackward0>)\n",
      "iter 12100, loss: 0.08925823867321014\n",
      "tensor(2.0825, grad_fn=<SelectBackward0>) tensor(0.0602, grad_fn=<SelectBackward0>) tensor([-1.0066, -1.1779], grad_fn=<SliceBackward0>) tensor([-0.7754, -0.6942], grad_fn=<SliceBackward0>)\n",
      "iter 12200, loss: 52.08314895629883\n",
      "tensor(0.0257, grad_fn=<SelectBackward0>) tensor(1.4003, grad_fn=<SelectBackward0>) tensor([ 2.1648, -0.3510], grad_fn=<SliceBackward0>) tensor([-1.1267, -0.5417], grad_fn=<SliceBackward0>)\n",
      "iter 12300, loss: 44.350921630859375\n",
      "tensor(1.4101, grad_fn=<SelectBackward0>) tensor(1.7654, grad_fn=<SelectBackward0>) tensor([-1.0154, -2.1790], grad_fn=<SliceBackward0>) tensor([0.1246, 1.4544], grad_fn=<SliceBackward0>)\n",
      "iter 12400, loss: 10.840611457824707\n",
      "tensor(0.2644, grad_fn=<SelectBackward0>) tensor(1.3755, grad_fn=<SelectBackward0>) tensor([ 0.4119, -0.5050], grad_fn=<SliceBackward0>) tensor([-0.1656, -0.6367], grad_fn=<SliceBackward0>)\n",
      "iter 12500, loss: 12.33977222442627\n",
      "tensor(-0.7892, grad_fn=<SelectBackward0>) tensor(0.5085, grad_fn=<SelectBackward0>) tensor([-0.2941,  0.7202], grad_fn=<SliceBackward0>) tensor([0.9583, 0.4323], grad_fn=<SliceBackward0>)\n",
      "iter 12600, loss: 99.2465591430664\n",
      "tensor(1.5360, grad_fn=<SelectBackward0>) tensor(-1.6123, grad_fn=<SelectBackward0>) tensor([ 1.0942, -0.2404], grad_fn=<SliceBackward0>) tensor([-2.3751,  0.2120], grad_fn=<SliceBackward0>)\n",
      "iter 12700, loss: 14.167885780334473\n",
      "tensor(-0.4337, grad_fn=<SelectBackward0>) tensor(-0.6371, grad_fn=<SelectBackward0>) tensor([-0.8855, -1.4675], grad_fn=<SliceBackward0>) tensor([-0.6518, -0.0851], grad_fn=<SliceBackward0>)\n",
      "iter 12800, loss: 3.7757060527801514\n",
      "tensor(0.5387, grad_fn=<SelectBackward0>) tensor(0.9296, grad_fn=<SelectBackward0>) tensor([ 1.9025, -1.0981], grad_fn=<SliceBackward0>) tensor([0.5034, 0.0876], grad_fn=<SliceBackward0>)\n",
      "iter 12900, loss: 64.26762390136719\n",
      "tensor(-0.3673, grad_fn=<SelectBackward0>) tensor(-1.6327, grad_fn=<SelectBackward0>) tensor([0.0724, 1.9734], grad_fn=<SliceBackward0>) tensor([-0.3095, -0.4514], grad_fn=<SliceBackward0>)\n",
      "iter 13000, loss: 47.29207229614258\n",
      "tensor(-0.0142, grad_fn=<SelectBackward0>) tensor(-0.1061, grad_fn=<SelectBackward0>) tensor([-0.7908,  1.2457], grad_fn=<SliceBackward0>) tensor([-0.4761, -1.0465], grad_fn=<SliceBackward0>)\n",
      "iter 13100, loss: 5.288852691650391\n",
      "tensor(0.3192, grad_fn=<SelectBackward0>) tensor(0.3378, grad_fn=<SelectBackward0>) tensor([ 0.3713, -1.1366], grad_fn=<SliceBackward0>) tensor([ 0.1976, -0.1139], grad_fn=<SliceBackward0>)\n",
      "iter 13200, loss: 5.9503302574157715\n",
      "tensor(1.4484, grad_fn=<SelectBackward0>) tensor(0.9825, grad_fn=<SelectBackward0>) tensor([1.7603, 0.9187], grad_fn=<SliceBackward0>) tensor([-0.0312,  0.5303], grad_fn=<SliceBackward0>)\n",
      "iter 13300, loss: 10.241640090942383\n",
      "tensor(0.3568, grad_fn=<SelectBackward0>) tensor(0.2880, grad_fn=<SelectBackward0>) tensor([-1.4466,  0.7481], grad_fn=<SliceBackward0>) tensor([-1.0297,  0.0198], grad_fn=<SliceBackward0>)\n",
      "iter 13400, loss: 4.108418941497803\n",
      "tensor(0.5668, grad_fn=<SelectBackward0>) tensor(0.0966, grad_fn=<SelectBackward0>) tensor([0.5843, 0.7432], grad_fn=<SliceBackward0>) tensor([-0.5897, -0.2796], grad_fn=<SliceBackward0>)\n",
      "iter 13500, loss: 39.06788635253906\n",
      "tensor(-0.3890, grad_fn=<SelectBackward0>) tensor(0.6071, grad_fn=<SelectBackward0>) tensor([0.2737, 0.3478], grad_fn=<SliceBackward0>) tensor([ 0.1483, -1.9860], grad_fn=<SliceBackward0>)\n",
      "iter 13600, loss: 16.23656463623047\n",
      "tensor(-1.7325, grad_fn=<SelectBackward0>) tensor(1.0646, grad_fn=<SelectBackward0>) tensor([ 0.0537, -0.8597], grad_fn=<SliceBackward0>) tensor([0.7136, 0.1543], grad_fn=<SliceBackward0>)\n",
      "iter 13700, loss: 12.125650405883789\n",
      "tensor(0.8822, grad_fn=<SelectBackward0>) tensor(1.5487, grad_fn=<SelectBackward0>) tensor([ 0.0960, -1.1356], grad_fn=<SliceBackward0>) tensor([-0.1699,  0.5568], grad_fn=<SliceBackward0>)\n",
      "iter 13800, loss: 7.503015518188477\n",
      "tensor(1.9816, grad_fn=<SelectBackward0>) tensor(-1.7968, grad_fn=<SelectBackward0>) tensor([ 0.2008, -0.0531], grad_fn=<SliceBackward0>) tensor([ 1.7040, -0.0593], grad_fn=<SliceBackward0>)\n",
      "iter 13900, loss: 6.3689069747924805\n",
      "tensor(0.9608, grad_fn=<SelectBackward0>) tensor(0.7589, grad_fn=<SelectBackward0>) tensor([-0.5023,  0.3959], grad_fn=<SliceBackward0>) tensor([ 0.0146, -0.2755], grad_fn=<SliceBackward0>)\n",
      "iter 14000, loss: 32.84831237792969\n",
      "tensor(-0.7699, grad_fn=<SelectBackward0>) tensor(0.5124, grad_fn=<SelectBackward0>) tensor([ 0.5107, -1.0555], grad_fn=<SliceBackward0>) tensor([-0.1819,  0.8219], grad_fn=<SliceBackward0>)\n",
      "iter 14100, loss: 73.59939575195312\n",
      "tensor(-1.6600, grad_fn=<SelectBackward0>) tensor(-1.2622, grad_fn=<SelectBackward0>) tensor([-0.1957,  0.9971], grad_fn=<SliceBackward0>) tensor([ 0.0455, -1.5433], grad_fn=<SliceBackward0>)\n",
      "iter 14200, loss: 14.541420936584473\n",
      "tensor(0.4035, grad_fn=<SelectBackward0>) tensor(0.2202, grad_fn=<SelectBackward0>) tensor([ 1.6689, -0.8031], grad_fn=<SliceBackward0>) tensor([1.5199, 1.5219], grad_fn=<SliceBackward0>)\n",
      "iter 14300, loss: 31.455448150634766\n",
      "tensor(0.7375, grad_fn=<SelectBackward0>) tensor(-0.6635, grad_fn=<SelectBackward0>) tensor([-0.5454,  1.4864], grad_fn=<SliceBackward0>) tensor([ 0.5289, -0.5225], grad_fn=<SliceBackward0>)\n",
      "iter 14400, loss: 24.582914352416992\n",
      "tensor(-0.6185, grad_fn=<SelectBackward0>) tensor(-0.4626, grad_fn=<SelectBackward0>) tensor([ 0.3311, -0.5096], grad_fn=<SliceBackward0>) tensor([ 0.6222, -0.3815], grad_fn=<SliceBackward0>)\n",
      "iter 14500, loss: 33.41413497924805\n",
      "tensor(0.4802, grad_fn=<SelectBackward0>) tensor(-0.9572, grad_fn=<SelectBackward0>) tensor([ 0.7677, -0.8885], grad_fn=<SliceBackward0>) tensor([2.3635, 1.0767], grad_fn=<SliceBackward0>)\n",
      "iter 14600, loss: 27.804065704345703\n",
      "tensor(0.0296, grad_fn=<SelectBackward0>) tensor(-0.7160, grad_fn=<SelectBackward0>) tensor([ 1.0304, -0.3277], grad_fn=<SliceBackward0>) tensor([ 0.5145, -0.9987], grad_fn=<SliceBackward0>)\n",
      "iter 14700, loss: 25.710119247436523\n",
      "tensor(-0.8405, grad_fn=<SelectBackward0>) tensor(0.6288, grad_fn=<SelectBackward0>) tensor([-1.1689,  0.2867], grad_fn=<SliceBackward0>) tensor([-0.9988, -1.3826], grad_fn=<SliceBackward0>)\n",
      "iter 14800, loss: 17.496082305908203\n",
      "tensor(-0.0491, grad_fn=<SelectBackward0>) tensor(-0.2056, grad_fn=<SelectBackward0>) tensor([-1.6121, -0.6402], grad_fn=<SliceBackward0>) tensor([-0.0470, -0.7026], grad_fn=<SliceBackward0>)\n",
      "iter 14900, loss: 1.6202195882797241\n",
      "tensor(-0.0354, grad_fn=<SelectBackward0>) tensor(1.4559, grad_fn=<SelectBackward0>) tensor([-0.7266,  0.6100], grad_fn=<SliceBackward0>) tensor([-1.0496, -0.5662], grad_fn=<SliceBackward0>)\n",
      "iter 15000, loss: 9.513880729675293\n",
      "tensor(0.1035, grad_fn=<SelectBackward0>) tensor(0.3131, grad_fn=<SelectBackward0>) tensor([-0.5482,  0.5793], grad_fn=<SliceBackward0>) tensor([-0.9645,  0.3273], grad_fn=<SliceBackward0>)\n",
      "iter 15100, loss: 0.3953899145126343\n",
      "tensor(0.9989, grad_fn=<SelectBackward0>) tensor(-0.7296, grad_fn=<SelectBackward0>) tensor([ 1.2735, -0.9077], grad_fn=<SliceBackward0>) tensor([2.1337, 0.5473], grad_fn=<SliceBackward0>)\n",
      "iter 15200, loss: 32.22713088989258\n",
      "tensor(0.3250, grad_fn=<SelectBackward0>) tensor(-0.0456, grad_fn=<SelectBackward0>) tensor([ 1.0483, -0.1482], grad_fn=<SliceBackward0>) tensor([-0.3674,  0.7539], grad_fn=<SliceBackward0>)\n",
      "iter 15300, loss: 21.429916381835938\n",
      "tensor(-0.0729, grad_fn=<SelectBackward0>) tensor(0.6421, grad_fn=<SelectBackward0>) tensor([ 0.2053, -0.0321], grad_fn=<SliceBackward0>) tensor([0.8218, 0.9605], grad_fn=<SliceBackward0>)\n",
      "iter 15400, loss: 32.8246955871582\n",
      "tensor(-0.1454, grad_fn=<SelectBackward0>) tensor(-0.9847, grad_fn=<SelectBackward0>) tensor([ 1.4474, -1.3024], grad_fn=<SliceBackward0>) tensor([ 0.6411, -0.1187], grad_fn=<SliceBackward0>)\n",
      "iter 15500, loss: 36.14154815673828\n",
      "tensor(-1.3715, grad_fn=<SelectBackward0>) tensor(1.0340, grad_fn=<SelectBackward0>) tensor([0.1951, 1.3891], grad_fn=<SliceBackward0>) tensor([ 0.6762, -0.1842], grad_fn=<SliceBackward0>)\n",
      "iter 15600, loss: 1.9835755825042725\n",
      "tensor(0.4521, grad_fn=<SelectBackward0>) tensor(-0.0560, grad_fn=<SelectBackward0>) tensor([-1.0245, -1.8363], grad_fn=<SliceBackward0>) tensor([-0.8763,  0.2709], grad_fn=<SliceBackward0>)\n",
      "iter 15700, loss: 7.19144344329834\n",
      "tensor(0.7194, grad_fn=<SelectBackward0>) tensor(-0.1737, grad_fn=<SelectBackward0>) tensor([-1.3551, -0.3167], grad_fn=<SliceBackward0>) tensor([-1.5067, -0.1537], grad_fn=<SliceBackward0>)\n",
      "iter 15800, loss: 7.824724197387695\n",
      "tensor(0.8101, grad_fn=<SelectBackward0>) tensor(-0.1302, grad_fn=<SelectBackward0>) tensor([-1.6149, -1.4117], grad_fn=<SliceBackward0>) tensor([-0.6790,  0.1303], grad_fn=<SliceBackward0>)\n",
      "iter 15900, loss: 31.385284423828125\n",
      "tensor(-0.1446, grad_fn=<SelectBackward0>) tensor(-0.4766, grad_fn=<SelectBackward0>) tensor([-0.3554,  1.1766], grad_fn=<SliceBackward0>) tensor([ 0.7057, -0.2132], grad_fn=<SliceBackward0>)\n",
      "iter 16000, loss: 19.01419448852539\n",
      "tensor(0.7182, grad_fn=<SelectBackward0>) tensor(0.9358, grad_fn=<SelectBackward0>) tensor([-0.1269,  1.0264], grad_fn=<SliceBackward0>) tensor([-0.6455, -0.7114], grad_fn=<SliceBackward0>)\n",
      "iter 16100, loss: 55.73241424560547\n",
      "tensor(0.1946, grad_fn=<SelectBackward0>) tensor(-1.4424, grad_fn=<SelectBackward0>) tensor([ 0.1336, -0.3817], grad_fn=<SliceBackward0>) tensor([-1.4967,  0.6473], grad_fn=<SliceBackward0>)\n",
      "iter 16200, loss: 18.19497299194336\n",
      "tensor(-1.1327, grad_fn=<SelectBackward0>) tensor(0.0958, grad_fn=<SelectBackward0>) tensor([0.5723, 0.4136], grad_fn=<SliceBackward0>) tensor([0.9317, 2.3511], grad_fn=<SliceBackward0>)\n",
      "iter 16300, loss: 11.96216869354248\n",
      "tensor(-0.4104, grad_fn=<SelectBackward0>) tensor(1.1591, grad_fn=<SelectBackward0>) tensor([0.0083, 0.3730], grad_fn=<SliceBackward0>) tensor([-0.6038, -0.0743], grad_fn=<SliceBackward0>)\n",
      "iter 16400, loss: 12.570679664611816\n",
      "tensor(2.4126, grad_fn=<SelectBackward0>) tensor(0.7973, grad_fn=<SelectBackward0>) tensor([-1.2108,  0.6474], grad_fn=<SliceBackward0>) tensor([ 1.1062, -0.0460], grad_fn=<SliceBackward0>)\n",
      "iter 16500, loss: 2.483067512512207\n",
      "tensor(-0.8486, grad_fn=<SelectBackward0>) tensor(1.4598, grad_fn=<SelectBackward0>) tensor([1.1414, 0.4714], grad_fn=<SliceBackward0>) tensor([ 1.0251, -0.4426], grad_fn=<SliceBackward0>)\n",
      "iter 16600, loss: 5.702632427215576\n",
      "tensor(0.9390, grad_fn=<SelectBackward0>) tensor(0.3045, grad_fn=<SelectBackward0>) tensor([ 1.6761, -0.8349], grad_fn=<SliceBackward0>) tensor([ 0.6689, -0.6492], grad_fn=<SliceBackward0>)\n",
      "iter 16700, loss: 26.423858642578125\n",
      "tensor(-0.4268, grad_fn=<SelectBackward0>) tensor(-0.1355, grad_fn=<SelectBackward0>) tensor([ 0.5125, -0.1065], grad_fn=<SliceBackward0>) tensor([ 0.0203, -2.4333], grad_fn=<SliceBackward0>)\n",
      "iter 16800, loss: 12.008855819702148\n",
      "tensor(0.6426, grad_fn=<SelectBackward0>) tensor(-0.1793, grad_fn=<SelectBackward0>) tensor([0.3426, 0.6645], grad_fn=<SliceBackward0>) tensor([0.0254, 2.4775], grad_fn=<SliceBackward0>)\n",
      "iter 16900, loss: 11.84719181060791\n",
      "tensor(0.8553, grad_fn=<SelectBackward0>) tensor(0.9632, grad_fn=<SelectBackward0>) tensor([ 0.7373, -0.6640], grad_fn=<SliceBackward0>) tensor([-0.2782,  1.1187], grad_fn=<SliceBackward0>)\n",
      "iter 17000, loss: 15.030616760253906\n",
      "tensor(0.4121, grad_fn=<SelectBackward0>) tensor(0.8590, grad_fn=<SelectBackward0>) tensor([-0.0137, -1.5297], grad_fn=<SliceBackward0>) tensor([-2.3274,  0.2636], grad_fn=<SliceBackward0>)\n",
      "iter 17100, loss: 10.114272117614746\n",
      "tensor(-0.1474, grad_fn=<SelectBackward0>) tensor(0.8795, grad_fn=<SelectBackward0>) tensor([-2.1079, -0.9228], grad_fn=<SliceBackward0>) tensor([0.0868, 0.2727], grad_fn=<SliceBackward0>)\n",
      "iter 17200, loss: 3.5922958850860596\n",
      "tensor(1.9753, grad_fn=<SelectBackward0>) tensor(0.0655, grad_fn=<SelectBackward0>) tensor([ 0.5233, -1.2958], grad_fn=<SliceBackward0>) tensor([ 1.7699, -0.3133], grad_fn=<SliceBackward0>)\n",
      "iter 17300, loss: 18.473508834838867\n",
      "tensor(0.2204, grad_fn=<SelectBackward0>) tensor(-0.2707, grad_fn=<SelectBackward0>) tensor([-0.4787,  0.6539], grad_fn=<SliceBackward0>) tensor([-0.6539,  1.2488], grad_fn=<SliceBackward0>)\n",
      "iter 17400, loss: 5.910770893096924\n",
      "tensor(2.2479, grad_fn=<SelectBackward0>) tensor(-0.2619, grad_fn=<SelectBackward0>) tensor([-0.1056,  0.6644], grad_fn=<SliceBackward0>) tensor([ 1.0311, -1.5266], grad_fn=<SliceBackward0>)\n",
      "iter 17500, loss: 54.15437316894531\n",
      "tensor(1.5681, grad_fn=<SelectBackward0>) tensor(0.4613, grad_fn=<SelectBackward0>) tensor([-1.9888, -0.5659], grad_fn=<SliceBackward0>) tensor([ 1.6074, -0.7682], grad_fn=<SliceBackward0>)\n",
      "iter 17600, loss: 4.389170169830322\n",
      "tensor(-0.7483, grad_fn=<SelectBackward0>) tensor(0.7514, grad_fn=<SelectBackward0>) tensor([2.4605, 1.5208], grad_fn=<SliceBackward0>) tensor([ 1.8630, -0.7208], grad_fn=<SliceBackward0>)\n",
      "iter 17700, loss: 28.695486068725586\n",
      "tensor(-0.0049, grad_fn=<SelectBackward0>) tensor(0.4664, grad_fn=<SelectBackward0>) tensor([-0.1282, -0.3314], grad_fn=<SliceBackward0>) tensor([ 1.8645, -0.1169], grad_fn=<SliceBackward0>)\n",
      "iter 17800, loss: 12.364192008972168\n",
      "tensor(0.4981, grad_fn=<SelectBackward0>) tensor(-0.1971, grad_fn=<SelectBackward0>) tensor([-0.3205,  0.4201], grad_fn=<SliceBackward0>) tensor([-0.4742,  0.5270], grad_fn=<SliceBackward0>)\n",
      "iter 17900, loss: 46.13543701171875\n",
      "tensor(-0.9097, grad_fn=<SelectBackward0>) tensor(-0.7152, grad_fn=<SelectBackward0>) tensor([ 0.0128, -1.2286], grad_fn=<SliceBackward0>) tensor([ 2.6650, -1.1249], grad_fn=<SliceBackward0>)\n",
      "iter 18000, loss: 49.11314010620117\n",
      "tensor(0.1924, grad_fn=<SelectBackward0>) tensor(-1.0869, grad_fn=<SelectBackward0>) tensor([0.6977, 1.1516], grad_fn=<SliceBackward0>) tensor([-0.0565, -1.1040], grad_fn=<SliceBackward0>)\n",
      "iter 18100, loss: 30.32769775390625\n",
      "tensor(-1.5420, grad_fn=<SelectBackward0>) tensor(1.0781, grad_fn=<SelectBackward0>) tensor([-0.7583,  1.4076], grad_fn=<SliceBackward0>) tensor([ 0.0547, -0.3279], grad_fn=<SliceBackward0>)\n",
      "iter 18200, loss: 10.443857192993164\n",
      "tensor(0.7742, grad_fn=<SelectBackward0>) tensor(0.0272, grad_fn=<SelectBackward0>) tensor([-0.5516, -1.3340], grad_fn=<SliceBackward0>) tensor([ 0.9409, -0.6225], grad_fn=<SliceBackward0>)\n",
      "iter 18300, loss: 23.011701583862305\n",
      "tensor(-0.8758, grad_fn=<SelectBackward0>) tensor(0.1098, grad_fn=<SelectBackward0>) tensor([-1.2644,  0.3289], grad_fn=<SliceBackward0>) tensor([-1.0166,  0.3538], grad_fn=<SliceBackward0>)\n",
      "iter 18400, loss: 15.400763511657715\n",
      "tensor(0.9116, grad_fn=<SelectBackward0>) tensor(1.4872, grad_fn=<SelectBackward0>) tensor([ 0.5904, -1.4553], grad_fn=<SliceBackward0>) tensor([-1.0551,  0.8060], grad_fn=<SliceBackward0>)\n",
      "iter 18500, loss: 4.511202812194824\n",
      "tensor(0.6555, grad_fn=<SelectBackward0>) tensor(-0.0012, grad_fn=<SelectBackward0>) tensor([ 1.3592, -0.5385], grad_fn=<SliceBackward0>) tensor([1.9115, 0.1063], grad_fn=<SliceBackward0>)\n",
      "iter 18600, loss: 21.50086784362793\n",
      "tensor(-1.5162, grad_fn=<SelectBackward0>) tensor(2.2926, grad_fn=<SelectBackward0>) tensor([0.9597, 0.4927], grad_fn=<SliceBackward0>) tensor([-0.2439,  0.2664], grad_fn=<SliceBackward0>)\n",
      "iter 18700, loss: 28.88492202758789\n",
      "tensor(-0.2486, grad_fn=<SelectBackward0>) tensor(-0.3634, grad_fn=<SelectBackward0>) tensor([ 1.0148, -0.3637], grad_fn=<SliceBackward0>) tensor([-0.8582,  0.9153], grad_fn=<SliceBackward0>)\n",
      "iter 18800, loss: 50.50132751464844\n",
      "tensor(0.1089, grad_fn=<SelectBackward0>) tensor(-0.3824, grad_fn=<SelectBackward0>) tensor([-0.1541, -1.1650], grad_fn=<SliceBackward0>) tensor([0.9911, 1.4078], grad_fn=<SliceBackward0>)\n",
      "iter 18900, loss: 40.992008209228516\n",
      "tensor(-1.3894, grad_fn=<SelectBackward0>) tensor(-1.3377, grad_fn=<SelectBackward0>) tensor([-0.9695, -0.1335], grad_fn=<SliceBackward0>) tensor([-2.6772,  0.3725], grad_fn=<SliceBackward0>)\n",
      "iter 19000, loss: 73.68704223632812\n",
      "tensor(-1.6507, grad_fn=<SelectBackward0>) tensor(-1.5096, grad_fn=<SelectBackward0>) tensor([-0.1273,  0.3308], grad_fn=<SliceBackward0>) tensor([-0.9500, -0.0678], grad_fn=<SliceBackward0>)\n",
      "iter 19100, loss: 18.164844512939453\n",
      "tensor(-1.0938, grad_fn=<SelectBackward0>) tensor(2.0695, grad_fn=<SelectBackward0>) tensor([0.3899, 1.1379], grad_fn=<SliceBackward0>) tensor([-0.3231,  0.1706], grad_fn=<SliceBackward0>)\n",
      "iter 19200, loss: 6.322011947631836\n",
      "tensor(0.0821, grad_fn=<SelectBackward0>) tensor(0.5810, grad_fn=<SelectBackward0>) tensor([-0.2449,  0.3533], grad_fn=<SliceBackward0>) tensor([0.7669, 0.4556], grad_fn=<SliceBackward0>)\n",
      "iter 19300, loss: 74.8307113647461\n",
      "tensor(-1.3647, grad_fn=<SelectBackward0>) tensor(-0.4999, grad_fn=<SelectBackward0>) tensor([-0.4519,  1.2507], grad_fn=<SliceBackward0>) tensor([ 1.5212, -0.6309], grad_fn=<SliceBackward0>)\n",
      "iter 19400, loss: 4.869073867797852\n",
      "tensor(0.7605, grad_fn=<SelectBackward0>) tensor(1.2633, grad_fn=<SelectBackward0>) tensor([0.3302, 0.3134], grad_fn=<SliceBackward0>) tensor([ 1.1498, -1.2317], grad_fn=<SliceBackward0>)\n",
      "iter 19500, loss: 15.138279914855957\n",
      "tensor(-0.6231, grad_fn=<SelectBackward0>) tensor(-0.6040, grad_fn=<SelectBackward0>) tensor([ 0.2639, -0.5807], grad_fn=<SliceBackward0>) tensor([ 0.0397, -1.0018], grad_fn=<SliceBackward0>)\n",
      "iter 19600, loss: 14.008694648742676\n",
      "tensor(-0.5705, grad_fn=<SelectBackward0>) tensor(-0.5299, grad_fn=<SelectBackward0>) tensor([0.1377, 1.6475], grad_fn=<SliceBackward0>) tensor([-0.2823,  1.7925], grad_fn=<SliceBackward0>)\n",
      "iter 19700, loss: 26.451658248901367\n",
      "tensor(-0.1369, grad_fn=<SelectBackward0>) tensor(1.4469, grad_fn=<SelectBackward0>) tensor([1.9906, 0.1253], grad_fn=<SliceBackward0>) tensor([-0.3752,  1.5051], grad_fn=<SliceBackward0>)\n",
      "iter 19800, loss: 18.230201721191406\n",
      "tensor(-0.2436, grad_fn=<SelectBackward0>) tensor(-0.8098, grad_fn=<SelectBackward0>) tensor([-0.0093, -0.5159], grad_fn=<SliceBackward0>) tensor([-0.1651,  0.0409], grad_fn=<SliceBackward0>)\n",
      "iter 19900, loss: 17.33574867248535\n",
      "tensor(-0.1233, grad_fn=<SelectBackward0>) tensor(0.6351, grad_fn=<SelectBackward0>) tensor([1.0134, 1.8430], grad_fn=<SliceBackward0>) tensor([-0.5644,  0.8140], grad_fn=<SliceBackward0>)\n",
      "iter 20000, loss: 5.409127235412598\n",
      "tensor(-0.2579, grad_fn=<SelectBackward0>) tensor(2.5686, grad_fn=<SelectBackward0>) tensor([0.8090, 0.1937], grad_fn=<SliceBackward0>) tensor([0.3906, 1.3611], grad_fn=<SliceBackward0>)\n",
      "iter 20100, loss: 6.2489213943481445\n",
      "tensor(-0.6058, grad_fn=<SelectBackward0>) tensor(3.0666, grad_fn=<SelectBackward0>) tensor([ 1.4140, -0.2218], grad_fn=<SliceBackward0>) tensor([0.2126, 0.2441], grad_fn=<SliceBackward0>)\n",
      "iter 20200, loss: 2.5675301551818848\n",
      "tensor(1.1873, grad_fn=<SelectBackward0>) tensor(1.3568, grad_fn=<SelectBackward0>) tensor([-0.4755,  0.2743], grad_fn=<SliceBackward0>) tensor([ 0.0461, -0.1769], grad_fn=<SliceBackward0>)\n",
      "iter 20300, loss: 51.42696762084961\n",
      "tensor(-0.9531, grad_fn=<SelectBackward0>) tensor(-0.8826, grad_fn=<SelectBackward0>) tensor([1.6085, 0.8408], grad_fn=<SliceBackward0>) tensor([0.2500, 0.0284], grad_fn=<SliceBackward0>)\n",
      "iter 20400, loss: 41.3848762512207\n",
      "tensor(0.9787, grad_fn=<SelectBackward0>) tensor(-1.5963, grad_fn=<SelectBackward0>) tensor([-1.9679,  0.8210], grad_fn=<SliceBackward0>) tensor([0.2959, 0.9025], grad_fn=<SliceBackward0>)\n",
      "iter 20500, loss: 2.676652669906616\n",
      "tensor(1.8413, grad_fn=<SelectBackward0>) tensor(1.2808, grad_fn=<SelectBackward0>) tensor([-0.8128,  0.2915], grad_fn=<SliceBackward0>) tensor([-0.5585, -0.3682], grad_fn=<SliceBackward0>)\n",
      "iter 20600, loss: 12.060958862304688\n",
      "tensor(1.1776, grad_fn=<SelectBackward0>) tensor(0.4942, grad_fn=<SelectBackward0>) tensor([1.3453, 1.0723], grad_fn=<SliceBackward0>) tensor([ 1.5568, -1.4714], grad_fn=<SliceBackward0>)\n",
      "iter 20700, loss: 0.06595518440008163\n",
      "tensor(1.0759, grad_fn=<SelectBackward0>) tensor(-0.7386, grad_fn=<SelectBackward0>) tensor([-2.1716,  0.7470], grad_fn=<SliceBackward0>) tensor([-1.5905,  0.5440], grad_fn=<SliceBackward0>)\n",
      "iter 20800, loss: 11.871399879455566\n",
      "tensor(1.1303, grad_fn=<SelectBackward0>) tensor(-1.0426, grad_fn=<SelectBackward0>) tensor([-0.5258,  1.1216], grad_fn=<SliceBackward0>) tensor([-0.8810,  1.2317], grad_fn=<SliceBackward0>)\n",
      "iter 20900, loss: 7.123959541320801\n",
      "tensor(0.2807, grad_fn=<SelectBackward0>) tensor(2.4466, grad_fn=<SelectBackward0>) tensor([ 0.8607, -0.3852], grad_fn=<SliceBackward0>) tensor([-0.1198,  0.3355], grad_fn=<SliceBackward0>)\n",
      "iter 21000, loss: 10.875420570373535\n",
      "tensor(-0.0108, grad_fn=<SelectBackward0>) tensor(-0.4664, grad_fn=<SelectBackward0>) tensor([-0.4916,  1.1951], grad_fn=<SliceBackward0>) tensor([-0.1214,  1.2058], grad_fn=<SliceBackward0>)\n",
      "iter 21100, loss: 4.309450149536133\n",
      "tensor(1.2008, grad_fn=<SelectBackward0>) tensor(-1.2166, grad_fn=<SelectBackward0>) tensor([-0.9905,  0.4003], grad_fn=<SliceBackward0>) tensor([-1.8591,  1.0102], grad_fn=<SliceBackward0>)\n",
      "iter 21200, loss: 36.58084487915039\n",
      "tensor(-1.2462, grad_fn=<SelectBackward0>) tensor(-0.1946, grad_fn=<SelectBackward0>) tensor([-0.2935,  0.1044], grad_fn=<SliceBackward0>) tensor([ 0.2582, -1.0873], grad_fn=<SliceBackward0>)\n",
      "iter 21300, loss: 16.53872299194336\n",
      "tensor(1.6866, grad_fn=<SelectBackward0>) tensor(-0.5907, grad_fn=<SelectBackward0>) tensor([ 0.7139, -0.3482], grad_fn=<SliceBackward0>) tensor([-0.1516, -0.5281], grad_fn=<SliceBackward0>)\n",
      "iter 21400, loss: 22.429094314575195\n",
      "tensor(1.5859, grad_fn=<SelectBackward0>) tensor(1.3241, grad_fn=<SelectBackward0>) tensor([-0.3478,  1.0774], grad_fn=<SliceBackward0>) tensor([-0.2093, -1.8673], grad_fn=<SliceBackward0>)\n",
      "iter 21500, loss: 3.734304428100586\n",
      "tensor(0.0081, grad_fn=<SelectBackward0>) tensor(2.1506, grad_fn=<SelectBackward0>) tensor([-1.2212, -0.5415], grad_fn=<SliceBackward0>) tensor([-0.0290, -0.0379], grad_fn=<SliceBackward0>)\n",
      "iter 21600, loss: 1.4525264501571655\n",
      "tensor(1.0533, grad_fn=<SelectBackward0>) tensor(1.6059, grad_fn=<SelectBackward0>) tensor([-0.6218, -2.2279], grad_fn=<SliceBackward0>) tensor([ 0.5560, -0.7539], grad_fn=<SliceBackward0>)\n",
      "iter 21700, loss: 23.007343292236328\n",
      "tensor(0.6715, grad_fn=<SelectBackward0>) tensor(0.1588, grad_fn=<SelectBackward0>) tensor([0.1484, 0.3381], grad_fn=<SliceBackward0>) tensor([-1.0947, -0.3589], grad_fn=<SliceBackward0>)\n",
      "iter 21800, loss: 7.3754191398620605\n",
      "tensor(0.1688, grad_fn=<SelectBackward0>) tensor(1.8698, grad_fn=<SelectBackward0>) tensor([-0.7144,  0.2938], grad_fn=<SliceBackward0>) tensor([ 0.5527, -0.5999], grad_fn=<SliceBackward0>)\n",
      "iter 21900, loss: 7.063805103302002\n",
      "tensor(0.8001, grad_fn=<SelectBackward0>) tensor(0.9371, grad_fn=<SelectBackward0>) tensor([-1.4055,  0.3804], grad_fn=<SliceBackward0>) tensor([-0.4819,  0.4287], grad_fn=<SliceBackward0>)\n",
      "iter 22000, loss: 24.554410934448242\n",
      "tensor(-0.4049, grad_fn=<SelectBackward0>) tensor(-0.2981, grad_fn=<SelectBackward0>) tensor([ 0.3501, -1.2848], grad_fn=<SliceBackward0>) tensor([-0.5153,  0.4825], grad_fn=<SliceBackward0>)\n",
      "iter 22100, loss: 18.141489028930664\n",
      "tensor(0.5937, grad_fn=<SelectBackward0>) tensor(-0.9789, grad_fn=<SelectBackward0>) tensor([-0.8961, -0.8723], grad_fn=<SliceBackward0>) tensor([-1.2139, -0.5287], grad_fn=<SliceBackward0>)\n",
      "iter 22200, loss: 31.144229888916016\n",
      "tensor(0.0598, grad_fn=<SelectBackward0>) tensor(0.4151, grad_fn=<SelectBackward0>) tensor([0.3643, 0.6287], grad_fn=<SliceBackward0>) tensor([ 1.0935, -1.3069], grad_fn=<SliceBackward0>)\n",
      "iter 22300, loss: 51.42267608642578\n",
      "tensor(0.0419, grad_fn=<SelectBackward0>) tensor(1.3133, grad_fn=<SelectBackward0>) tensor([ 1.8780, -0.2356], grad_fn=<SliceBackward0>) tensor([-1.5793,  0.5306], grad_fn=<SliceBackward0>)\n",
      "iter 22400, loss: 18.9270076751709\n",
      "tensor(0.3986, grad_fn=<SelectBackward0>) tensor(-0.8532, grad_fn=<SelectBackward0>) tensor([ 0.2841, -0.4779], grad_fn=<SliceBackward0>) tensor([-0.1452, -0.8437], grad_fn=<SliceBackward0>)\n",
      "iter 22500, loss: 50.680992126464844\n",
      "tensor(-0.0038, grad_fn=<SelectBackward0>) tensor(0.9649, grad_fn=<SelectBackward0>) tensor([-1.6616,  1.1743], grad_fn=<SliceBackward0>) tensor([1.4265, 0.5487], grad_fn=<SliceBackward0>)\n",
      "iter 22600, loss: 36.430992126464844\n",
      "tensor(-0.8443, grad_fn=<SelectBackward0>) tensor(0.7511, grad_fn=<SelectBackward0>) tensor([-0.4702,  0.2550], grad_fn=<SliceBackward0>) tensor([1.1286, 0.1952], grad_fn=<SliceBackward0>)\n",
      "iter 22700, loss: 46.75632095336914\n",
      "tensor(-0.0264, grad_fn=<SelectBackward0>) tensor(-0.7887, grad_fn=<SelectBackward0>) tensor([-0.2236,  1.3698], grad_fn=<SliceBackward0>) tensor([-0.2897, -0.3549], grad_fn=<SliceBackward0>)\n",
      "iter 22800, loss: 0.5774774551391602\n",
      "tensor(1.3978, grad_fn=<SelectBackward0>) tensor(0.2101, grad_fn=<SelectBackward0>) tensor([-0.1660, -1.2098], grad_fn=<SliceBackward0>) tensor([-0.5389, -1.3466], grad_fn=<SliceBackward0>)\n",
      "iter 22900, loss: 53.67993927001953\n",
      "tensor(-1.6388, grad_fn=<SelectBackward0>) tensor(-1.5789, grad_fn=<SelectBackward0>) tensor([ 0.5562, -0.9220], grad_fn=<SliceBackward0>) tensor([ 0.0367, -1.9601], grad_fn=<SliceBackward0>)\n",
      "iter 23000, loss: 1.9243969917297363\n",
      "tensor(-1.0231, grad_fn=<SelectBackward0>) tensor(0.6734, grad_fn=<SelectBackward0>) tensor([0.5523, 0.8922], grad_fn=<SliceBackward0>) tensor([-0.0240,  1.2355], grad_fn=<SliceBackward0>)\n",
      "iter 23100, loss: 23.199369430541992\n",
      "tensor(1.8898, grad_fn=<SelectBackward0>) tensor(-1.8251, grad_fn=<SelectBackward0>) tensor([0.9713, 0.8904], grad_fn=<SliceBackward0>) tensor([-0.3246, -0.1963], grad_fn=<SliceBackward0>)\n",
      "iter 23200, loss: 47.300079345703125\n",
      "tensor(-2.6109, grad_fn=<SelectBackward0>) tensor(-0.6276, grad_fn=<SelectBackward0>) tensor([ 0.0981, -0.9028], grad_fn=<SliceBackward0>) tensor([-0.2212, -0.9571], grad_fn=<SliceBackward0>)\n",
      "iter 23300, loss: 22.596601486206055\n",
      "tensor(-1.0580, grad_fn=<SelectBackward0>) tensor(1.4210, grad_fn=<SelectBackward0>) tensor([-0.1359, -0.7335], grad_fn=<SliceBackward0>) tensor([-0.7785, -0.1042], grad_fn=<SliceBackward0>)\n",
      "iter 23400, loss: 6.709469795227051\n",
      "tensor(1.6941, grad_fn=<SelectBackward0>) tensor(-0.6057, grad_fn=<SelectBackward0>) tensor([1.1707, 1.2677], grad_fn=<SliceBackward0>) tensor([0.4707, 0.8400], grad_fn=<SliceBackward0>)\n",
      "iter 23500, loss: 12.120476722717285\n",
      "tensor(0.1866, grad_fn=<SelectBackward0>) tensor(1.6792, grad_fn=<SelectBackward0>) tensor([-0.2955,  0.4796], grad_fn=<SliceBackward0>) tensor([1.2140, 0.6392], grad_fn=<SliceBackward0>)\n",
      "iter 23600, loss: 25.054166793823242\n",
      "tensor(0.9041, grad_fn=<SelectBackward0>) tensor(0.2375, grad_fn=<SelectBackward0>) tensor([1.0353, 0.1048], grad_fn=<SliceBackward0>) tensor([-0.7272, -0.0534], grad_fn=<SliceBackward0>)\n",
      "iter 23700, loss: 0.08021627366542816\n",
      "tensor(-0.0790, grad_fn=<SelectBackward0>) tensor(1.5515, grad_fn=<SelectBackward0>) tensor([0.5950, 3.5005], grad_fn=<SliceBackward0>) tensor([-0.3236,  0.4365], grad_fn=<SliceBackward0>)\n",
      "iter 23800, loss: 58.62350082397461\n",
      "tensor(-1.5465, grad_fn=<SelectBackward0>) tensor(-0.6021, grad_fn=<SelectBackward0>) tensor([-0.0914, -0.0377], grad_fn=<SliceBackward0>) tensor([-1.1830,  0.6394], grad_fn=<SliceBackward0>)\n",
      "iter 23900, loss: 9.204516410827637\n",
      "tensor(-0.5767, grad_fn=<SelectBackward0>) tensor(0.5212, grad_fn=<SelectBackward0>) tensor([ 0.1342, -0.1786], grad_fn=<SliceBackward0>) tensor([ 0.5702, -0.6216], grad_fn=<SliceBackward0>)\n",
      "iter 24000, loss: 0.2653159499168396\n",
      "tensor(-1.1137, grad_fn=<SelectBackward0>) tensor(-0.9711, grad_fn=<SelectBackward0>) tensor([ 3.7390, -0.7254], grad_fn=<SliceBackward0>) tensor([ 1.0165, -1.3353], grad_fn=<SliceBackward0>)\n",
      "iter 24100, loss: 10.41152286529541\n",
      "tensor(2.1616, grad_fn=<SelectBackward0>) tensor(-0.0407, grad_fn=<SelectBackward0>) tensor([ 0.8111, -0.1583], grad_fn=<SliceBackward0>) tensor([-0.2982, -0.6556], grad_fn=<SliceBackward0>)\n",
      "iter 24200, loss: 16.681480407714844\n",
      "tensor(-0.5791, grad_fn=<SelectBackward0>) tensor(0.5973, grad_fn=<SelectBackward0>) tensor([-0.6096,  0.2399], grad_fn=<SliceBackward0>) tensor([0.1230, 1.7577], grad_fn=<SliceBackward0>)\n",
      "iter 24300, loss: 32.781517028808594\n",
      "tensor(-0.3294, grad_fn=<SelectBackward0>) tensor(0.6947, grad_fn=<SelectBackward0>) tensor([-1.1037, -1.4827], grad_fn=<SliceBackward0>) tensor([-0.5976,  0.6805], grad_fn=<SliceBackward0>)\n",
      "iter 24400, loss: 27.216028213500977\n",
      "tensor(1.1371, grad_fn=<SelectBackward0>) tensor(0.2889, grad_fn=<SelectBackward0>) tensor([-0.9049,  2.1069], grad_fn=<SliceBackward0>) tensor([-0.6608, -0.6433], grad_fn=<SliceBackward0>)\n",
      "iter 24500, loss: 0.16738569736480713\n",
      "tensor(2.7675, grad_fn=<SelectBackward0>) tensor(1.2732, grad_fn=<SelectBackward0>) tensor([1.6212, 1.1594], grad_fn=<SliceBackward0>) tensor([-1.3987,  0.7724], grad_fn=<SliceBackward0>)\n",
      "iter 24600, loss: 46.85383605957031\n",
      "tensor(-1.7974, grad_fn=<SelectBackward0>) tensor(0.0484, grad_fn=<SelectBackward0>) tensor([ 1.0404, -0.1263], grad_fn=<SliceBackward0>) tensor([ 0.3083, -0.0644], grad_fn=<SliceBackward0>)\n",
      "iter 24700, loss: 3.3907833099365234\n",
      "tensor(-0.2953, grad_fn=<SelectBackward0>) tensor(1.9154, grad_fn=<SelectBackward0>) tensor([ 0.6128, -1.1094], grad_fn=<SliceBackward0>) tensor([-0.2734, -0.7771], grad_fn=<SliceBackward0>)\n",
      "iter 24800, loss: 32.732627868652344\n",
      "tensor(-0.4331, grad_fn=<SelectBackward0>) tensor(-0.2261, grad_fn=<SelectBackward0>) tensor([0.1179, 0.2642], grad_fn=<SliceBackward0>) tensor([0.8002, 1.4130], grad_fn=<SliceBackward0>)\n",
      "iter 24900, loss: 0.5947669148445129\n",
      "tensor(1.5822, grad_fn=<SelectBackward0>) tensor(0.1996, grad_fn=<SelectBackward0>) tensor([-1.0023, -1.0089], grad_fn=<SliceBackward0>) tensor([-0.1258, -0.3838], grad_fn=<SliceBackward0>)\n",
      "iter 25000, loss: 24.98633575439453\n",
      "tensor(-0.0774, grad_fn=<SelectBackward0>) tensor(-0.8227, grad_fn=<SelectBackward0>) tensor([-0.3234, -0.6630], grad_fn=<SliceBackward0>) tensor([-0.6519, -2.0926], grad_fn=<SliceBackward0>)\n",
      "iter 25100, loss: 31.060791015625\n",
      "tensor(-1.1268, grad_fn=<SelectBackward0>) tensor(0.5339, grad_fn=<SelectBackward0>) tensor([0.2280, 0.5897], grad_fn=<SliceBackward0>) tensor([0.0651, 0.4917], grad_fn=<SliceBackward0>)\n",
      "iter 25200, loss: 63.58607864379883\n",
      "tensor(-1.1095, grad_fn=<SelectBackward0>) tensor(-0.3718, grad_fn=<SelectBackward0>) tensor([1.0971, 0.2756], grad_fn=<SliceBackward0>) tensor([-0.3260, -1.1364], grad_fn=<SliceBackward0>)\n",
      "iter 25300, loss: 59.59986877441406\n",
      "tensor(-0.0006, grad_fn=<SelectBackward0>) tensor(-2.0258, grad_fn=<SelectBackward0>) tensor([-0.5149,  0.2267], grad_fn=<SliceBackward0>) tensor([-0.6158, -1.3333], grad_fn=<SliceBackward0>)\n",
      "iter 25400, loss: 2.4369029998779297\n",
      "tensor(1.5041, grad_fn=<SelectBackward0>) tensor(2.4839, grad_fn=<SelectBackward0>) tensor([ 0.9733, -0.3908], grad_fn=<SliceBackward0>) tensor([-0.6830, -0.6196], grad_fn=<SliceBackward0>)\n",
      "iter 25500, loss: 1.0203816890716553\n",
      "tensor(-0.1704, grad_fn=<SelectBackward0>) tensor(-0.8662, grad_fn=<SelectBackward0>) tensor([-0.3364,  1.7880], grad_fn=<SliceBackward0>) tensor([0.0760, 1.2237], grad_fn=<SliceBackward0>)\n",
      "iter 25600, loss: 11.775483131408691\n",
      "tensor(0.7518, grad_fn=<SelectBackward0>) tensor(0.4135, grad_fn=<SelectBackward0>) tensor([0.7761, 0.0921], grad_fn=<SliceBackward0>) tensor([ 0.8526, -0.3245], grad_fn=<SliceBackward0>)\n",
      "iter 25700, loss: 14.281142234802246\n",
      "tensor(0.4962, grad_fn=<SelectBackward0>) tensor(0.6960, grad_fn=<SelectBackward0>) tensor([1.7256, 0.0509], grad_fn=<SliceBackward0>) tensor([0.2383, 0.7773], grad_fn=<SliceBackward0>)\n",
      "iter 25800, loss: 9.280430793762207\n",
      "tensor(0.3573, grad_fn=<SelectBackward0>) tensor(0.4955, grad_fn=<SelectBackward0>) tensor([ 1.8929, -0.5101], grad_fn=<SliceBackward0>) tensor([ 0.4811, -1.2599], grad_fn=<SliceBackward0>)\n",
      "iter 25900, loss: 33.45918273925781\n",
      "tensor(-0.7444, grad_fn=<SelectBackward0>) tensor(0.0370, grad_fn=<SelectBackward0>) tensor([-0.0584, -0.4324], grad_fn=<SliceBackward0>) tensor([-1.1928, -0.7605], grad_fn=<SliceBackward0>)\n",
      "iter 26000, loss: 37.752010345458984\n",
      "tensor(-1.7864, grad_fn=<SelectBackward0>) tensor(0.6103, grad_fn=<SelectBackward0>) tensor([-1.8028,  1.4008], grad_fn=<SliceBackward0>) tensor([-0.6496, -0.1575], grad_fn=<SliceBackward0>)\n",
      "iter 26100, loss: 7.072415828704834\n",
      "tensor(1.7243, grad_fn=<SelectBackward0>) tensor(-0.6468, grad_fn=<SelectBackward0>) tensor([1.0892, 0.7660], grad_fn=<SliceBackward0>) tensor([-0.1547,  0.8765], grad_fn=<SliceBackward0>)\n",
      "iter 26200, loss: 60.00993347167969\n",
      "tensor(-0.2449, grad_fn=<SelectBackward0>) tensor(-1.1613, grad_fn=<SelectBackward0>) tensor([1.4242, 0.1143], grad_fn=<SliceBackward0>) tensor([-1.0010, -0.0235], grad_fn=<SliceBackward0>)\n",
      "iter 26300, loss: 4.773885250091553\n",
      "tensor(1.1248, grad_fn=<SelectBackward0>) tensor(-1.8793, grad_fn=<SelectBackward0>) tensor([-0.5716, -0.6170], grad_fn=<SliceBackward0>) tensor([-2.5839, -0.8505], grad_fn=<SliceBackward0>)\n",
      "iter 26400, loss: 9.206459045410156\n",
      "tensor(0.1153, grad_fn=<SelectBackward0>) tensor(1.0949, grad_fn=<SelectBackward0>) tensor([-0.8717, -1.6298], grad_fn=<SliceBackward0>) tensor([-1.4452,  0.0363], grad_fn=<SliceBackward0>)\n",
      "iter 26500, loss: 10.380622863769531\n",
      "tensor(1.9319, grad_fn=<SelectBackward0>) tensor(0.5240, grad_fn=<SelectBackward0>) tensor([-0.4321, -1.1244], grad_fn=<SliceBackward0>) tensor([0.4404, 0.2159], grad_fn=<SliceBackward0>)\n",
      "iter 26600, loss: 10.77068042755127\n",
      "tensor(1.1047, grad_fn=<SelectBackward0>) tensor(0.5179, grad_fn=<SelectBackward0>) tensor([-0.8426,  0.0493], grad_fn=<SliceBackward0>) tensor([-0.3364,  0.8486], grad_fn=<SliceBackward0>)\n",
      "iter 26700, loss: 21.0616512298584\n",
      "tensor(-0.2740, grad_fn=<SelectBackward0>) tensor(-0.2533, grad_fn=<SelectBackward0>) tensor([-0.4044,  0.4613], grad_fn=<SliceBackward0>) tensor([-1.2750, -1.8810], grad_fn=<SliceBackward0>)\n",
      "iter 26800, loss: 16.929353713989258\n",
      "tensor(-0.1961, grad_fn=<SelectBackward0>) tensor(0.9575, grad_fn=<SelectBackward0>) tensor([-0.6847,  0.3170], grad_fn=<SliceBackward0>) tensor([-0.2902,  0.4986], grad_fn=<SliceBackward0>)\n",
      "iter 26900, loss: 53.79733657836914\n",
      "tensor(-0.4972, grad_fn=<SelectBackward0>) tensor(0.1952, grad_fn=<SelectBackward0>) tensor([0.1014, 0.5914], grad_fn=<SliceBackward0>) tensor([ 1.1423, -1.7792], grad_fn=<SliceBackward0>)\n",
      "iter 27000, loss: 82.66187286376953\n",
      "tensor(-3.2046, grad_fn=<SelectBackward0>) tensor(-0.6284, grad_fn=<SelectBackward0>) tensor([ 0.3791, -2.4662], grad_fn=<SliceBackward0>) tensor([-0.9275, -0.7242], grad_fn=<SliceBackward0>)\n",
      "iter 27100, loss: 10.359447479248047\n",
      "tensor(0.8616, grad_fn=<SelectBackward0>) tensor(1.3562, grad_fn=<SelectBackward0>) tensor([-0.2446, -0.2182], grad_fn=<SliceBackward0>) tensor([-1.5295,  1.6172], grad_fn=<SliceBackward0>)\n",
      "iter 27200, loss: 4.772590160369873\n",
      "tensor(1.8124, grad_fn=<SelectBackward0>) tensor(1.1541, grad_fn=<SelectBackward0>) tensor([0.1934, 0.1119], grad_fn=<SliceBackward0>) tensor([ 0.7876, -1.1461], grad_fn=<SliceBackward0>)\n",
      "iter 27300, loss: 19.791797637939453\n",
      "tensor(1.9260, grad_fn=<SelectBackward0>) tensor(-1.3105, grad_fn=<SelectBackward0>) tensor([0.4938, 0.4079], grad_fn=<SliceBackward0>) tensor([ 1.0128, -0.5719], grad_fn=<SliceBackward0>)\n",
      "iter 27400, loss: 7.2501020431518555\n",
      "tensor(-0.6815, grad_fn=<SelectBackward0>) tensor(2.1918, grad_fn=<SelectBackward0>) tensor([ 0.1036, -0.6889], grad_fn=<SliceBackward0>) tensor([-0.4947,  0.0051], grad_fn=<SliceBackward0>)\n",
      "iter 27500, loss: 17.531898498535156\n",
      "tensor(0.2523, grad_fn=<SelectBackward0>) tensor(0.8296, grad_fn=<SelectBackward0>) tensor([0.4142, 0.0173], grad_fn=<SliceBackward0>) tensor([-0.1131,  0.7798], grad_fn=<SliceBackward0>)\n",
      "iter 27600, loss: 2.444322347640991\n",
      "tensor(-0.3544, grad_fn=<SelectBackward0>) tensor(0.1114, grad_fn=<SelectBackward0>) tensor([1.9192, 1.2670], grad_fn=<SliceBackward0>) tensor([0.2496, 1.1585], grad_fn=<SliceBackward0>)\n",
      "iter 27700, loss: 1.550422191619873\n",
      "tensor(1.3779, grad_fn=<SelectBackward0>) tensor(1.7567, grad_fn=<SelectBackward0>) tensor([ 0.2425, -0.2975], grad_fn=<SliceBackward0>) tensor([ 0.7953, -2.0084], grad_fn=<SliceBackward0>)\n",
      "iter 27800, loss: 13.911633491516113\n",
      "tensor(-0.2055, grad_fn=<SelectBackward0>) tensor(0.9749, grad_fn=<SelectBackward0>) tensor([0.9427, 0.5928], grad_fn=<SliceBackward0>) tensor([-1.2148,  2.4311], grad_fn=<SliceBackward0>)\n",
      "iter 27900, loss: 39.91265869140625\n",
      "tensor(-0.7642, grad_fn=<SelectBackward0>) tensor(-1.5855, grad_fn=<SelectBackward0>) tensor([-1.2682, -0.5776], grad_fn=<SliceBackward0>) tensor([ 0.7341, -1.3702], grad_fn=<SliceBackward0>)\n",
      "iter 28000, loss: 14.93411636352539\n",
      "tensor(0.0373, grad_fn=<SelectBackward0>) tensor(-0.1986, grad_fn=<SelectBackward0>) tensor([-0.4888,  1.4101], grad_fn=<SliceBackward0>) tensor([-1.1364,  0.8481], grad_fn=<SliceBackward0>)\n",
      "iter 28100, loss: 0.0713532492518425\n",
      "tensor(2.0404, grad_fn=<SelectBackward0>) tensor(-1.1904, grad_fn=<SelectBackward0>) tensor([-1.8200,  0.9418], grad_fn=<SliceBackward0>) tensor([-1.1305,  0.3314], grad_fn=<SliceBackward0>)\n",
      "iter 28200, loss: 35.24448013305664\n",
      "tensor(-2.1556, grad_fn=<SelectBackward0>) tensor(0.9190, grad_fn=<SelectBackward0>) tensor([-0.7375, -0.4715], grad_fn=<SliceBackward0>) tensor([-0.5854, -0.5187], grad_fn=<SliceBackward0>)\n",
      "iter 28300, loss: 29.462724685668945\n",
      "tensor(0.1750, grad_fn=<SelectBackward0>) tensor(0.8021, grad_fn=<SelectBackward0>) tensor([-1.8195, -0.3725], grad_fn=<SliceBackward0>) tensor([0.8724, 0.1846], grad_fn=<SliceBackward0>)\n",
      "iter 28400, loss: 14.56881046295166\n",
      "tensor(1.6714, grad_fn=<SelectBackward0>) tensor(-0.6226, grad_fn=<SelectBackward0>) tensor([-0.0875,  0.7520], grad_fn=<SliceBackward0>) tensor([0.1153, 0.4702], grad_fn=<SliceBackward0>)\n",
      "iter 28500, loss: 0.8219065070152283\n",
      "tensor(0.7037, grad_fn=<SelectBackward0>) tensor(0.0197, grad_fn=<SelectBackward0>) tensor([ 1.6731, -0.7824], grad_fn=<SliceBackward0>) tensor([ 1.3472, -0.3173], grad_fn=<SliceBackward0>)\n",
      "iter 28600, loss: 18.10700225830078\n",
      "tensor(0.1030, grad_fn=<SelectBackward0>) tensor(0.5660, grad_fn=<SelectBackward0>) tensor([ 0.9249, -0.3436], grad_fn=<SliceBackward0>) tensor([ 0.0269, -1.2563], grad_fn=<SliceBackward0>)\n",
      "iter 28700, loss: 53.29384994506836\n",
      "tensor(1.5447, grad_fn=<SelectBackward0>) tensor(-1.4607, grad_fn=<SelectBackward0>) tensor([1.7637, 1.8848], grad_fn=<SliceBackward0>) tensor([-0.5756,  0.0282], grad_fn=<SliceBackward0>)\n",
      "iter 28800, loss: 32.708702087402344\n",
      "tensor(1.2530, grad_fn=<SelectBackward0>) tensor(-0.4119, grad_fn=<SelectBackward0>) tensor([ 0.9884, -0.2497], grad_fn=<SliceBackward0>) tensor([-1.1030, -0.3018], grad_fn=<SliceBackward0>)\n",
      "iter 28900, loss: 4.448955059051514\n",
      "tensor(0.3923, grad_fn=<SelectBackward0>) tensor(-0.2783, grad_fn=<SelectBackward0>) tensor([1.6100, 1.6160], grad_fn=<SliceBackward0>) tensor([0.9684, 0.3443], grad_fn=<SliceBackward0>)\n",
      "iter 29000, loss: 16.49823570251465\n",
      "tensor(1.4014, grad_fn=<SelectBackward0>) tensor(0.1065, grad_fn=<SelectBackward0>) tensor([0.2247, 0.5334], grad_fn=<SliceBackward0>) tensor([-0.7361, -0.2923], grad_fn=<SliceBackward0>)\n",
      "iter 29100, loss: 5.518129825592041\n",
      "tensor(0.2253, grad_fn=<SelectBackward0>) tensor(1.9188, grad_fn=<SelectBackward0>) tensor([ 0.1891, -0.3438], grad_fn=<SliceBackward0>) tensor([-0.6579,  0.6518], grad_fn=<SliceBackward0>)\n",
      "iter 29200, loss: 2.1893746852874756\n",
      "tensor(-0.8247, grad_fn=<SelectBackward0>) tensor(1.7831, grad_fn=<SelectBackward0>) tensor([-2.9975, -0.3809], grad_fn=<SliceBackward0>) tensor([-1.1182,  0.5691], grad_fn=<SliceBackward0>)\n",
      "iter 29300, loss: 33.11796569824219\n",
      "tensor(-0.6954, grad_fn=<SelectBackward0>) tensor(-0.7340, grad_fn=<SelectBackward0>) tensor([0.4013, 0.0326], grad_fn=<SliceBackward0>) tensor([-0.1779,  0.2127], grad_fn=<SliceBackward0>)\n",
      "iter 29400, loss: 31.731321334838867\n",
      "tensor(0.9942, grad_fn=<SelectBackward0>) tensor(0.1411, grad_fn=<SelectBackward0>) tensor([-0.0346, -0.9471], grad_fn=<SliceBackward0>) tensor([-1.8988,  0.9925], grad_fn=<SliceBackward0>)\n",
      "iter 29500, loss: 14.139789581298828\n",
      "tensor(-1.0546, grad_fn=<SelectBackward0>) tensor(0.8223, grad_fn=<SelectBackward0>) tensor([ 1.9180, -0.5925], grad_fn=<SliceBackward0>) tensor([ 0.8084, -0.7349], grad_fn=<SliceBackward0>)\n",
      "iter 29600, loss: 33.71348571777344\n",
      "tensor(-0.1296, grad_fn=<SelectBackward0>) tensor(-0.2674, grad_fn=<SelectBackward0>) tensor([-0.8140,  0.1197], grad_fn=<SliceBackward0>) tensor([0.1448, 0.3523], grad_fn=<SliceBackward0>)\n",
      "iter 29700, loss: 39.45906448364258\n",
      "tensor(-0.3051, grad_fn=<SelectBackward0>) tensor(0.4597, grad_fn=<SelectBackward0>) tensor([ 1.5124, -0.2730], grad_fn=<SliceBackward0>) tensor([-0.4867,  0.2392], grad_fn=<SliceBackward0>)\n",
      "iter 29800, loss: 8.387947082519531\n",
      "tensor(0.1582, grad_fn=<SelectBackward0>) tensor(1.1848, grad_fn=<SelectBackward0>) tensor([-0.0948,  0.1730], grad_fn=<SliceBackward0>) tensor([0.9950, 0.1978], grad_fn=<SliceBackward0>)\n",
      "iter 29900, loss: 0.01904325559735298\n",
      "tensor(2.0234, grad_fn=<SelectBackward0>) tensor(0.7486, grad_fn=<SelectBackward0>) tensor([-0.0864, -1.0790], grad_fn=<SliceBackward0>) tensor([-0.1617, -2.1411], grad_fn=<SliceBackward0>)\n",
      "iter 30000, loss: 15.713299751281738\n",
      "tensor(0.0610, grad_fn=<SelectBackward0>) tensor(1.2860, grad_fn=<SelectBackward0>) tensor([ 0.2270, -0.1223], grad_fn=<SliceBackward0>) tensor([-0.3432,  0.3748], grad_fn=<SliceBackward0>)\n",
      "iter 30100, loss: 42.695125579833984\n",
      "tensor(-1.0510, grad_fn=<SelectBackward0>) tensor(2.1480, grad_fn=<SelectBackward0>) tensor([0.4289, 2.1330], grad_fn=<SliceBackward0>) tensor([-1.6287, -0.2781], grad_fn=<SliceBackward0>)\n",
      "iter 30200, loss: 8.17696762084961\n",
      "tensor(1.3076, grad_fn=<SelectBackward0>) tensor(0.5422, grad_fn=<SelectBackward0>) tensor([-0.9009, -0.0082], grad_fn=<SliceBackward0>) tensor([-0.5265,  0.3667], grad_fn=<SliceBackward0>)\n",
      "iter 30300, loss: 14.442421913146973\n",
      "tensor(0.3962, grad_fn=<SelectBackward0>) tensor(-0.6965, grad_fn=<SelectBackward0>) tensor([0.7727, 1.4616], grad_fn=<SliceBackward0>) tensor([-0.2035,  0.7161], grad_fn=<SliceBackward0>)\n",
      "iter 30400, loss: 47.506591796875\n",
      "tensor(-1.4450, grad_fn=<SelectBackward0>) tensor(-1.0384, grad_fn=<SelectBackward0>) tensor([0.6910, 0.2560], grad_fn=<SliceBackward0>) tensor([ 0.2321, -0.6082], grad_fn=<SliceBackward0>)\n",
      "iter 30500, loss: 15.237204551696777\n",
      "tensor(0.8715, grad_fn=<SelectBackward0>) tensor(-1.0081, grad_fn=<SelectBackward0>) tensor([-0.5197,  0.0860], grad_fn=<SliceBackward0>) tensor([-0.8425,  0.7423], grad_fn=<SliceBackward0>)\n",
      "iter 30600, loss: 45.64564895629883\n",
      "tensor(-0.2030, grad_fn=<SelectBackward0>) tensor(-0.6775, grad_fn=<SelectBackward0>) tensor([0.0606, 0.2191], grad_fn=<SliceBackward0>) tensor([-2.0060,  0.7370], grad_fn=<SliceBackward0>)\n",
      "iter 30700, loss: 1.4568688869476318\n",
      "tensor(1.0561, grad_fn=<SelectBackward0>) tensor(0.9129, grad_fn=<SelectBackward0>) tensor([2.8378, 0.1357], grad_fn=<SliceBackward0>) tensor([0.3694, 0.1683], grad_fn=<SliceBackward0>)\n",
      "iter 30800, loss: 50.1013298034668\n",
      "tensor(-0.9882, grad_fn=<SelectBackward0>) tensor(-0.8290, grad_fn=<SelectBackward0>) tensor([ 0.2863, -2.0664], grad_fn=<SliceBackward0>) tensor([ 0.2381, -0.2783], grad_fn=<SliceBackward0>)\n",
      "iter 30900, loss: 19.820587158203125\n",
      "tensor(-2.6771, grad_fn=<SelectBackward0>) tensor(0.6508, grad_fn=<SelectBackward0>) tensor([ 0.7145, -1.9294], grad_fn=<SliceBackward0>) tensor([ 0.5667, -1.4938], grad_fn=<SliceBackward0>)\n",
      "iter 31000, loss: 41.523075103759766\n",
      "tensor(0.6936, grad_fn=<SelectBackward0>) tensor(-0.1919, grad_fn=<SelectBackward0>) tensor([-1.7178, -0.0910], grad_fn=<SliceBackward0>) tensor([0.2659, 2.1229], grad_fn=<SliceBackward0>)\n",
      "iter 31100, loss: 21.247241973876953\n",
      "tensor(-0.7274, grad_fn=<SelectBackward0>) tensor(-0.0655, grad_fn=<SelectBackward0>) tensor([-0.4809,  1.0749], grad_fn=<SliceBackward0>) tensor([0.6942, 0.8671], grad_fn=<SliceBackward0>)\n",
      "iter 31200, loss: 5.791824817657471\n",
      "tensor(1.3772, grad_fn=<SelectBackward0>) tensor(1.4216, grad_fn=<SelectBackward0>) tensor([-0.3902,  1.5750], grad_fn=<SliceBackward0>) tensor([-0.2685, -0.6691], grad_fn=<SliceBackward0>)\n",
      "iter 31300, loss: 38.52839279174805\n",
      "tensor(0.9471, grad_fn=<SelectBackward0>) tensor(0.3189, grad_fn=<SelectBackward0>) tensor([-0.9498, -0.8710], grad_fn=<SliceBackward0>) tensor([ 2.5141, -0.3442], grad_fn=<SliceBackward0>)\n",
      "iter 31400, loss: 6.151026248931885\n",
      "tensor(-0.1820, grad_fn=<SelectBackward0>) tensor(1.7713, grad_fn=<SelectBackward0>) tensor([-1.4024, -0.1863], grad_fn=<SliceBackward0>) tensor([-0.7321, -0.8412], grad_fn=<SliceBackward0>)\n",
      "iter 31500, loss: 4.689859867095947\n",
      "tensor(-0.7163, grad_fn=<SelectBackward0>) tensor(2.1728, grad_fn=<SelectBackward0>) tensor([0.2311, 1.0150], grad_fn=<SliceBackward0>) tensor([-0.8185,  1.8410], grad_fn=<SliceBackward0>)\n",
      "iter 31600, loss: 15.20700740814209\n",
      "tensor(0.6688, grad_fn=<SelectBackward0>) tensor(-1.4271, grad_fn=<SelectBackward0>) tensor([-0.7113,  0.5368], grad_fn=<SliceBackward0>) tensor([ 0.7400, -0.5794], grad_fn=<SliceBackward0>)\n",
      "iter 31700, loss: 45.029293060302734\n",
      "tensor(0.9201, grad_fn=<SelectBackward0>) tensor(-0.7859, grad_fn=<SelectBackward0>) tensor([0.9947, 0.1481], grad_fn=<SliceBackward0>) tensor([-1.2079,  0.3265], grad_fn=<SliceBackward0>)\n",
      "iter 31800, loss: 34.46617126464844\n",
      "tensor(-0.5209, grad_fn=<SelectBackward0>) tensor(0.6544, grad_fn=<SelectBackward0>) tensor([1.2052, 0.4079], grad_fn=<SliceBackward0>) tensor([-1.0451, -0.2811], grad_fn=<SliceBackward0>)\n",
      "iter 31900, loss: 0.8470245599746704\n",
      "tensor(-0.9769, grad_fn=<SelectBackward0>) tensor(1.1387, grad_fn=<SelectBackward0>) tensor([1.4803, 1.5542], grad_fn=<SliceBackward0>) tensor([1.2620, 0.4703], grad_fn=<SliceBackward0>)\n",
      "iter 32000, loss: 9.908321380615234\n",
      "tensor(1.8930, grad_fn=<SelectBackward0>) tensor(-1.6849, grad_fn=<SelectBackward0>) tensor([0.4421, 0.3082], grad_fn=<SliceBackward0>) tensor([-0.6853,  0.4404], grad_fn=<SliceBackward0>)\n",
      "iter 32100, loss: 21.961790084838867\n",
      "tensor(-0.7996, grad_fn=<SelectBackward0>) tensor(0.8647, grad_fn=<SelectBackward0>) tensor([ 1.7873, -0.4088], grad_fn=<SliceBackward0>) tensor([0.9066, 1.4772], grad_fn=<SliceBackward0>)\n",
      "iter 32200, loss: 14.579190254211426\n",
      "tensor(0.6479, grad_fn=<SelectBackward0>) tensor(1.5030, grad_fn=<SelectBackward0>) tensor([1.3501, 0.7639], grad_fn=<SliceBackward0>) tensor([1.9424, 3.2697], grad_fn=<SliceBackward0>)\n",
      "iter 32300, loss: 48.859458923339844\n",
      "tensor(0.0496, grad_fn=<SelectBackward0>) tensor(-0.2705, grad_fn=<SelectBackward0>) tensor([0.6186, 1.6025], grad_fn=<SliceBackward0>) tensor([-0.6984, -0.3045], grad_fn=<SliceBackward0>)\n",
      "iter 32400, loss: 39.03476333618164\n",
      "tensor(0.9074, grad_fn=<SelectBackward0>) tensor(-0.2646, grad_fn=<SelectBackward0>) tensor([-0.0625,  1.1313], grad_fn=<SliceBackward0>) tensor([ 0.5984, -1.0516], grad_fn=<SliceBackward0>)\n",
      "iter 32500, loss: 29.46924591064453\n",
      "tensor(-1.0553, grad_fn=<SelectBackward0>) tensor(-0.0394, grad_fn=<SelectBackward0>) tensor([-0.5285, -0.4857], grad_fn=<SliceBackward0>) tensor([-1.1112, -1.3146], grad_fn=<SliceBackward0>)\n",
      "iter 32600, loss: 37.58261489868164\n",
      "tensor(0.2154, grad_fn=<SelectBackward0>) tensor(0.0748, grad_fn=<SelectBackward0>) tensor([1.0540, 2.0711], grad_fn=<SliceBackward0>) tensor([ 1.1418, -0.7036], grad_fn=<SliceBackward0>)\n",
      "iter 32700, loss: 13.134998321533203\n",
      "tensor(1.3854, grad_fn=<SelectBackward0>) tensor(-0.2003, grad_fn=<SelectBackward0>) tensor([-0.0217,  1.4251], grad_fn=<SliceBackward0>) tensor([1.1050, 0.4225], grad_fn=<SliceBackward0>)\n",
      "iter 32800, loss: 48.957244873046875\n",
      "tensor(-1.2347, grad_fn=<SelectBackward0>) tensor(0.8959, grad_fn=<SelectBackward0>) tensor([1.1075, 0.2620], grad_fn=<SliceBackward0>) tensor([-0.9698,  0.3916], grad_fn=<SliceBackward0>)\n",
      "iter 32900, loss: 20.03974151611328\n",
      "tensor(0.0944, grad_fn=<SelectBackward0>) tensor(0.4000, grad_fn=<SelectBackward0>) tensor([-0.0376,  0.2976], grad_fn=<SliceBackward0>) tensor([0.4743, 1.7107], grad_fn=<SliceBackward0>)\n",
      "iter 33000, loss: 47.39259719848633\n",
      "tensor(-0.0503, grad_fn=<SelectBackward0>) tensor(0.1725, grad_fn=<SelectBackward0>) tensor([-1.4349, -0.2222], grad_fn=<SliceBackward0>) tensor([ 0.9205, -1.0340], grad_fn=<SliceBackward0>)\n",
      "iter 33100, loss: 5.990216255187988\n",
      "tensor(0.8545, grad_fn=<SelectBackward0>) tensor(0.4651, grad_fn=<SelectBackward0>) tensor([0.2412, 1.0481], grad_fn=<SliceBackward0>) tensor([1.1367, 0.1677], grad_fn=<SliceBackward0>)\n",
      "iter 33200, loss: 16.088842391967773\n",
      "tensor(-0.4482, grad_fn=<SelectBackward0>) tensor(-0.2811, grad_fn=<SelectBackward0>) tensor([-0.8805,  0.8219], grad_fn=<SliceBackward0>) tensor([-0.6241,  0.5927], grad_fn=<SliceBackward0>)\n",
      "iter 33300, loss: 7.540621280670166\n",
      "tensor(-1.8934, grad_fn=<SelectBackward0>) tensor(-0.0248, grad_fn=<SelectBackward0>) tensor([-1.2283,  0.6030], grad_fn=<SliceBackward0>) tensor([-2.5248,  1.1122], grad_fn=<SliceBackward0>)\n",
      "iter 33400, loss: 7.661095142364502\n",
      "tensor(2.0035, grad_fn=<SelectBackward0>) tensor(0.3281, grad_fn=<SelectBackward0>) tensor([-0.6968, -0.2900], grad_fn=<SliceBackward0>) tensor([0.6811, 1.2466], grad_fn=<SliceBackward0>)\n",
      "iter 33500, loss: 36.646080017089844\n",
      "tensor(-0.8220, grad_fn=<SelectBackward0>) tensor(-0.9690, grad_fn=<SelectBackward0>) tensor([-1.3176,  3.5821], grad_fn=<SliceBackward0>) tensor([-1.0592,  0.4001], grad_fn=<SliceBackward0>)\n",
      "iter 33600, loss: 5.375172138214111\n",
      "tensor(-0.1441, grad_fn=<SelectBackward0>) tensor(1.2651, grad_fn=<SelectBackward0>) tensor([-0.4795,  0.1447], grad_fn=<SliceBackward0>) tensor([-1.7639, -0.2589], grad_fn=<SliceBackward0>)\n",
      "iter 33700, loss: 25.381467819213867\n",
      "tensor(0.2221, grad_fn=<SelectBackward0>) tensor(0.4517, grad_fn=<SelectBackward0>) tensor([-0.9399,  1.0025], grad_fn=<SliceBackward0>) tensor([0.4580, 0.1468], grad_fn=<SliceBackward0>)\n",
      "iter 33800, loss: 8.800487518310547\n",
      "tensor(1.7095, grad_fn=<SelectBackward0>) tensor(1.1442, grad_fn=<SelectBackward0>) tensor([-0.1345, -0.3036], grad_fn=<SliceBackward0>) tensor([1.0550, 1.2664], grad_fn=<SliceBackward0>)\n",
      "iter 33900, loss: 11.2455415725708\n",
      "tensor(-0.4910, grad_fn=<SelectBackward0>) tensor(2.1376, grad_fn=<SelectBackward0>) tensor([-1.9099,  1.0185], grad_fn=<SliceBackward0>) tensor([0.3177, 1.1225], grad_fn=<SliceBackward0>)\n",
      "iter 34000, loss: 38.32139205932617\n",
      "tensor(-1.6559, grad_fn=<SelectBackward0>) tensor(1.0885, grad_fn=<SelectBackward0>) tensor([-1.5476, -0.4415], grad_fn=<SliceBackward0>) tensor([ 0.2219, -0.9380], grad_fn=<SliceBackward0>)\n",
      "iter 34100, loss: 8.921589851379395\n",
      "tensor(0.9624, grad_fn=<SelectBackward0>) tensor(1.0369, grad_fn=<SelectBackward0>) tensor([0.2871, 0.4450], grad_fn=<SliceBackward0>) tensor([-0.2869,  0.5749], grad_fn=<SliceBackward0>)\n",
      "iter 34200, loss: 21.287784576416016\n",
      "tensor(0.2361, grad_fn=<SelectBackward0>) tensor(0.2955, grad_fn=<SelectBackward0>) tensor([-1.4512,  1.2193], grad_fn=<SliceBackward0>) tensor([-0.7495, -0.5279], grad_fn=<SliceBackward0>)\n",
      "iter 34300, loss: 26.42095947265625\n",
      "tensor(-0.9845, grad_fn=<SelectBackward0>) tensor(2.3137, grad_fn=<SelectBackward0>) tensor([1.1344, 0.2267], grad_fn=<SliceBackward0>) tensor([-0.7231, -0.7158], grad_fn=<SliceBackward0>)\n",
      "iter 34400, loss: 43.43341064453125\n",
      "tensor(-1.5777, grad_fn=<SelectBackward0>) tensor(0.5640, grad_fn=<SelectBackward0>) tensor([-0.7615,  0.8368], grad_fn=<SliceBackward0>) tensor([0.3593, 0.1960], grad_fn=<SliceBackward0>)\n",
      "iter 34500, loss: 56.194400787353516\n",
      "tensor(0.5335, grad_fn=<SelectBackward0>) tensor(-1.2381, grad_fn=<SelectBackward0>) tensor([ 0.6107, -0.4928], grad_fn=<SliceBackward0>) tensor([-1.5442,  1.3647], grad_fn=<SliceBackward0>)\n",
      "iter 34600, loss: 15.864992141723633\n",
      "tensor(0.0214, grad_fn=<SelectBackward0>) tensor(1.0483, grad_fn=<SelectBackward0>) tensor([-1.1290,  0.2003], grad_fn=<SliceBackward0>) tensor([-0.0784,  0.9957], grad_fn=<SliceBackward0>)\n",
      "iter 34700, loss: 0.5118283629417419\n",
      "tensor(-0.9774, grad_fn=<SelectBackward0>) tensor(2.2520, grad_fn=<SelectBackward0>) tensor([ 1.6354, -0.9108], grad_fn=<SliceBackward0>) tensor([ 1.5504, -0.6528], grad_fn=<SliceBackward0>)\n",
      "iter 34800, loss: 14.98090934753418\n",
      "tensor(0.8903, grad_fn=<SelectBackward0>) tensor(-0.4587, grad_fn=<SelectBackward0>) tensor([-1.5094, -0.0231], grad_fn=<SliceBackward0>) tensor([-0.7033,  0.2467], grad_fn=<SliceBackward0>)\n",
      "iter 34900, loss: 7.701754093170166\n",
      "tensor(0.2814, grad_fn=<SelectBackward0>) tensor(2.0708, grad_fn=<SelectBackward0>) tensor([1.1138, 0.5542], grad_fn=<SliceBackward0>) tensor([ 1.1085, -1.6925], grad_fn=<SliceBackward0>)\n",
      "iter 35000, loss: 25.41008186340332\n",
      "tensor(-2.5076, grad_fn=<SelectBackward0>) tensor(1.6269, grad_fn=<SelectBackward0>) tensor([-0.9987, -0.2611], grad_fn=<SliceBackward0>) tensor([-0.1025, -0.1866], grad_fn=<SliceBackward0>)\n",
      "iter 35100, loss: 12.37789535522461\n",
      "tensor(1.3296, grad_fn=<SelectBackward0>) tensor(-0.2103, grad_fn=<SelectBackward0>) tensor([-0.7013,  1.2457], grad_fn=<SliceBackward0>) tensor([-0.5991, -0.5762], grad_fn=<SliceBackward0>)\n",
      "iter 35200, loss: 16.58325958251953\n",
      "tensor(1.1240, grad_fn=<SelectBackward0>) tensor(-1.3950, grad_fn=<SelectBackward0>) tensor([-0.9056, -1.3059], grad_fn=<SliceBackward0>) tensor([-1.8685, -0.0999], grad_fn=<SliceBackward0>)\n",
      "iter 35300, loss: 22.38666343688965\n",
      "tensor(0.4345, grad_fn=<SelectBackward0>) tensor(-0.2884, grad_fn=<SelectBackward0>) tensor([0.0981, 0.6686], grad_fn=<SliceBackward0>) tensor([-1.1887,  1.0435], grad_fn=<SliceBackward0>)\n",
      "iter 35400, loss: 8.600529670715332\n",
      "tensor(0.0374, grad_fn=<SelectBackward0>) tensor(-0.0775, grad_fn=<SelectBackward0>) tensor([-0.6679, -1.9042], grad_fn=<SliceBackward0>) tensor([-0.0701, -0.2190], grad_fn=<SliceBackward0>)\n",
      "iter 35500, loss: 30.231143951416016\n",
      "tensor(-1.3659, grad_fn=<SelectBackward0>) tensor(0.4061, grad_fn=<SelectBackward0>) tensor([ 0.2490, -0.7731], grad_fn=<SliceBackward0>) tensor([-0.0991, -1.1677], grad_fn=<SliceBackward0>)\n",
      "iter 35600, loss: 12.710516929626465\n",
      "tensor(0.8474, grad_fn=<SelectBackward0>) tensor(0.7597, grad_fn=<SelectBackward0>) tensor([0.8980, 1.4410], grad_fn=<SliceBackward0>) tensor([-0.1309,  0.2064], grad_fn=<SliceBackward0>)\n",
      "iter 35700, loss: 8.995471000671387\n",
      "tensor(0.7715, grad_fn=<SelectBackward0>) tensor(-0.4865, grad_fn=<SelectBackward0>) tensor([-1.0586, -1.0728], grad_fn=<SliceBackward0>) tensor([ 0.2057, -0.1825], grad_fn=<SliceBackward0>)\n",
      "iter 35800, loss: 16.29058074951172\n",
      "tensor(0.4641, grad_fn=<SelectBackward0>) tensor(0.3060, grad_fn=<SelectBackward0>) tensor([-1.0061, -0.4767], grad_fn=<SliceBackward0>) tensor([-0.8323,  0.6329], grad_fn=<SliceBackward0>)\n",
      "iter 35900, loss: 0.07971847057342529\n",
      "tensor(1.6657, grad_fn=<SelectBackward0>) tensor(1.6155, grad_fn=<SelectBackward0>) tensor([0.8990, 0.6833], grad_fn=<SliceBackward0>) tensor([0.7736, 1.1406], grad_fn=<SliceBackward0>)\n",
      "iter 36000, loss: 35.60090637207031\n",
      "tensor(0.1591, grad_fn=<SelectBackward0>) tensor(-0.0684, grad_fn=<SelectBackward0>) tensor([-1.2636,  0.5107], grad_fn=<SliceBackward0>) tensor([-0.2275, -1.2806], grad_fn=<SliceBackward0>)\n",
      "iter 36100, loss: 32.120750427246094\n",
      "tensor(0.0665, grad_fn=<SelectBackward0>) tensor(-0.2507, grad_fn=<SelectBackward0>) tensor([-0.7210, -1.0016], grad_fn=<SliceBackward0>) tensor([ 0.1795, -0.0570], grad_fn=<SliceBackward0>)\n",
      "iter 36200, loss: 12.190200805664062\n",
      "tensor(0.7709, grad_fn=<SelectBackward0>) tensor(0.6494, grad_fn=<SelectBackward0>) tensor([0.2519, 0.0330], grad_fn=<SliceBackward0>) tensor([2.0026, 0.1759], grad_fn=<SliceBackward0>)\n",
      "iter 36300, loss: 21.45663833618164\n",
      "tensor(1.4858, grad_fn=<SelectBackward0>) tensor(0.5212, grad_fn=<SelectBackward0>) tensor([-1.3386, -0.3500], grad_fn=<SliceBackward0>) tensor([ 0.9590, -0.4085], grad_fn=<SliceBackward0>)\n",
      "iter 36400, loss: 28.591461181640625\n",
      "tensor(0.0633, grad_fn=<SelectBackward0>) tensor(-0.6469, grad_fn=<SelectBackward0>) tensor([-0.4253, -0.9210], grad_fn=<SliceBackward0>) tensor([-1.2979,  0.7922], grad_fn=<SliceBackward0>)\n",
      "iter 36500, loss: 16.54410171508789\n",
      "tensor(1.4907, grad_fn=<SelectBackward0>) tensor(0.5406, grad_fn=<SelectBackward0>) tensor([ 0.9206, -0.1600], grad_fn=<SliceBackward0>) tensor([-0.7808,  0.4071], grad_fn=<SliceBackward0>)\n",
      "iter 36600, loss: 7.9111328125\n",
      "tensor(2.4790, grad_fn=<SelectBackward0>) tensor(-0.4067, grad_fn=<SelectBackward0>) tensor([ 0.1110, -0.5566], grad_fn=<SliceBackward0>) tensor([ 0.3007, -0.4038], grad_fn=<SliceBackward0>)\n",
      "iter 36700, loss: 37.3052978515625\n",
      "tensor(-1.0899, grad_fn=<SelectBackward0>) tensor(2.0368, grad_fn=<SelectBackward0>) tensor([-0.3608, -1.5300], grad_fn=<SliceBackward0>) tensor([0.4445, 0.7698], grad_fn=<SliceBackward0>)\n",
      "iter 36800, loss: 20.60540008544922\n",
      "tensor(-1.3879, grad_fn=<SelectBackward0>) tensor(0.7589, grad_fn=<SelectBackward0>) tensor([-0.3110,  1.0825], grad_fn=<SliceBackward0>) tensor([-1.4641, -0.7469], grad_fn=<SliceBackward0>)\n",
      "iter 36900, loss: 97.86522674560547\n",
      "tensor(-0.3240, grad_fn=<SelectBackward0>) tensor(-0.2282, grad_fn=<SelectBackward0>) tensor([-1.2476, -0.3060], grad_fn=<SliceBackward0>) tensor([1.9059, 0.3286], grad_fn=<SliceBackward0>)\n",
      "iter 37000, loss: 8.133516311645508\n",
      "tensor(0.9758, grad_fn=<SelectBackward0>) tensor(0.2462, grad_fn=<SelectBackward0>) tensor([ 0.1034, -0.2040], grad_fn=<SliceBackward0>) tensor([-0.1193, -0.3002], grad_fn=<SliceBackward0>)\n",
      "iter 37100, loss: 20.074228286743164\n",
      "tensor(0.4878, grad_fn=<SelectBackward0>) tensor(-0.6401, grad_fn=<SelectBackward0>) tensor([-0.0358,  0.5081], grad_fn=<SliceBackward0>) tensor([ 0.7672, -0.0822], grad_fn=<SliceBackward0>)\n",
      "iter 37200, loss: 11.486207008361816\n",
      "tensor(0.9510, grad_fn=<SelectBackward0>) tensor(1.3024, grad_fn=<SelectBackward0>) tensor([0.5007, 0.3841], grad_fn=<SliceBackward0>) tensor([ 0.2375, -1.2539], grad_fn=<SliceBackward0>)\n",
      "iter 37300, loss: 37.116973876953125\n",
      "tensor(-0.7395, grad_fn=<SelectBackward0>) tensor(-0.0381, grad_fn=<SelectBackward0>) tensor([-1.9973, -0.4268], grad_fn=<SliceBackward0>) tensor([-0.3035,  1.7545], grad_fn=<SliceBackward0>)\n",
      "iter 37400, loss: 93.33870697021484\n",
      "tensor(1.1261, grad_fn=<SelectBackward0>) tensor(-1.3834, grad_fn=<SelectBackward0>) tensor([-0.6681,  0.2417], grad_fn=<SliceBackward0>) tensor([2.9088, 1.1863], grad_fn=<SliceBackward0>)\n",
      "iter 37500, loss: 26.688724517822266\n",
      "tensor(0.2290, grad_fn=<SelectBackward0>) tensor(-0.8429, grad_fn=<SelectBackward0>) tensor([ 0.6688, -0.8412], grad_fn=<SliceBackward0>) tensor([-0.4628, -1.5984], grad_fn=<SliceBackward0>)\n",
      "iter 37600, loss: 41.83720397949219\n",
      "tensor(-1.0532, grad_fn=<SelectBackward0>) tensor(0.3004, grad_fn=<SelectBackward0>) tensor([0.0618, 0.2263], grad_fn=<SliceBackward0>) tensor([-1.7288,  0.3244], grad_fn=<SliceBackward0>)\n",
      "iter 37700, loss: 13.930217742919922\n",
      "tensor(1.0502, grad_fn=<SelectBackward0>) tensor(-0.3760, grad_fn=<SelectBackward0>) tensor([0.3544, 0.7817], grad_fn=<SliceBackward0>) tensor([ 1.7646, -0.7096], grad_fn=<SliceBackward0>)\n",
      "iter 37800, loss: 7.973406791687012\n",
      "tensor(1.3868, grad_fn=<SelectBackward0>) tensor(-0.2445, grad_fn=<SelectBackward0>) tensor([ 0.2837, -0.1417], grad_fn=<SliceBackward0>) tensor([ 0.4235, -0.3380], grad_fn=<SliceBackward0>)\n",
      "iter 37900, loss: 36.1374626159668\n",
      "tensor(-0.1116, grad_fn=<SelectBackward0>) tensor(0.0331, grad_fn=<SelectBackward0>) tensor([1.1838, 0.1478], grad_fn=<SliceBackward0>) tensor([-0.4355,  0.4831], grad_fn=<SliceBackward0>)\n",
      "iter 38000, loss: 7.970944881439209\n",
      "tensor(0.0784, grad_fn=<SelectBackward0>) tensor(1.3111, grad_fn=<SelectBackward0>) tensor([-0.3605,  1.4481], grad_fn=<SliceBackward0>) tensor([0.1827, 0.0655], grad_fn=<SliceBackward0>)\n",
      "iter 38100, loss: 0.16632677614688873\n",
      "tensor(-0.5696, grad_fn=<SelectBackward0>) tensor(1.3042, grad_fn=<SelectBackward0>) tensor([-1.5918,  0.2030], grad_fn=<SliceBackward0>) tensor([-1.7828, -1.2064], grad_fn=<SliceBackward0>)\n",
      "iter 38200, loss: 7.202168941497803\n",
      "tensor(1.8406, grad_fn=<SelectBackward0>) tensor(0.5556, grad_fn=<SelectBackward0>) tensor([ 1.0164, -1.1575], grad_fn=<SliceBackward0>) tensor([-0.4273,  0.3338], grad_fn=<SliceBackward0>)\n",
      "iter 38300, loss: 53.40013122558594\n",
      "tensor(-0.9258, grad_fn=<SelectBackward0>) tensor(-0.5616, grad_fn=<SelectBackward0>) tensor([ 0.6227, -0.1857], grad_fn=<SliceBackward0>) tensor([-1.4920,  0.4879], grad_fn=<SliceBackward0>)\n",
      "iter 38400, loss: 48.583003997802734\n",
      "tensor(0.2944, grad_fn=<SelectBackward0>) tensor(-1.2715, grad_fn=<SelectBackward0>) tensor([-0.3711,  0.2144], grad_fn=<SliceBackward0>) tensor([-0.2879, -1.6767], grad_fn=<SliceBackward0>)\n",
      "iter 38500, loss: 28.43863868713379\n",
      "tensor(0.4128, grad_fn=<SelectBackward0>) tensor(0.1364, grad_fn=<SelectBackward0>) tensor([1.6624, 0.0359], grad_fn=<SliceBackward0>) tensor([-0.7584,  0.3177], grad_fn=<SliceBackward0>)\n",
      "iter 38600, loss: 35.00431442260742\n",
      "tensor(-1.0200, grad_fn=<SelectBackward0>) tensor(-0.0525, grad_fn=<SelectBackward0>) tensor([-0.0275, -0.5503], grad_fn=<SliceBackward0>) tensor([-0.3413, -0.9463], grad_fn=<SliceBackward0>)\n",
      "iter 38700, loss: 19.484891891479492\n",
      "tensor(-1.2446, grad_fn=<SelectBackward0>) tensor(1.2976, grad_fn=<SelectBackward0>) tensor([0.8786, 0.1460], grad_fn=<SliceBackward0>) tensor([ 1.0376, -0.3154], grad_fn=<SliceBackward0>)\n",
      "iter 38800, loss: 15.794947624206543\n",
      "tensor(-1.1577, grad_fn=<SelectBackward0>) tensor(1.5342, grad_fn=<SelectBackward0>) tensor([0.6383, 1.4426], grad_fn=<SliceBackward0>) tensor([-0.2329,  0.8299], grad_fn=<SliceBackward0>)\n",
      "iter 38900, loss: 39.16508102416992\n",
      "tensor(1.3798, grad_fn=<SelectBackward0>) tensor(-1.1360, grad_fn=<SelectBackward0>) tensor([-0.7905, -0.0999], grad_fn=<SliceBackward0>) tensor([1.5094, 1.8304], grad_fn=<SliceBackward0>)\n",
      "iter 39000, loss: 11.127358436584473\n",
      "tensor(0.5804, grad_fn=<SelectBackward0>) tensor(1.7728, grad_fn=<SelectBackward0>) tensor([0.4613, 1.0910], grad_fn=<SliceBackward0>) tensor([ 1.1583, -0.7868], grad_fn=<SliceBackward0>)\n",
      "iter 39100, loss: 8.6490478515625\n",
      "tensor(-0.1046, grad_fn=<SelectBackward0>) tensor(0.1875, grad_fn=<SelectBackward0>) tensor([0.0852, 0.2153], grad_fn=<SliceBackward0>) tensor([0.3945, 0.3697], grad_fn=<SliceBackward0>)\n",
      "iter 39200, loss: 29.97039794921875\n",
      "tensor(-0.5916, grad_fn=<SelectBackward0>) tensor(0.5978, grad_fn=<SelectBackward0>) tensor([ 0.7716, -1.0683], grad_fn=<SliceBackward0>) tensor([-0.7750, -0.5964], grad_fn=<SliceBackward0>)\n",
      "iter 39300, loss: 28.16063690185547\n",
      "tensor(-1.4401, grad_fn=<SelectBackward0>) tensor(1.1157, grad_fn=<SelectBackward0>) tensor([ 1.3308, -0.1252], grad_fn=<SliceBackward0>) tensor([0.3502, 0.2796], grad_fn=<SliceBackward0>)\n",
      "iter 39400, loss: 21.368186950683594\n",
      "tensor(-1.5996, grad_fn=<SelectBackward0>) tensor(1.0086, grad_fn=<SelectBackward0>) tensor([-0.1248,  1.1886], grad_fn=<SliceBackward0>) tensor([-0.1773,  0.2236], grad_fn=<SliceBackward0>)\n",
      "iter 39500, loss: 1.4257652759552002\n",
      "tensor(0.4122, grad_fn=<SelectBackward0>) tensor(0.5418, grad_fn=<SelectBackward0>) tensor([0.3649, 2.1599], grad_fn=<SliceBackward0>) tensor([1.6532, 1.1597], grad_fn=<SliceBackward0>)\n",
      "iter 39600, loss: 24.09952163696289\n",
      "tensor(-0.0870, grad_fn=<SelectBackward0>) tensor(0.3156, grad_fn=<SelectBackward0>) tensor([0.6281, 1.1622], grad_fn=<SliceBackward0>) tensor([0.1405, 0.1220], grad_fn=<SliceBackward0>)\n",
      "iter 39700, loss: 44.182682037353516\n",
      "tensor(-1.4634, grad_fn=<SelectBackward0>) tensor(0.0311, grad_fn=<SelectBackward0>) tensor([ 1.1154, -0.2504], grad_fn=<SliceBackward0>) tensor([ 0.1320, -0.3659], grad_fn=<SliceBackward0>)\n",
      "iter 39800, loss: 38.079402923583984\n",
      "tensor(-1.1997, grad_fn=<SelectBackward0>) tensor(0.7293, grad_fn=<SelectBackward0>) tensor([-2.5688, -0.9721], grad_fn=<SliceBackward0>) tensor([-0.6918,  1.1150], grad_fn=<SliceBackward0>)\n",
      "iter 39900, loss: 17.704471588134766\n",
      "tensor(0.3665, grad_fn=<SelectBackward0>) tensor(0.0777, grad_fn=<SelectBackward0>) tensor([1.5670, 0.8892], grad_fn=<SliceBackward0>) tensor([ 0.9229, -0.6346], grad_fn=<SliceBackward0>)\n",
      "iter 40000, loss: 16.199262619018555\n",
      "tensor(0.9537, grad_fn=<SelectBackward0>) tensor(0.2036, grad_fn=<SelectBackward0>) tensor([-0.8785, -0.0050], grad_fn=<SliceBackward0>) tensor([-0.2673,  1.5014], grad_fn=<SliceBackward0>)\n",
      "iter 40100, loss: 32.05462646484375\n",
      "tensor(-0.3542, grad_fn=<SelectBackward0>) tensor(-0.1558, grad_fn=<SelectBackward0>) tensor([1.4341, 1.3138], grad_fn=<SliceBackward0>) tensor([-0.3722, -0.6356], grad_fn=<SliceBackward0>)\n",
      "iter 40200, loss: 5.472464561462402\n",
      "tensor(0.3525, grad_fn=<SelectBackward0>) tensor(0.8238, grad_fn=<SelectBackward0>) tensor([ 1.4883, -1.0682], grad_fn=<SliceBackward0>) tensor([0.9299, 0.5593], grad_fn=<SliceBackward0>)\n",
      "iter 40300, loss: 0.7698849439620972\n",
      "tensor(1.3979, grad_fn=<SelectBackward0>) tensor(1.2298, grad_fn=<SelectBackward0>) tensor([ 0.7087, -0.0549], grad_fn=<SliceBackward0>) tensor([ 0.7665, -0.1439], grad_fn=<SliceBackward0>)\n",
      "iter 40400, loss: 45.50661087036133\n",
      "tensor(-0.5671, grad_fn=<SelectBackward0>) tensor(-1.6322, grad_fn=<SelectBackward0>) tensor([-1.9060,  0.2775], grad_fn=<SliceBackward0>) tensor([-0.0458,  1.1895], grad_fn=<SliceBackward0>)\n",
      "iter 40500, loss: 25.960281372070312\n",
      "tensor(0.9071, grad_fn=<SelectBackward0>) tensor(0.9555, grad_fn=<SelectBackward0>) tensor([-0.7803, -1.4159], grad_fn=<SliceBackward0>) tensor([0.7467, 0.5421], grad_fn=<SliceBackward0>)\n",
      "iter 40600, loss: 0.7896593809127808\n",
      "tensor(-0.4271, grad_fn=<SelectBackward0>) tensor(1.8501, grad_fn=<SelectBackward0>) tensor([ 0.2065, -1.0276], grad_fn=<SliceBackward0>) tensor([ 0.4394, -1.6598], grad_fn=<SliceBackward0>)\n",
      "iter 40700, loss: 23.884441375732422\n",
      "tensor(-0.4518, grad_fn=<SelectBackward0>) tensor(-1.2399, grad_fn=<SelectBackward0>) tensor([-1.2345,  0.3671], grad_fn=<SliceBackward0>) tensor([-2.0793, -0.1167], grad_fn=<SliceBackward0>)\n",
      "iter 40800, loss: 13.70926284790039\n",
      "tensor(1.1784, grad_fn=<SelectBackward0>) tensor(0.1249, grad_fn=<SelectBackward0>) tensor([-0.4189,  1.4678], grad_fn=<SliceBackward0>) tensor([-1.1674, -0.0522], grad_fn=<SliceBackward0>)\n",
      "iter 40900, loss: 15.966937065124512\n",
      "tensor(0.0831, grad_fn=<SelectBackward0>) tensor(1.4286, grad_fn=<SelectBackward0>) tensor([-2.4590, -0.0344], grad_fn=<SliceBackward0>) tensor([ 0.3386, -0.4247], grad_fn=<SliceBackward0>)\n",
      "iter 41000, loss: 11.847392082214355\n",
      "tensor(1.4906, grad_fn=<SelectBackward0>) tensor(-0.8814, grad_fn=<SelectBackward0>) tensor([ 1.3282, -0.0176], grad_fn=<SliceBackward0>) tensor([ 0.9823, -0.9597], grad_fn=<SliceBackward0>)\n",
      "iter 41100, loss: 72.12267303466797\n",
      "tensor(-0.8875, grad_fn=<SelectBackward0>) tensor(-1.0044, grad_fn=<SelectBackward0>) tensor([ 1.1465, -0.3371], grad_fn=<SliceBackward0>) tensor([0.5357, 2.1489], grad_fn=<SliceBackward0>)\n",
      "iter 41200, loss: 10.059541702270508\n",
      "tensor(1.0326, grad_fn=<SelectBackward0>) tensor(0.6740, grad_fn=<SelectBackward0>) tensor([-0.1356, -0.9489], grad_fn=<SliceBackward0>) tensor([-1.1834, -0.2489], grad_fn=<SliceBackward0>)\n",
      "iter 41300, loss: 31.82096290588379\n",
      "tensor(-0.6017, grad_fn=<SelectBackward0>) tensor(-0.2743, grad_fn=<SelectBackward0>) tensor([0.6623, 0.6781], grad_fn=<SliceBackward0>) tensor([-0.0709,  1.0539], grad_fn=<SliceBackward0>)\n",
      "iter 41400, loss: 30.697656631469727\n",
      "tensor(-0.3387, grad_fn=<SelectBackward0>) tensor(0.1257, grad_fn=<SelectBackward0>) tensor([0.6667, 0.5726], grad_fn=<SliceBackward0>) tensor([-0.2318,  0.2628], grad_fn=<SliceBackward0>)\n",
      "iter 41500, loss: 13.217499732971191\n",
      "tensor(0.1835, grad_fn=<SelectBackward0>) tensor(0.3702, grad_fn=<SelectBackward0>) tensor([ 0.2380, -0.2073], grad_fn=<SliceBackward0>) tensor([-0.4834, -0.5815], grad_fn=<SliceBackward0>)\n",
      "iter 41600, loss: 13.026956558227539\n",
      "tensor(-0.0185, grad_fn=<SelectBackward0>) tensor(1.6006, grad_fn=<SelectBackward0>) tensor([-0.5216,  0.3183], grad_fn=<SliceBackward0>) tensor([-0.0069, -0.0706], grad_fn=<SliceBackward0>)\n",
      "iter 41700, loss: 7.336711883544922\n",
      "tensor(1.4779, grad_fn=<SelectBackward0>) tensor(1.4886, grad_fn=<SelectBackward0>) tensor([ 0.9543, -1.3816], grad_fn=<SliceBackward0>) tensor([0.3943, 0.5502], grad_fn=<SliceBackward0>)\n",
      "iter 41800, loss: 14.377050399780273\n",
      "tensor(0.0839, grad_fn=<SelectBackward0>) tensor(-0.6292, grad_fn=<SelectBackward0>) tensor([-1.3442, -0.5310], grad_fn=<SliceBackward0>) tensor([-1.7139,  0.0966], grad_fn=<SliceBackward0>)\n",
      "iter 41900, loss: 15.20808219909668\n",
      "tensor(0.6876, grad_fn=<SelectBackward0>) tensor(-0.0103, grad_fn=<SelectBackward0>) tensor([0.8322, 0.4261], grad_fn=<SliceBackward0>) tensor([0.6984, 0.2279], grad_fn=<SliceBackward0>)\n",
      "iter 42000, loss: 1.3691190481185913\n",
      "tensor(0.6687, grad_fn=<SelectBackward0>) tensor(1.2993, grad_fn=<SelectBackward0>) tensor([1.1283, 0.3160], grad_fn=<SliceBackward0>) tensor([-0.1109,  0.2177], grad_fn=<SliceBackward0>)\n",
      "iter 42100, loss: 0.049303121864795685\n",
      "tensor(-0.1519, grad_fn=<SelectBackward0>) tensor(-1.2960, grad_fn=<SelectBackward0>) tensor([1.1175, 2.1050], grad_fn=<SliceBackward0>) tensor([1.2111, 2.0199], grad_fn=<SliceBackward0>)\n",
      "iter 42200, loss: 6.261632919311523\n",
      "tensor(1.0728, grad_fn=<SelectBackward0>) tensor(1.7566, grad_fn=<SelectBackward0>) tensor([-1.6122, -0.5392], grad_fn=<SliceBackward0>) tensor([ 0.2283, -0.5593], grad_fn=<SliceBackward0>)\n",
      "iter 42300, loss: 7.323949337005615\n",
      "tensor(0.0379, grad_fn=<SelectBackward0>) tensor(-0.7240, grad_fn=<SelectBackward0>) tensor([ 1.6057, -0.3549], grad_fn=<SliceBackward0>) tensor([1.8267, 1.2682], grad_fn=<SliceBackward0>)\n",
      "iter 42400, loss: 0.5168270468711853\n",
      "tensor(1.0478, grad_fn=<SelectBackward0>) tensor(0.0738, grad_fn=<SelectBackward0>) tensor([1.0040, 1.8673], grad_fn=<SliceBackward0>) tensor([-0.3214, -0.2247], grad_fn=<SliceBackward0>)\n",
      "iter 42500, loss: 43.10490036010742\n",
      "tensor(-0.0986, grad_fn=<SelectBackward0>) tensor(0.5513, grad_fn=<SelectBackward0>) tensor([ 0.7165, -0.8127], grad_fn=<SliceBackward0>) tensor([-1.2072,  0.5247], grad_fn=<SliceBackward0>)\n",
      "iter 42600, loss: 16.2200927734375\n",
      "tensor(-0.5720, grad_fn=<SelectBackward0>) tensor(1.2324, grad_fn=<SelectBackward0>) tensor([0.4245, 1.6611], grad_fn=<SliceBackward0>) tensor([-0.2475, -0.1025], grad_fn=<SliceBackward0>)\n",
      "iter 42700, loss: 43.992919921875\n",
      "tensor(0.1072, grad_fn=<SelectBackward0>) tensor(-0.4458, grad_fn=<SelectBackward0>) tensor([-0.1320,  0.9396], grad_fn=<SliceBackward0>) tensor([ 0.3818, -0.7596], grad_fn=<SliceBackward0>)\n",
      "iter 42800, loss: 24.92369842529297\n",
      "tensor(-0.4384, grad_fn=<SelectBackward0>) tensor(-0.0408, grad_fn=<SelectBackward0>) tensor([ 0.0256, -0.6397], grad_fn=<SliceBackward0>) tensor([ 1.2049, -1.7602], grad_fn=<SliceBackward0>)\n",
      "iter 42900, loss: 32.258872985839844\n",
      "tensor(-1.4406, grad_fn=<SelectBackward0>) tensor(1.4619, grad_fn=<SelectBackward0>) tensor([ 0.8870, -0.4099], grad_fn=<SliceBackward0>) tensor([-0.7109, -1.2618], grad_fn=<SliceBackward0>)\n",
      "iter 43000, loss: 9.899168968200684\n",
      "tensor(-0.4741, grad_fn=<SelectBackward0>) tensor(0.1850, grad_fn=<SelectBackward0>) tensor([ 0.4655, -0.6979], grad_fn=<SliceBackward0>) tensor([ 0.5392, -0.1113], grad_fn=<SliceBackward0>)\n",
      "iter 43100, loss: 3.279006004333496\n",
      "tensor(0.7059, grad_fn=<SelectBackward0>) tensor(1.4408, grad_fn=<SelectBackward0>) tensor([ 0.3056, -0.0578], grad_fn=<SliceBackward0>) tensor([0.6242, 0.6971], grad_fn=<SliceBackward0>)\n",
      "iter 43200, loss: 5.539606094360352\n",
      "tensor(1.1121, grad_fn=<SelectBackward0>) tensor(0.5458, grad_fn=<SelectBackward0>) tensor([-1.2352, -0.0962], grad_fn=<SliceBackward0>) tensor([-0.2552,  1.0729], grad_fn=<SliceBackward0>)\n",
      "iter 43300, loss: 5.078134536743164\n",
      "tensor(-0.3890, grad_fn=<SelectBackward0>) tensor(0.2877, grad_fn=<SelectBackward0>) tensor([-0.5310, -2.2203], grad_fn=<SliceBackward0>) tensor([-1.2358, -0.2625], grad_fn=<SliceBackward0>)\n",
      "iter 43400, loss: 16.80154037475586\n",
      "tensor(0.3465, grad_fn=<SelectBackward0>) tensor(0.4533, grad_fn=<SelectBackward0>) tensor([-0.4048,  1.2094], grad_fn=<SliceBackward0>) tensor([0.8794, 0.7044], grad_fn=<SliceBackward0>)\n",
      "iter 43500, loss: 18.333959579467773\n",
      "tensor(-1.2215, grad_fn=<SelectBackward0>) tensor(0.8462, grad_fn=<SelectBackward0>) tensor([ 1.3313, -0.1437], grad_fn=<SliceBackward0>) tensor([0.4699, 0.8901], grad_fn=<SliceBackward0>)\n",
      "iter 43600, loss: 23.379940032958984\n",
      "tensor(1.0145, grad_fn=<SelectBackward0>) tensor(1.0387, grad_fn=<SelectBackward0>) tensor([ 0.8263, -1.1204], grad_fn=<SliceBackward0>) tensor([-1.6421, -0.1385], grad_fn=<SliceBackward0>)\n",
      "iter 43700, loss: 52.12697219848633\n",
      "tensor(-0.3275, grad_fn=<SelectBackward0>) tensor(-2.2019, grad_fn=<SelectBackward0>) tensor([-0.0539,  1.1042], grad_fn=<SliceBackward0>) tensor([0.1130, 0.7432], grad_fn=<SliceBackward0>)\n",
      "iter 43800, loss: 5.3621320724487305\n",
      "tensor(0.8638, grad_fn=<SelectBackward0>) tensor(0.4595, grad_fn=<SelectBackward0>) tensor([-1.0545, -0.8995], grad_fn=<SliceBackward0>) tensor([ 0.0590, -0.6947], grad_fn=<SliceBackward0>)\n",
      "iter 43900, loss: 11.75015926361084\n",
      "tensor(0.0628, grad_fn=<SelectBackward0>) tensor(-0.6394, grad_fn=<SelectBackward0>) tensor([-0.3360,  0.6783], grad_fn=<SliceBackward0>) tensor([-0.0646,  0.4632], grad_fn=<SliceBackward0>)\n",
      "iter 44000, loss: 6.216955661773682\n",
      "tensor(0.7855, grad_fn=<SelectBackward0>) tensor(1.4963, grad_fn=<SelectBackward0>) tensor([-0.3410, -0.7667], grad_fn=<SliceBackward0>) tensor([ 0.5769, -0.7848], grad_fn=<SliceBackward0>)\n",
      "iter 44100, loss: 14.35307502746582\n",
      "tensor(-0.0896, grad_fn=<SelectBackward0>) tensor(0.5298, grad_fn=<SelectBackward0>) tensor([ 0.1703, -0.0474], grad_fn=<SliceBackward0>) tensor([0.4187, 1.0431], grad_fn=<SliceBackward0>)\n",
      "iter 44200, loss: 0.12807713449001312\n",
      "tensor(-0.0174, grad_fn=<SelectBackward0>) tensor(1.7635, grad_fn=<SelectBackward0>) tensor([-0.3166,  1.1506], grad_fn=<SliceBackward0>) tensor([1.0846, 1.1183], grad_fn=<SliceBackward0>)\n",
      "iter 44300, loss: 55.43184280395508\n",
      "tensor(-0.2916, grad_fn=<SelectBackward0>) tensor(-0.6696, grad_fn=<SelectBackward0>) tensor([-0.5755,  0.4134], grad_fn=<SliceBackward0>) tensor([1.6187, 1.0823], grad_fn=<SliceBackward0>)\n",
      "iter 44400, loss: 5.764473915100098\n",
      "tensor(-0.8122, grad_fn=<SelectBackward0>) tensor(1.0527, grad_fn=<SelectBackward0>) tensor([ 0.5142, -1.1587], grad_fn=<SliceBackward0>) tensor([ 0.9592, -0.9644], grad_fn=<SliceBackward0>)\n",
      "iter 44500, loss: 18.757144927978516\n",
      "tensor(0.5191, grad_fn=<SelectBackward0>) tensor(0.2083, grad_fn=<SelectBackward0>) tensor([1.3647, 1.5709], grad_fn=<SliceBackward0>) tensor([ 1.0315, -0.5147], grad_fn=<SliceBackward0>)\n",
      "iter 44600, loss: 16.61033058166504\n",
      "tensor(0.5432, grad_fn=<SelectBackward0>) tensor(1.1574, grad_fn=<SelectBackward0>) tensor([-0.8463,  1.0174], grad_fn=<SliceBackward0>) tensor([ 0.3543, -0.1446], grad_fn=<SliceBackward0>)\n",
      "iter 44700, loss: 33.83669662475586\n",
      "tensor(-0.4180, grad_fn=<SelectBackward0>) tensor(-0.4768, grad_fn=<SelectBackward0>) tensor([-0.0631, -1.0166], grad_fn=<SliceBackward0>) tensor([-2.2440, -0.9394], grad_fn=<SliceBackward0>)\n",
      "iter 44800, loss: 9.052766799926758\n",
      "tensor(0.2723, grad_fn=<SelectBackward0>) tensor(-0.3464, grad_fn=<SelectBackward0>) tensor([-0.5917,  1.5544], grad_fn=<SliceBackward0>) tensor([-0.3670,  1.4437], grad_fn=<SliceBackward0>)\n",
      "iter 44900, loss: 4.328089237213135\n",
      "tensor(0.8967, grad_fn=<SelectBackward0>) tensor(-0.0508, grad_fn=<SelectBackward0>) tensor([ 1.1572, -0.5182], grad_fn=<SliceBackward0>) tensor([-0.1250, -0.7574], grad_fn=<SliceBackward0>)\n",
      "iter 45000, loss: 16.85723304748535\n",
      "tensor(0.8896, grad_fn=<SelectBackward0>) tensor(-0.5096, grad_fn=<SelectBackward0>) tensor([-1.0202,  0.0622], grad_fn=<SliceBackward0>) tensor([-0.7728,  0.2517], grad_fn=<SliceBackward0>)\n",
      "iter 45100, loss: 5.863821029663086\n",
      "tensor(0.4293, grad_fn=<SelectBackward0>) tensor(1.1650, grad_fn=<SelectBackward0>) tensor([-0.8223,  0.0412], grad_fn=<SliceBackward0>) tensor([ 0.9928, -0.2763], grad_fn=<SliceBackward0>)\n",
      "iter 45200, loss: 21.797183990478516\n",
      "tensor(-0.9944, grad_fn=<SelectBackward0>) tensor(0.7166, grad_fn=<SelectBackward0>) tensor([-0.7738, -0.8470], grad_fn=<SliceBackward0>) tensor([ 0.1977, -0.0950], grad_fn=<SliceBackward0>)\n",
      "iter 45300, loss: 38.85751724243164\n",
      "tensor(-2.2531, grad_fn=<SelectBackward0>) tensor(-0.5307, grad_fn=<SelectBackward0>) tensor([0.3534, 0.9455], grad_fn=<SliceBackward0>) tensor([-1.0935,  2.0478], grad_fn=<SliceBackward0>)\n",
      "iter 45400, loss: 18.379011154174805\n",
      "tensor(0.4400, grad_fn=<SelectBackward0>) tensor(0.1486, grad_fn=<SelectBackward0>) tensor([ 0.4056, -0.1022], grad_fn=<SliceBackward0>) tensor([ 1.0957, -1.4978], grad_fn=<SliceBackward0>)\n",
      "iter 45500, loss: 49.71341323852539\n",
      "tensor(-0.3900, grad_fn=<SelectBackward0>) tensor(0.1548, grad_fn=<SelectBackward0>) tensor([ 1.8013, -0.9262], grad_fn=<SliceBackward0>) tensor([0.0524, 0.9216], grad_fn=<SliceBackward0>)\n",
      "iter 45600, loss: 8.494848251342773\n",
      "tensor(-0.0847, grad_fn=<SelectBackward0>) tensor(0.1733, grad_fn=<SelectBackward0>) tensor([-0.4487, -0.4277], grad_fn=<SliceBackward0>) tensor([-1.8708,  1.0282], grad_fn=<SliceBackward0>)\n",
      "iter 45700, loss: 30.4805965423584\n",
      "tensor(0.6240, grad_fn=<SelectBackward0>) tensor(-1.8566, grad_fn=<SelectBackward0>) tensor([ 0.5733, -0.9022], grad_fn=<SliceBackward0>) tensor([0.2702, 0.0957], grad_fn=<SliceBackward0>)\n",
      "iter 45800, loss: 35.69855499267578\n",
      "tensor(0.2896, grad_fn=<SelectBackward0>) tensor(0.3875, grad_fn=<SelectBackward0>) tensor([1.0189, 0.3025], grad_fn=<SliceBackward0>) tensor([-1.6234, -0.5766], grad_fn=<SliceBackward0>)\n",
      "iter 45900, loss: 25.338233947753906\n",
      "tensor(-0.3449, grad_fn=<SelectBackward0>) tensor(-1.0244, grad_fn=<SelectBackward0>) tensor([ 1.7649, -0.4845], grad_fn=<SliceBackward0>) tensor([0.6366, 0.4328], grad_fn=<SliceBackward0>)\n",
      "iter 46000, loss: 3.7585747241973877\n",
      "tensor(-0.1633, grad_fn=<SelectBackward0>) tensor(1.7825, grad_fn=<SelectBackward0>) tensor([-0.3126, -0.0837], grad_fn=<SliceBackward0>) tensor([-2.0594, -1.3369], grad_fn=<SliceBackward0>)\n",
      "iter 46100, loss: 4.7017107009887695\n",
      "tensor(0.0113, grad_fn=<SelectBackward0>) tensor(3.0830, grad_fn=<SelectBackward0>) tensor([ 1.5009, -1.5097], grad_fn=<SliceBackward0>) tensor([-0.0988, -0.1137], grad_fn=<SliceBackward0>)\n",
      "iter 46200, loss: 19.198884963989258\n",
      "tensor(-0.5769, grad_fn=<SelectBackward0>) tensor(0.4943, grad_fn=<SelectBackward0>) tensor([0.3423, 0.9597], grad_fn=<SliceBackward0>) tensor([-1.4701,  2.1105], grad_fn=<SliceBackward0>)\n",
      "iter 46300, loss: 11.893856048583984\n",
      "tensor(1.1929, grad_fn=<SelectBackward0>) tensor(0.0610, grad_fn=<SelectBackward0>) tensor([-0.5137,  0.1979], grad_fn=<SliceBackward0>) tensor([0.9838, 0.1965], grad_fn=<SliceBackward0>)\n",
      "iter 46400, loss: 11.08657169342041\n",
      "tensor(0.6149, grad_fn=<SelectBackward0>) tensor(1.2570, grad_fn=<SelectBackward0>) tensor([0.1649, 0.4476], grad_fn=<SliceBackward0>) tensor([-1.3002,  0.6823], grad_fn=<SliceBackward0>)\n",
      "iter 46500, loss: 20.04903221130371\n",
      "tensor(-0.2210, grad_fn=<SelectBackward0>) tensor(0.8261, grad_fn=<SelectBackward0>) tensor([ 1.0763, -0.7949], grad_fn=<SliceBackward0>) tensor([-0.0853, -0.4586], grad_fn=<SliceBackward0>)\n",
      "iter 46600, loss: 29.199583053588867\n",
      "tensor(-0.0751, grad_fn=<SelectBackward0>) tensor(-0.6344, grad_fn=<SelectBackward0>) tensor([-0.4672, -1.0457], grad_fn=<SliceBackward0>) tensor([ 0.7647, -1.1533], grad_fn=<SliceBackward0>)\n",
      "iter 46700, loss: 19.17327117919922\n",
      "tensor(0.0909, grad_fn=<SelectBackward0>) tensor(-0.7670, grad_fn=<SelectBackward0>) tensor([-0.9938,  0.0714], grad_fn=<SliceBackward0>) tensor([-1.8427,  0.9510], grad_fn=<SliceBackward0>)\n",
      "iter 46800, loss: 72.715576171875\n",
      "tensor(-0.9491, grad_fn=<SelectBackward0>) tensor(-0.8547, grad_fn=<SelectBackward0>) tensor([-1.4161, -0.4874], grad_fn=<SliceBackward0>) tensor([0.1500, 1.0307], grad_fn=<SliceBackward0>)\n",
      "iter 46900, loss: 17.90651512145996\n",
      "tensor(-0.1343, grad_fn=<SelectBackward0>) tensor(-0.1302, grad_fn=<SelectBackward0>) tensor([ 0.3744, -1.0926], grad_fn=<SliceBackward0>) tensor([0.3042, 0.6742], grad_fn=<SliceBackward0>)\n",
      "iter 47000, loss: 9.895082473754883\n",
      "tensor(2.6508, grad_fn=<SelectBackward0>) tensor(-0.5044, grad_fn=<SelectBackward0>) tensor([-0.9137,  0.1907], grad_fn=<SliceBackward0>) tensor([0.1849, 0.3694], grad_fn=<SliceBackward0>)\n",
      "iter 47100, loss: 19.230403900146484\n",
      "tensor(-2.3125, grad_fn=<SelectBackward0>) tensor(1.2451, grad_fn=<SelectBackward0>) tensor([ 2.2886, -0.4131], grad_fn=<SliceBackward0>) tensor([ 0.5523, -0.1797], grad_fn=<SliceBackward0>)\n",
      "iter 47200, loss: 22.840425491333008\n",
      "tensor(-1.0102, grad_fn=<SelectBackward0>) tensor(1.2523, grad_fn=<SelectBackward0>) tensor([ 1.9199, -2.4679], grad_fn=<SliceBackward0>) tensor([1.5606, 0.6615], grad_fn=<SliceBackward0>)\n",
      "iter 47300, loss: 26.609159469604492\n",
      "tensor(0.6039, grad_fn=<SelectBackward0>) tensor(-0.1461, grad_fn=<SelectBackward0>) tensor([0.4212, 0.9131], grad_fn=<SliceBackward0>) tensor([ 0.3480, -0.4462], grad_fn=<SliceBackward0>)\n",
      "iter 47400, loss: 31.985179901123047\n",
      "tensor(-1.0094, grad_fn=<SelectBackward0>) tensor(1.1110, grad_fn=<SelectBackward0>) tensor([0.2269, 1.5837], grad_fn=<SliceBackward0>) tensor([-0.5620, -0.0391], grad_fn=<SliceBackward0>)\n",
      "iter 47500, loss: 18.897472381591797\n",
      "tensor(-1.0350, grad_fn=<SelectBackward0>) tensor(-0.4990, grad_fn=<SelectBackward0>) tensor([-0.6775,  1.5912], grad_fn=<SliceBackward0>) tensor([-0.5784,  1.5077], grad_fn=<SliceBackward0>)\n",
      "iter 47600, loss: 7.196582794189453\n",
      "tensor(1.8228, grad_fn=<SelectBackward0>) tensor(1.5933, grad_fn=<SelectBackward0>) tensor([-0.6772, -0.8313], grad_fn=<SliceBackward0>) tensor([1.1610, 0.0744], grad_fn=<SliceBackward0>)\n",
      "iter 47700, loss: 31.819231033325195\n",
      "tensor(0.3314, grad_fn=<SelectBackward0>) tensor(-0.2908, grad_fn=<SelectBackward0>) tensor([ 1.7145, -1.3144], grad_fn=<SliceBackward0>) tensor([-0.3302, -0.5252], grad_fn=<SliceBackward0>)\n",
      "iter 47800, loss: 26.355466842651367\n",
      "tensor(0.3928, grad_fn=<SelectBackward0>) tensor(-1.5633, grad_fn=<SelectBackward0>) tensor([ 0.1775, -1.9138], grad_fn=<SliceBackward0>) tensor([ 1.4777, -0.8414], grad_fn=<SliceBackward0>)\n",
      "iter 47900, loss: 11.436464309692383\n",
      "tensor(0.8325, grad_fn=<SelectBackward0>) tensor(-0.6266, grad_fn=<SelectBackward0>) tensor([0.1072, 0.4775], grad_fn=<SliceBackward0>) tensor([-0.4105,  1.6785], grad_fn=<SliceBackward0>)\n",
      "iter 48000, loss: 65.2667236328125\n",
      "tensor(0.8317, grad_fn=<SelectBackward0>) tensor(0.4918, grad_fn=<SelectBackward0>) tensor([-1.9851, -0.7724], grad_fn=<SliceBackward0>) tensor([1.3663, 0.0634], grad_fn=<SliceBackward0>)\n",
      "iter 48100, loss: 22.878042221069336\n",
      "tensor(0.8271, grad_fn=<SelectBackward0>) tensor(0.9371, grad_fn=<SelectBackward0>) tensor([-0.0106, -2.3788], grad_fn=<SliceBackward0>) tensor([-1.1033,  0.2821], grad_fn=<SliceBackward0>)\n",
      "iter 48200, loss: 29.28079605102539\n",
      "tensor(0.0499, grad_fn=<SelectBackward0>) tensor(-0.5092, grad_fn=<SelectBackward0>) tensor([-1.2623, -0.3531], grad_fn=<SliceBackward0>) tensor([-0.6477,  0.7662], grad_fn=<SliceBackward0>)\n",
      "iter 48300, loss: 50.15943145751953\n",
      "tensor(0.6887, grad_fn=<SelectBackward0>) tensor(-0.8334, grad_fn=<SelectBackward0>) tensor([-0.9113, -0.7235], grad_fn=<SliceBackward0>) tensor([0.3344, 1.1817], grad_fn=<SliceBackward0>)\n",
      "iter 48400, loss: 11.827396392822266\n",
      "tensor(-0.1617, grad_fn=<SelectBackward0>) tensor(1.2209, grad_fn=<SelectBackward0>) tensor([ 1.6352, -0.3578], grad_fn=<SliceBackward0>) tensor([0.0711, 2.4172], grad_fn=<SliceBackward0>)\n",
      "iter 48500, loss: 2.3083083629608154\n",
      "tensor(-1.7097, grad_fn=<SelectBackward0>) tensor(-0.3812, grad_fn=<SelectBackward0>) tensor([1.0002, 0.9716], grad_fn=<SliceBackward0>) tensor([1.0978, 0.6572], grad_fn=<SliceBackward0>)\n",
      "iter 48600, loss: 0.9779466390609741\n",
      "tensor(1.1956, grad_fn=<SelectBackward0>) tensor(1.6659, grad_fn=<SelectBackward0>) tensor([1.5760, 1.4946], grad_fn=<SliceBackward0>) tensor([-0.3236,  1.6355], grad_fn=<SliceBackward0>)\n",
      "iter 48700, loss: 63.45446014404297\n",
      "tensor(-1.1702, grad_fn=<SelectBackward0>) tensor(-0.3105, grad_fn=<SelectBackward0>) tensor([-0.5173,  0.5182], grad_fn=<SliceBackward0>) tensor([1.7254, 0.9760], grad_fn=<SliceBackward0>)\n",
      "iter 48800, loss: 3.205777168273926\n",
      "tensor(0.1680, grad_fn=<SelectBackward0>) tensor(1.2715, grad_fn=<SelectBackward0>) tensor([0.2627, 1.7161], grad_fn=<SliceBackward0>) tensor([-1.0097,  0.7392], grad_fn=<SliceBackward0>)\n",
      "iter 48900, loss: 22.984655380249023\n",
      "tensor(-0.3016, grad_fn=<SelectBackward0>) tensor(2.1102, grad_fn=<SelectBackward0>) tensor([-1.4952, -1.4016], grad_fn=<SliceBackward0>) tensor([ 0.6467, -0.0239], grad_fn=<SliceBackward0>)\n",
      "iter 49000, loss: 11.982912063598633\n",
      "tensor(1.4717, grad_fn=<SelectBackward0>) tensor(0.4620, grad_fn=<SelectBackward0>) tensor([-0.1894, -1.0924], grad_fn=<SliceBackward0>) tensor([-0.2366,  0.1891], grad_fn=<SliceBackward0>)\n",
      "iter 49100, loss: 49.85625076293945\n",
      "tensor(-0.7018, grad_fn=<SelectBackward0>) tensor(-0.2156, grad_fn=<SelectBackward0>) tensor([-1.3947, -0.9584], grad_fn=<SliceBackward0>) tensor([-1.4809,  1.8016], grad_fn=<SliceBackward0>)\n",
      "iter 49200, loss: 5.4949049949646\n",
      "tensor(0.2588, grad_fn=<SelectBackward0>) tensor(-0.3083, grad_fn=<SelectBackward0>) tensor([0.4694, 0.5840], grad_fn=<SliceBackward0>) tensor([0.2422, 1.3638], grad_fn=<SliceBackward0>)\n",
      "iter 49300, loss: 15.5737943649292\n",
      "tensor(0.2783, grad_fn=<SelectBackward0>) tensor(1.0946, grad_fn=<SelectBackward0>) tensor([-1.0524,  0.2001], grad_fn=<SliceBackward0>) tensor([ 0.0013, -0.2988], grad_fn=<SliceBackward0>)\n",
      "iter 49400, loss: 16.766876220703125\n",
      "tensor(-0.0719, grad_fn=<SelectBackward0>) tensor(-0.6805, grad_fn=<SelectBackward0>) tensor([-0.6763, -1.1613], grad_fn=<SliceBackward0>) tensor([-0.7641, -1.3964], grad_fn=<SliceBackward0>)\n",
      "iter 49500, loss: 60.36073684692383\n",
      "tensor(-0.3344, grad_fn=<SelectBackward0>) tensor(-0.2367, grad_fn=<SelectBackward0>) tensor([ 1.8092, -0.4725], grad_fn=<SliceBackward0>) tensor([-0.4890,  0.5462], grad_fn=<SliceBackward0>)\n",
      "iter 49600, loss: 33.872013092041016\n",
      "tensor(-0.4039, grad_fn=<SelectBackward0>) tensor(0.5483, grad_fn=<SelectBackward0>) tensor([-0.5681, -0.5329], grad_fn=<SliceBackward0>) tensor([-0.0232,  0.9973], grad_fn=<SliceBackward0>)\n",
      "iter 49700, loss: 1.8154202699661255\n",
      "tensor(0.2047, grad_fn=<SelectBackward0>) tensor(1.2888, grad_fn=<SelectBackward0>) tensor([ 2.3095, -0.4894], grad_fn=<SliceBackward0>) tensor([0.7613, 0.7474], grad_fn=<SliceBackward0>)\n",
      "iter 49800, loss: 0.17965459823608398\n",
      "tensor(0.0997, grad_fn=<SelectBackward0>) tensor(3.6341, grad_fn=<SelectBackward0>) tensor([0.9631, 0.2312], grad_fn=<SliceBackward0>) tensor([-0.0790, -0.2181], grad_fn=<SliceBackward0>)\n",
      "iter 49900, loss: 29.493593215942383\n",
      "tensor(0.2820, grad_fn=<SelectBackward0>) tensor(-1.1908, grad_fn=<SelectBackward0>) tensor([-0.7756, -1.0959], grad_fn=<SliceBackward0>) tensor([-0.6783, -0.3671], grad_fn=<SliceBackward0>)\n",
      "iter 50000, loss: 60.21550369262695\n",
      "tensor(0.3419, grad_fn=<SelectBackward0>) tensor(-0.8036, grad_fn=<SelectBackward0>) tensor([-1.3852, -1.1429], grad_fn=<SliceBackward0>) tensor([0.5699, 1.1071], grad_fn=<SliceBackward0>)\n",
      "iter 50100, loss: 0.8557305932044983\n",
      "tensor(1.3662, grad_fn=<SelectBackward0>) tensor(2.7116, grad_fn=<SelectBackward0>) tensor([-0.3522, -0.3377], grad_fn=<SliceBackward0>) tensor([-0.0963, -0.0211], grad_fn=<SliceBackward0>)\n",
      "iter 50200, loss: 4.406481742858887\n",
      "tensor(2.1061, grad_fn=<SelectBackward0>) tensor(1.5545, grad_fn=<SelectBackward0>) tensor([ 0.4939, -0.3260], grad_fn=<SliceBackward0>) tensor([-1.1286,  0.1374], grad_fn=<SliceBackward0>)\n",
      "iter 50300, loss: 20.71150779724121\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>) tensor(0.2496, grad_fn=<SelectBackward0>) tensor([ 0.7710, -0.2066], grad_fn=<SliceBackward0>) tensor([0.8124, 0.5447], grad_fn=<SliceBackward0>)\n",
      "iter 50400, loss: 22.894193649291992\n",
      "tensor(0.2160, grad_fn=<SelectBackward0>) tensor(-0.1978, grad_fn=<SelectBackward0>) tensor([-0.4059, -0.0330], grad_fn=<SliceBackward0>) tensor([-1.5049,  0.0619], grad_fn=<SliceBackward0>)\n",
      "iter 50500, loss: 8.970211029052734\n",
      "tensor(-0.4742, grad_fn=<SelectBackward0>) tensor(0.4928, grad_fn=<SelectBackward0>) tensor([-1.2710,  0.0406], grad_fn=<SliceBackward0>) tensor([-0.1737, -0.2960], grad_fn=<SliceBackward0>)\n",
      "iter 50600, loss: 2.20782208442688\n",
      "tensor(0.7309, grad_fn=<SelectBackward0>) tensor(0.8339, grad_fn=<SelectBackward0>) tensor([-1.5678, -0.1753], grad_fn=<SliceBackward0>) tensor([-0.7758,  0.6064], grad_fn=<SliceBackward0>)\n",
      "iter 50700, loss: 22.143014907836914\n",
      "tensor(-0.1077, grad_fn=<SelectBackward0>) tensor(-0.2998, grad_fn=<SelectBackward0>) tensor([ 0.4302, -0.7706], grad_fn=<SliceBackward0>) tensor([1.0056, 0.4580], grad_fn=<SliceBackward0>)\n",
      "iter 50800, loss: 9.988024711608887\n",
      "tensor(0.9070, grad_fn=<SelectBackward0>) tensor(3.9322, grad_fn=<SelectBackward0>) tensor([0.9058, 1.2618], grad_fn=<SliceBackward0>) tensor([ 0.1180, -0.0542], grad_fn=<SliceBackward0>)\n",
      "iter 50900, loss: 9.371288299560547\n",
      "tensor(0.7393, grad_fn=<SelectBackward0>) tensor(1.0220, grad_fn=<SelectBackward0>) tensor([-0.8104,  0.3811], grad_fn=<SliceBackward0>) tensor([ 0.4968, -0.5437], grad_fn=<SliceBackward0>)\n",
      "iter 51000, loss: 8.198629379272461\n",
      "tensor(-0.7862, grad_fn=<SelectBackward0>) tensor(-0.8253, grad_fn=<SelectBackward0>) tensor([-0.4636, -0.6319], grad_fn=<SliceBackward0>) tensor([ 0.2226, -0.0079], grad_fn=<SliceBackward0>)\n",
      "iter 51100, loss: 19.244142532348633\n",
      "tensor(-0.7505, grad_fn=<SelectBackward0>) tensor(-0.9720, grad_fn=<SelectBackward0>) tensor([-0.6956,  0.9946], grad_fn=<SliceBackward0>) tensor([0.0561, 0.7155], grad_fn=<SliceBackward0>)\n",
      "iter 51200, loss: 22.26097297668457\n",
      "tensor(0.0730, grad_fn=<SelectBackward0>) tensor(-0.2364, grad_fn=<SelectBackward0>) tensor([-0.4212, -1.3029], grad_fn=<SliceBackward0>) tensor([-0.2658, -0.5492], grad_fn=<SliceBackward0>)\n",
      "iter 51300, loss: 4.105367183685303\n",
      "tensor(-0.8709, grad_fn=<SelectBackward0>) tensor(3.3202, grad_fn=<SelectBackward0>) tensor([-1.0615,  0.9003], grad_fn=<SliceBackward0>) tensor([-0.6543,  0.0053], grad_fn=<SliceBackward0>)\n",
      "iter 51400, loss: 3.1514976024627686\n",
      "tensor(0.4044, grad_fn=<SelectBackward0>) tensor(1.2086, grad_fn=<SelectBackward0>) tensor([ 1.0204, -0.1371], grad_fn=<SliceBackward0>) tensor([0.8065, 0.5221], grad_fn=<SliceBackward0>)\n",
      "iter 51500, loss: 27.987110137939453\n",
      "tensor(0.3897, grad_fn=<SelectBackward0>) tensor(-0.7658, grad_fn=<SelectBackward0>) tensor([ 0.6606, -0.9294], grad_fn=<SliceBackward0>) tensor([-0.7835, -1.2609], grad_fn=<SliceBackward0>)\n",
      "iter 51600, loss: 6.469107627868652\n",
      "tensor(-0.3255, grad_fn=<SelectBackward0>) tensor(2.6702, grad_fn=<SelectBackward0>) tensor([ 0.4246, -0.3762], grad_fn=<SliceBackward0>) tensor([ 0.3792, -0.2053], grad_fn=<SliceBackward0>)\n",
      "iter 51700, loss: 19.35839080810547\n",
      "tensor(0.1768, grad_fn=<SelectBackward0>) tensor(-0.3652, grad_fn=<SelectBackward0>) tensor([-0.3429, -1.0713], grad_fn=<SliceBackward0>) tensor([ 0.4472, -0.2348], grad_fn=<SliceBackward0>)\n",
      "iter 51800, loss: 4.593894958496094\n",
      "tensor(0.4909, grad_fn=<SelectBackward0>) tensor(1.2421, grad_fn=<SelectBackward0>) tensor([-0.6982,  1.6727], grad_fn=<SliceBackward0>) tensor([0.2265, 0.9211], grad_fn=<SliceBackward0>)\n",
      "iter 51900, loss: 4.5088067054748535\n",
      "tensor(2.0299, grad_fn=<SelectBackward0>) tensor(-0.0154, grad_fn=<SelectBackward0>) tensor([0.0333, 0.1310], grad_fn=<SliceBackward0>) tensor([-1.4009,  0.8160], grad_fn=<SliceBackward0>)\n",
      "iter 52000, loss: 5.832926273345947\n",
      "tensor(1.0874, grad_fn=<SelectBackward0>) tensor(0.4592, grad_fn=<SelectBackward0>) tensor([-1.0695, -0.4022], grad_fn=<SliceBackward0>) tensor([-0.0441, -0.3922], grad_fn=<SliceBackward0>)\n",
      "iter 52100, loss: 50.09801483154297\n",
      "tensor(-0.2727, grad_fn=<SelectBackward0>) tensor(-1.4956, grad_fn=<SelectBackward0>) tensor([-0.0339,  0.3962], grad_fn=<SliceBackward0>) tensor([-0.9061,  0.2189], grad_fn=<SliceBackward0>)\n",
      "iter 52200, loss: 3.699148654937744\n",
      "tensor(1.7152, grad_fn=<SelectBackward0>) tensor(2.0542, grad_fn=<SelectBackward0>) tensor([ 0.7616, -0.3389], grad_fn=<SliceBackward0>) tensor([0.2144, 0.3578], grad_fn=<SliceBackward0>)\n",
      "iter 52300, loss: 2.0552988052368164\n",
      "tensor(2.4318, grad_fn=<SelectBackward0>) tensor(0.9065, grad_fn=<SelectBackward0>) tensor([-1.0175, -0.0070], grad_fn=<SliceBackward0>) tensor([0.0117, 0.9345], grad_fn=<SliceBackward0>)\n",
      "iter 52400, loss: 6.659887313842773\n",
      "tensor(-0.3679, grad_fn=<SelectBackward0>) tensor(0.7948, grad_fn=<SelectBackward0>) tensor([ 0.4511, -0.1915], grad_fn=<SliceBackward0>) tensor([ 0.1918, -0.1231], grad_fn=<SliceBackward0>)\n",
      "iter 52500, loss: 29.447145462036133\n",
      "tensor(-0.8308, grad_fn=<SelectBackward0>) tensor(1.1207, grad_fn=<SelectBackward0>) tensor([0.7540, 0.0934], grad_fn=<SliceBackward0>) tensor([-0.4804, -0.2700], grad_fn=<SliceBackward0>)\n",
      "iter 52600, loss: 29.085458755493164\n",
      "tensor(-0.7024, grad_fn=<SelectBackward0>) tensor(0.3228, grad_fn=<SelectBackward0>) tensor([0.0144, 0.8903], grad_fn=<SliceBackward0>) tensor([-0.4424,  0.3605], grad_fn=<SliceBackward0>)\n",
      "iter 52700, loss: 8.337807655334473\n",
      "tensor(0.7993, grad_fn=<SelectBackward0>) tensor(1.6542, grad_fn=<SelectBackward0>) tensor([ 0.1680, -0.6685], grad_fn=<SliceBackward0>) tensor([-0.3908,  0.1781], grad_fn=<SliceBackward0>)\n",
      "iter 52800, loss: 9.35607624053955\n",
      "tensor(-0.3279, grad_fn=<SelectBackward0>) tensor(1.0312, grad_fn=<SelectBackward0>) tensor([0.7632, 0.9246], grad_fn=<SliceBackward0>) tensor([-0.2084,  0.6864], grad_fn=<SliceBackward0>)\n",
      "iter 52900, loss: 34.69645309448242\n",
      "tensor(-0.6095, grad_fn=<SelectBackward0>) tensor(-0.1443, grad_fn=<SelectBackward0>) tensor([-2.2691, -1.4303], grad_fn=<SliceBackward0>) tensor([-1.4713,  1.3575], grad_fn=<SliceBackward0>)\n",
      "iter 53000, loss: 25.89426612854004\n",
      "tensor(0.3690, grad_fn=<SelectBackward0>) tensor(0.1829, grad_fn=<SelectBackward0>) tensor([-0.1492,  0.0212], grad_fn=<SliceBackward0>) tensor([1.4337, 0.2178], grad_fn=<SliceBackward0>)\n",
      "iter 53100, loss: 1.5499720573425293\n",
      "tensor(0.8951, grad_fn=<SelectBackward0>) tensor(2.4881, grad_fn=<SelectBackward0>) tensor([0.2975, 1.4858], grad_fn=<SliceBackward0>) tensor([ 1.4358, -0.5957], grad_fn=<SliceBackward0>)\n",
      "iter 53200, loss: 28.203575134277344\n",
      "tensor(-0.2358, grad_fn=<SelectBackward0>) tensor(-0.9831, grad_fn=<SelectBackward0>) tensor([1.2959, 1.4605], grad_fn=<SliceBackward0>) tensor([-0.0068,  0.3699], grad_fn=<SliceBackward0>)\n",
      "iter 53300, loss: 19.0474796295166\n",
      "tensor(0.1486, grad_fn=<SelectBackward0>) tensor(-0.5676, grad_fn=<SelectBackward0>) tensor([-1.1391,  0.5526], grad_fn=<SliceBackward0>) tensor([-1.1974,  0.1876], grad_fn=<SliceBackward0>)\n",
      "iter 53400, loss: 9.43415355682373\n",
      "tensor(0.7684, grad_fn=<SelectBackward0>) tensor(1.4198, grad_fn=<SelectBackward0>) tensor([-1.3766,  1.8349], grad_fn=<SliceBackward0>) tensor([0.7309, 0.6839], grad_fn=<SliceBackward0>)\n",
      "iter 53500, loss: 21.36760711669922\n",
      "tensor(-0.7487, grad_fn=<SelectBackward0>) tensor(0.1447, grad_fn=<SelectBackward0>) tensor([-2.0399,  0.4456], grad_fn=<SliceBackward0>) tensor([-0.6687,  0.5390], grad_fn=<SliceBackward0>)\n",
      "iter 53600, loss: 21.499526977539062\n",
      "tensor(0.6684, grad_fn=<SelectBackward0>) tensor(0.9184, grad_fn=<SelectBackward0>) tensor([0.3604, 1.1042], grad_fn=<SliceBackward0>) tensor([ 0.7133, -0.9230], grad_fn=<SliceBackward0>)\n",
      "iter 53700, loss: 32.460845947265625\n",
      "tensor(1.1018, grad_fn=<SelectBackward0>) tensor(-1.3067, grad_fn=<SelectBackward0>) tensor([ 0.3156, -0.0435], grad_fn=<SliceBackward0>) tensor([-0.3238, -1.2813], grad_fn=<SliceBackward0>)\n",
      "iter 53800, loss: 31.569988250732422\n",
      "tensor(0.3432, grad_fn=<SelectBackward0>) tensor(-1.3835, grad_fn=<SelectBackward0>) tensor([1.3279, 0.9026], grad_fn=<SliceBackward0>) tensor([ 0.8980, -0.2102], grad_fn=<SliceBackward0>)\n",
      "iter 53900, loss: 11.118041038513184\n",
      "tensor(0.5456, grad_fn=<SelectBackward0>) tensor(1.1079, grad_fn=<SelectBackward0>) tensor([-0.6631, -1.1938], grad_fn=<SliceBackward0>) tensor([-0.1861, -0.1237], grad_fn=<SliceBackward0>)\n",
      "iter 54000, loss: 36.4468994140625\n",
      "tensor(-0.4761, grad_fn=<SelectBackward0>) tensor(0.1521, grad_fn=<SelectBackward0>) tensor([0.2172, 0.6093], grad_fn=<SliceBackward0>) tensor([-1.8697,  0.8225], grad_fn=<SliceBackward0>)\n",
      "iter 54100, loss: 8.35586166381836\n",
      "tensor(1.4862, grad_fn=<SelectBackward0>) tensor(1.3639, grad_fn=<SelectBackward0>) tensor([ 0.3197, -0.8152], grad_fn=<SliceBackward0>) tensor([-1.3231,  0.0612], grad_fn=<SliceBackward0>)\n",
      "iter 54200, loss: 5.15072774887085\n",
      "tensor(0.7791, grad_fn=<SelectBackward0>) tensor(0.8234, grad_fn=<SelectBackward0>) tensor([-0.1036, -1.2891], grad_fn=<SliceBackward0>) tensor([ 0.3105, -0.2586], grad_fn=<SliceBackward0>)\n",
      "iter 54300, loss: 7.834909915924072\n",
      "tensor(0.7349, grad_fn=<SelectBackward0>) tensor(-0.1433, grad_fn=<SelectBackward0>) tensor([1.1405, 0.3295], grad_fn=<SliceBackward0>) tensor([1.4195, 1.0187], grad_fn=<SliceBackward0>)\n",
      "iter 54400, loss: 1.8479760885238647\n",
      "tensor(-0.3399, grad_fn=<SelectBackward0>) tensor(0.0216, grad_fn=<SelectBackward0>) tensor([-1.8946,  0.2613], grad_fn=<SliceBackward0>) tensor([-1.5965,  0.6194], grad_fn=<SliceBackward0>)\n",
      "iter 54500, loss: 14.585119247436523\n",
      "tensor(0.0794, grad_fn=<SelectBackward0>) tensor(-0.0969, grad_fn=<SelectBackward0>) tensor([0.6607, 0.3864], grad_fn=<SliceBackward0>) tensor([-0.0484,  1.5868], grad_fn=<SliceBackward0>)\n",
      "iter 54600, loss: 20.24989891052246\n",
      "tensor(0.3163, grad_fn=<SelectBackward0>) tensor(-1.6061, grad_fn=<SelectBackward0>) tensor([-0.2983,  0.1350], grad_fn=<SliceBackward0>) tensor([-0.0704, -0.2571], grad_fn=<SliceBackward0>)\n",
      "iter 54700, loss: 23.571718215942383\n",
      "tensor(1.4539, grad_fn=<SelectBackward0>) tensor(1.2088, grad_fn=<SelectBackward0>) tensor([ 0.9446, -1.6124], grad_fn=<SliceBackward0>) tensor([-1.6318,  0.0769], grad_fn=<SliceBackward0>)\n",
      "iter 54800, loss: 0.11937586963176727\n",
      "tensor(1.4679, grad_fn=<SelectBackward0>) tensor(1.7198, grad_fn=<SelectBackward0>) tensor([0.7871, 1.2685], grad_fn=<SliceBackward0>) tensor([0.8683, 1.1219], grad_fn=<SliceBackward0>)\n",
      "iter 54900, loss: 37.48079299926758\n",
      "tensor(-1.3313, grad_fn=<SelectBackward0>) tensor(0.7556, grad_fn=<SelectBackward0>) tensor([0.5552, 1.2259], grad_fn=<SliceBackward0>) tensor([ 0.0925, -0.8126], grad_fn=<SliceBackward0>)\n",
      "iter 55000, loss: 32.562835693359375\n",
      "tensor(0.5957, grad_fn=<SelectBackward0>) tensor(-1.5137, grad_fn=<SelectBackward0>) tensor([-0.0338,  0.5423], grad_fn=<SliceBackward0>) tensor([-0.1691,  1.0783], grad_fn=<SliceBackward0>)\n",
      "iter 55100, loss: 44.18440628051758\n",
      "tensor(-0.7627, grad_fn=<SelectBackward0>) tensor(0.0271, grad_fn=<SelectBackward0>) tensor([0.6309, 0.7652], grad_fn=<SliceBackward0>) tensor([-1.0124,  0.4057], grad_fn=<SliceBackward0>)\n",
      "iter 55200, loss: 0.9128262400627136\n",
      "tensor(1.3896, grad_fn=<SelectBackward0>) tensor(2.0337, grad_fn=<SelectBackward0>) tensor([-1.7511,  1.0231], grad_fn=<SliceBackward0>) tensor([-0.3732,  0.0872], grad_fn=<SliceBackward0>)\n",
      "iter 55300, loss: 43.79793930053711\n",
      "tensor(-1.7355, grad_fn=<SelectBackward0>) tensor(1.1312, grad_fn=<SelectBackward0>) tensor([0.8732, 0.5098], grad_fn=<SliceBackward0>) tensor([-0.4444, -0.2986], grad_fn=<SliceBackward0>)\n",
      "iter 55400, loss: 6.515411376953125\n",
      "tensor(0.3573, grad_fn=<SelectBackward0>) tensor(1.3298, grad_fn=<SelectBackward0>) tensor([-0.6429,  0.4668], grad_fn=<SliceBackward0>) tensor([-3.4398,  1.6155], grad_fn=<SliceBackward0>)\n",
      "iter 55500, loss: 42.57331085205078\n",
      "tensor(0.4105, grad_fn=<SelectBackward0>) tensor(-1.5173, grad_fn=<SelectBackward0>) tensor([-0.7423,  0.4809], grad_fn=<SliceBackward0>) tensor([0.6084, 1.9199], grad_fn=<SliceBackward0>)\n",
      "iter 55600, loss: 3.1630964279174805\n",
      "tensor(1.1345, grad_fn=<SelectBackward0>) tensor(1.1436, grad_fn=<SelectBackward0>) tensor([0.6158, 0.2652], grad_fn=<SliceBackward0>) tensor([ 0.5521, -0.9911], grad_fn=<SliceBackward0>)\n",
      "iter 55700, loss: 20.185245513916016\n",
      "tensor(0.6669, grad_fn=<SelectBackward0>) tensor(0.7759, grad_fn=<SelectBackward0>) tensor([0.9835, 0.2479], grad_fn=<SliceBackward0>) tensor([-1.5193,  0.3629], grad_fn=<SliceBackward0>)\n",
      "iter 55800, loss: 27.195470809936523\n",
      "tensor(1.5172, grad_fn=<SelectBackward0>) tensor(-0.3715, grad_fn=<SelectBackward0>) tensor([-0.3444, -0.7530], grad_fn=<SliceBackward0>) tensor([-1.1224,  1.4421], grad_fn=<SliceBackward0>)\n",
      "iter 55900, loss: 1.791295051574707\n",
      "tensor(0.1006, grad_fn=<SelectBackward0>) tensor(1.9623, grad_fn=<SelectBackward0>) tensor([-2.0650, -0.5189], grad_fn=<SliceBackward0>) tensor([-0.8436, -0.0939], grad_fn=<SliceBackward0>)\n",
      "iter 56000, loss: 39.561134338378906\n",
      "tensor(-1.9996, grad_fn=<SelectBackward0>) tensor(-0.7857, grad_fn=<SelectBackward0>) tensor([1.3544, 0.5889], grad_fn=<SliceBackward0>) tensor([1.0321, 1.8853], grad_fn=<SliceBackward0>)\n",
      "iter 56100, loss: 1.4185088872909546\n",
      "tensor(-0.7486, grad_fn=<SelectBackward0>) tensor(-0.3301, grad_fn=<SelectBackward0>) tensor([ 1.1648, -2.8452], grad_fn=<SliceBackward0>) tensor([ 1.1121, -1.6161], grad_fn=<SliceBackward0>)\n",
      "iter 56200, loss: 18.324798583984375\n",
      "tensor(0.5177, grad_fn=<SelectBackward0>) tensor(0.2611, grad_fn=<SelectBackward0>) tensor([-0.4267, -0.7916], grad_fn=<SliceBackward0>) tensor([ 0.7703, -0.7673], grad_fn=<SliceBackward0>)\n",
      "iter 56300, loss: 10.515153884887695\n",
      "tensor(-0.1525, grad_fn=<SelectBackward0>) tensor(1.7919, grad_fn=<SelectBackward0>) tensor([-1.3972, -1.0292], grad_fn=<SliceBackward0>) tensor([-0.6313,  0.3951], grad_fn=<SliceBackward0>)\n",
      "iter 56400, loss: 3.1601178646087646\n",
      "tensor(1.3935, grad_fn=<SelectBackward0>) tensor(1.9596, grad_fn=<SelectBackward0>) tensor([-0.0209, -1.3844], grad_fn=<SliceBackward0>) tensor([ 0.7920, -0.0353], grad_fn=<SliceBackward0>)\n",
      "iter 56500, loss: 11.046772003173828\n",
      "tensor(-0.2832, grad_fn=<SelectBackward0>) tensor(1.6640, grad_fn=<SelectBackward0>) tensor([-0.3251, -0.9305], grad_fn=<SliceBackward0>) tensor([-0.1781,  0.5732], grad_fn=<SliceBackward0>)\n",
      "iter 56600, loss: 39.28235626220703\n",
      "tensor(0.6579, grad_fn=<SelectBackward0>) tensor(-0.2583, grad_fn=<SelectBackward0>) tensor([ 0.9000, -0.0230], grad_fn=<SliceBackward0>) tensor([-1.9033,  0.5159], grad_fn=<SliceBackward0>)\n",
      "iter 56700, loss: 17.657289505004883\n",
      "tensor(1.5694, grad_fn=<SelectBackward0>) tensor(-0.6797, grad_fn=<SelectBackward0>) tensor([0.0994, 0.7202], grad_fn=<SliceBackward0>) tensor([-1.7436,  0.8400], grad_fn=<SliceBackward0>)\n",
      "iter 56800, loss: 8.104106903076172\n",
      "tensor(0.4024, grad_fn=<SelectBackward0>) tensor(1.3521, grad_fn=<SelectBackward0>) tensor([1.5764, 0.2035], grad_fn=<SliceBackward0>) tensor([0.3616, 0.5092], grad_fn=<SliceBackward0>)\n",
      "iter 56900, loss: 0.8755167126655579\n",
      "tensor(2.3415, grad_fn=<SelectBackward0>) tensor(0.4265, grad_fn=<SelectBackward0>) tensor([ 0.8237, -0.6942], grad_fn=<SliceBackward0>) tensor([ 0.3014, -0.1599], grad_fn=<SliceBackward0>)\n",
      "iter 57000, loss: 19.480382919311523\n",
      "tensor(0.0883, grad_fn=<SelectBackward0>) tensor(0.9951, grad_fn=<SelectBackward0>) tensor([-0.9167,  0.1077], grad_fn=<SliceBackward0>) tensor([0.2847, 0.8075], grad_fn=<SliceBackward0>)\n",
      "iter 57100, loss: 32.272499084472656\n",
      "tensor(-0.6170, grad_fn=<SelectBackward0>) tensor(0.1821, grad_fn=<SelectBackward0>) tensor([ 0.4678, -0.0261], grad_fn=<SliceBackward0>) tensor([ 0.0133, -0.0149], grad_fn=<SliceBackward0>)\n",
      "iter 57200, loss: 29.02035903930664\n",
      "tensor(0.0508, grad_fn=<SelectBackward0>) tensor(-0.7980, grad_fn=<SelectBackward0>) tensor([-0.6122,  0.7719], grad_fn=<SliceBackward0>) tensor([0.4648, 0.0015], grad_fn=<SliceBackward0>)\n",
      "iter 57300, loss: 48.4812126159668\n",
      "tensor(-0.5183, grad_fn=<SelectBackward0>) tensor(-0.5786, grad_fn=<SelectBackward0>) tensor([1.0033, 1.3842], grad_fn=<SliceBackward0>) tensor([ 0.2290, -0.2656], grad_fn=<SliceBackward0>)\n",
      "iter 57400, loss: 8.037810325622559\n",
      "tensor(-0.0814, grad_fn=<SelectBackward0>) tensor(2.2073, grad_fn=<SelectBackward0>) tensor([-0.2083,  0.1179], grad_fn=<SliceBackward0>) tensor([-0.7880,  0.2466], grad_fn=<SliceBackward0>)\n",
      "iter 57500, loss: 40.83234405517578\n",
      "tensor(-0.8937, grad_fn=<SelectBackward0>) tensor(-0.0111, grad_fn=<SelectBackward0>) tensor([-0.4369,  0.5052], grad_fn=<SliceBackward0>) tensor([ 0.2262, -0.1102], grad_fn=<SliceBackward0>)\n",
      "iter 57600, loss: 13.1693754196167\n",
      "tensor(-1.1575, grad_fn=<SelectBackward0>) tensor(1.8654, grad_fn=<SelectBackward0>) tensor([ 0.7839, -0.4534], grad_fn=<SliceBackward0>) tensor([0.4187, 0.8627], grad_fn=<SliceBackward0>)\n",
      "iter 57700, loss: 23.76526641845703\n",
      "tensor(-0.1521, grad_fn=<SelectBackward0>) tensor(0.9998, grad_fn=<SelectBackward0>) tensor([-0.0807, -1.6173], grad_fn=<SliceBackward0>) tensor([ 1.4831, -0.0452], grad_fn=<SliceBackward0>)\n",
      "iter 57800, loss: 7.123614311218262\n",
      "tensor(0.8960, grad_fn=<SelectBackward0>) tensor(0.8138, grad_fn=<SelectBackward0>) tensor([-0.2438, -0.0414], grad_fn=<SliceBackward0>) tensor([0.6618, 0.9070], grad_fn=<SliceBackward0>)\n",
      "iter 57900, loss: 44.384124755859375\n",
      "tensor(-0.6527, grad_fn=<SelectBackward0>) tensor(-1.7416, grad_fn=<SelectBackward0>) tensor([ 2.1657, -0.7350], grad_fn=<SliceBackward0>) tensor([0.3969, 0.2042], grad_fn=<SliceBackward0>)\n",
      "iter 58000, loss: 15.575604438781738\n",
      "tensor(0.5027, grad_fn=<SelectBackward0>) tensor(0.2213, grad_fn=<SelectBackward0>) tensor([-0.5929, -0.5899], grad_fn=<SliceBackward0>) tensor([ 0.0477, -1.1190], grad_fn=<SliceBackward0>)\n",
      "iter 58100, loss: 0.7451744675636292\n",
      "tensor(0.9331, grad_fn=<SelectBackward0>) tensor(0.9329, grad_fn=<SelectBackward0>) tensor([-2.0180, -0.9644], grad_fn=<SliceBackward0>) tensor([-0.5767, -1.7117], grad_fn=<SliceBackward0>)\n",
      "iter 58200, loss: 24.363327026367188\n",
      "tensor(-0.7770, grad_fn=<SelectBackward0>) tensor(0.0456, grad_fn=<SelectBackward0>) tensor([-1.1374, -0.0271], grad_fn=<SliceBackward0>) tensor([-1.0821, -0.6671], grad_fn=<SliceBackward0>)\n",
      "iter 58300, loss: 1.2684279680252075\n",
      "tensor(0.7739, grad_fn=<SelectBackward0>) tensor(0.2989, grad_fn=<SelectBackward0>) tensor([ 1.5009, -1.3622], grad_fn=<SliceBackward0>) tensor([ 1.2929, -0.0252], grad_fn=<SliceBackward0>)\n",
      "iter 58400, loss: 36.73786544799805\n",
      "tensor(1.1432, grad_fn=<SelectBackward0>) tensor(-0.6487, grad_fn=<SelectBackward0>) tensor([-0.0970,  1.2145], grad_fn=<SliceBackward0>) tensor([ 0.2214, -1.4475], grad_fn=<SliceBackward0>)\n",
      "iter 58500, loss: 11.504728317260742\n",
      "tensor(2.4297, grad_fn=<SelectBackward0>) tensor(-0.2479, grad_fn=<SelectBackward0>) tensor([-0.4963, -1.1140], grad_fn=<SliceBackward0>) tensor([-0.7858,  0.5887], grad_fn=<SliceBackward0>)\n",
      "iter 58600, loss: 2.9558122158050537\n",
      "tensor(0.6905, grad_fn=<SelectBackward0>) tensor(0.8362, grad_fn=<SelectBackward0>) tensor([-0.4599,  0.3574], grad_fn=<SliceBackward0>) tensor([-0.3676, -0.8500], grad_fn=<SliceBackward0>)\n",
      "iter 58700, loss: 8.994928359985352\n",
      "tensor(2.0273, grad_fn=<SelectBackward0>) tensor(0.8886, grad_fn=<SelectBackward0>) tensor([0.8997, 0.3082], grad_fn=<SliceBackward0>) tensor([-0.9151,  0.5098], grad_fn=<SliceBackward0>)\n",
      "iter 58800, loss: 19.3663387298584\n",
      "tensor(-0.6656, grad_fn=<SelectBackward0>) tensor(0.0505, grad_fn=<SelectBackward0>) tensor([-0.1128,  0.8167], grad_fn=<SliceBackward0>) tensor([-0.5871,  0.5250], grad_fn=<SliceBackward0>)\n",
      "iter 58900, loss: 14.0361967086792\n",
      "tensor(1.4263, grad_fn=<SelectBackward0>) tensor(-0.3520, grad_fn=<SelectBackward0>) tensor([-0.4180, -0.6067], grad_fn=<SliceBackward0>) tensor([-0.6398, -0.2156], grad_fn=<SliceBackward0>)\n",
      "iter 59000, loss: 29.00173568725586\n",
      "tensor(1.2390, grad_fn=<SelectBackward0>) tensor(-1.0364, grad_fn=<SelectBackward0>) tensor([ 0.2177, -0.2604], grad_fn=<SliceBackward0>) tensor([0.5808, 1.1453], grad_fn=<SliceBackward0>)\n",
      "iter 59100, loss: 11.435497283935547\n",
      "tensor(-0.1865, grad_fn=<SelectBackward0>) tensor(0.5756, grad_fn=<SelectBackward0>) tensor([ 0.3373, -1.1421], grad_fn=<SliceBackward0>) tensor([ 0.4990, -0.2702], grad_fn=<SliceBackward0>)\n",
      "iter 59200, loss: 33.220916748046875\n",
      "tensor(0.7356, grad_fn=<SelectBackward0>) tensor(-1.4987, grad_fn=<SelectBackward0>) tensor([-0.1758, -0.1790], grad_fn=<SliceBackward0>) tensor([1.5756, 0.6769], grad_fn=<SliceBackward0>)\n",
      "iter 59300, loss: 8.097662925720215\n",
      "tensor(-0.2186, grad_fn=<SelectBackward0>) tensor(0.5346, grad_fn=<SelectBackward0>) tensor([-0.3309,  1.2793], grad_fn=<SliceBackward0>) tensor([-0.9295,  1.4847], grad_fn=<SliceBackward0>)\n",
      "iter 59400, loss: 33.64002227783203\n",
      "tensor(-0.8123, grad_fn=<SelectBackward0>) tensor(-0.7921, grad_fn=<SelectBackward0>) tensor([ 0.7734, -0.2925], grad_fn=<SliceBackward0>) tensor([-0.8822,  0.2368], grad_fn=<SliceBackward0>)\n",
      "iter 59500, loss: 5.590479373931885\n",
      "tensor(0.0011, grad_fn=<SelectBackward0>) tensor(1.5898, grad_fn=<SelectBackward0>) tensor([ 1.1441, -0.6860], grad_fn=<SliceBackward0>) tensor([-0.2310, -0.7530], grad_fn=<SliceBackward0>)\n",
      "iter 59600, loss: 2.8219199180603027\n",
      "tensor(1.3341, grad_fn=<SelectBackward0>) tensor(0.8955, grad_fn=<SelectBackward0>) tensor([-1.3587,  0.0558], grad_fn=<SliceBackward0>) tensor([-0.2021, -0.6734], grad_fn=<SliceBackward0>)\n",
      "iter 59700, loss: 1.6696834564208984\n",
      "tensor(-0.7583, grad_fn=<SelectBackward0>) tensor(4.2034, grad_fn=<SelectBackward0>) tensor([ 1.0714, -0.7405], grad_fn=<SliceBackward0>) tensor([ 0.2536, -0.1210], grad_fn=<SliceBackward0>)\n",
      "iter 59800, loss: 11.629814147949219\n",
      "tensor(-0.2060, grad_fn=<SelectBackward0>) tensor(0.0005, grad_fn=<SelectBackward0>) tensor([ 1.0444, -0.8398], grad_fn=<SliceBackward0>) tensor([1.2480, 0.1838], grad_fn=<SliceBackward0>)\n",
      "iter 59900, loss: 18.3236083984375\n",
      "tensor(-1.1108, grad_fn=<SelectBackward0>) tensor(1.4369, grad_fn=<SelectBackward0>) tensor([0.0343, 0.6032], grad_fn=<SliceBackward0>) tensor([1.9534, 1.9057], grad_fn=<SliceBackward0>)\n",
      "iter 60000, loss: 13.606147766113281\n",
      "tensor(-0.5644, grad_fn=<SelectBackward0>) tensor(0.0207, grad_fn=<SelectBackward0>) tensor([-1.2075, -1.2911], grad_fn=<SliceBackward0>) tensor([ 0.6345, -0.0341], grad_fn=<SliceBackward0>)\n",
      "iter 60100, loss: 3.7238550186157227\n",
      "tensor(1.3382, grad_fn=<SelectBackward0>) tensor(-0.2263, grad_fn=<SelectBackward0>) tensor([-1.9346, -0.3537], grad_fn=<SliceBackward0>) tensor([-2.7634,  0.2195], grad_fn=<SliceBackward0>)\n",
      "iter 60200, loss: 7.128286361694336\n",
      "tensor(1.0524, grad_fn=<SelectBackward0>) tensor(0.8087, grad_fn=<SelectBackward0>) tensor([-0.8045,  0.4685], grad_fn=<SliceBackward0>) tensor([-0.7395,  0.1118], grad_fn=<SliceBackward0>)\n",
      "iter 60300, loss: 23.633602142333984\n",
      "tensor(-0.1095, grad_fn=<SelectBackward0>) tensor(0.4100, grad_fn=<SelectBackward0>) tensor([0.2761, 1.1726], grad_fn=<SliceBackward0>) tensor([ 0.9249, -0.0011], grad_fn=<SliceBackward0>)\n",
      "iter 60400, loss: 31.930753707885742\n",
      "tensor(0.6627, grad_fn=<SelectBackward0>) tensor(0.3512, grad_fn=<SelectBackward0>) tensor([1.3190, 0.0554], grad_fn=<SliceBackward0>) tensor([-0.6738, -1.2698], grad_fn=<SliceBackward0>)\n",
      "iter 60500, loss: 32.05817413330078\n",
      "tensor(0.6363, grad_fn=<SelectBackward0>) tensor(0.6121, grad_fn=<SelectBackward0>) tensor([-2.1264, -0.9759], grad_fn=<SliceBackward0>) tensor([0.3164, 1.1630], grad_fn=<SliceBackward0>)\n",
      "iter 60600, loss: 1.985460638999939\n",
      "tensor(0.8214, grad_fn=<SelectBackward0>) tensor(0.3639, grad_fn=<SelectBackward0>) tensor([0.9788, 1.2727], grad_fn=<SliceBackward0>) tensor([0.7563, 0.6441], grad_fn=<SliceBackward0>)\n",
      "iter 60700, loss: 11.890951156616211\n",
      "tensor(0.1290, grad_fn=<SelectBackward0>) tensor(1.3381, grad_fn=<SelectBackward0>) tensor([ 0.1382, -0.2716], grad_fn=<SliceBackward0>) tensor([ 0.2412, -0.9550], grad_fn=<SliceBackward0>)\n",
      "iter 60800, loss: 10.55569076538086\n",
      "tensor(-0.1060, grad_fn=<SelectBackward0>) tensor(1.0483, grad_fn=<SelectBackward0>) tensor([ 0.9196, -1.1557], grad_fn=<SliceBackward0>) tensor([ 0.5429, -0.5244], grad_fn=<SliceBackward0>)\n",
      "iter 60900, loss: 36.691436767578125\n",
      "tensor(-0.2334, grad_fn=<SelectBackward0>) tensor(-0.5663, grad_fn=<SelectBackward0>) tensor([-1.0160,  0.8314], grad_fn=<SliceBackward0>) tensor([-0.8202, -0.6204], grad_fn=<SliceBackward0>)\n",
      "iter 61000, loss: 5.313496112823486\n",
      "tensor(0.6343, grad_fn=<SelectBackward0>) tensor(1.2826, grad_fn=<SelectBackward0>) tensor([-0.4254,  1.8715], grad_fn=<SliceBackward0>) tensor([-1.5991,  0.2540], grad_fn=<SliceBackward0>)\n",
      "iter 61100, loss: 16.393800735473633\n",
      "tensor(0.1144, grad_fn=<SelectBackward0>) tensor(-0.7639, grad_fn=<SelectBackward0>) tensor([-2.9046,  0.5294], grad_fn=<SliceBackward0>) tensor([-0.8525,  0.0226], grad_fn=<SliceBackward0>)\n",
      "iter 61200, loss: 73.50791931152344\n",
      "tensor(0.9445, grad_fn=<SelectBackward0>) tensor(-0.9542, grad_fn=<SelectBackward0>) tensor([-1.2360, -0.2389], grad_fn=<SliceBackward0>) tensor([1.3145, 1.5508], grad_fn=<SliceBackward0>)\n",
      "iter 61300, loss: 42.53074645996094\n",
      "tensor(-0.5490, grad_fn=<SelectBackward0>) tensor(-1.2349, grad_fn=<SelectBackward0>) tensor([-0.3570,  0.7955], grad_fn=<SliceBackward0>) tensor([-0.8144,  0.5351], grad_fn=<SliceBackward0>)\n",
      "iter 61400, loss: 45.5267448425293\n",
      "tensor(-0.2233, grad_fn=<SelectBackward0>) tensor(-1.9869, grad_fn=<SelectBackward0>) tensor([ 0.4472, -0.4908], grad_fn=<SliceBackward0>) tensor([ 0.9992, -1.4944], grad_fn=<SliceBackward0>)\n",
      "iter 61500, loss: 26.453922271728516\n",
      "tensor(-0.0765, grad_fn=<SelectBackward0>) tensor(-0.3877, grad_fn=<SelectBackward0>) tensor([-1.4691, -0.9641], grad_fn=<SliceBackward0>) tensor([ 0.3709, -0.4518], grad_fn=<SliceBackward0>)\n",
      "iter 61600, loss: 1.5988355875015259\n",
      "tensor(0.2712, grad_fn=<SelectBackward0>) tensor(1.9953, grad_fn=<SelectBackward0>) tensor([0.2726, 1.3652], grad_fn=<SliceBackward0>) tensor([-0.3644,  1.2523], grad_fn=<SliceBackward0>)\n",
      "iter 61700, loss: 1.151489019393921\n",
      "tensor(-0.6118, grad_fn=<SelectBackward0>) tensor(-0.6005, grad_fn=<SelectBackward0>) tensor([ 0.4314, -0.7642], grad_fn=<SliceBackward0>) tensor([ 1.7796, -0.6637], grad_fn=<SliceBackward0>)\n",
      "iter 61800, loss: 5.462530136108398\n",
      "tensor(0.9803, grad_fn=<SelectBackward0>) tensor(0.3035, grad_fn=<SelectBackward0>) tensor([-0.9969,  1.4858], grad_fn=<SliceBackward0>) tensor([-0.4888,  0.7844], grad_fn=<SliceBackward0>)\n",
      "iter 61900, loss: 15.415114402770996\n",
      "tensor(0.4642, grad_fn=<SelectBackward0>) tensor(1.0351, grad_fn=<SelectBackward0>) tensor([-1.5752, -3.2644], grad_fn=<SliceBackward0>) tensor([ 0.0867, -0.2774], grad_fn=<SliceBackward0>)\n",
      "iter 62000, loss: 30.233808517456055\n",
      "tensor(0.3644, grad_fn=<SelectBackward0>) tensor(0.6253, grad_fn=<SelectBackward0>) tensor([0.4688, 0.1644], grad_fn=<SliceBackward0>) tensor([-1.8570,  0.4114], grad_fn=<SliceBackward0>)\n",
      "iter 62100, loss: 7.33271598815918\n",
      "tensor(2.2224, grad_fn=<SelectBackward0>) tensor(0.0989, grad_fn=<SelectBackward0>) tensor([0.3522, 0.0592], grad_fn=<SliceBackward0>) tensor([ 0.2562, -0.0159], grad_fn=<SliceBackward0>)\n",
      "iter 62200, loss: 2.291726589202881\n",
      "tensor(1.3744, grad_fn=<SelectBackward0>) tensor(1.3097, grad_fn=<SelectBackward0>) tensor([-0.3546,  1.3456], grad_fn=<SliceBackward0>) tensor([0.0022, 0.6952], grad_fn=<SliceBackward0>)\n",
      "iter 62300, loss: 0.9639253616333008\n",
      "tensor(0.8387, grad_fn=<SelectBackward0>) tensor(2.5817, grad_fn=<SelectBackward0>) tensor([-0.3531,  1.0161], grad_fn=<SliceBackward0>) tensor([-0.0847,  1.4034], grad_fn=<SliceBackward0>)\n",
      "iter 62400, loss: 45.82516098022461\n",
      "tensor(-2.3177, grad_fn=<SelectBackward0>) tensor(0.6361, grad_fn=<SelectBackward0>) tensor([-1.0461, -0.5137], grad_fn=<SliceBackward0>) tensor([-0.4302,  0.1349], grad_fn=<SliceBackward0>)\n",
      "iter 62500, loss: 54.01283645629883\n",
      "tensor(-1.2620, grad_fn=<SelectBackward0>) tensor(-1.2115, grad_fn=<SelectBackward0>) tensor([-2.1651, -1.7796], grad_fn=<SliceBackward0>) tensor([-0.8665,  0.1368], grad_fn=<SliceBackward0>)\n",
      "iter 62600, loss: 4.229098320007324\n",
      "tensor(1.2695, grad_fn=<SelectBackward0>) tensor(0.7514, grad_fn=<SelectBackward0>) tensor([ 0.7816, -0.3682], grad_fn=<SliceBackward0>) tensor([0.3556, 0.6017], grad_fn=<SliceBackward0>)\n",
      "iter 62700, loss: 8.73702621459961\n",
      "tensor(0.7209, grad_fn=<SelectBackward0>) tensor(0.6141, grad_fn=<SelectBackward0>) tensor([0.3672, 0.3869], grad_fn=<SliceBackward0>) tensor([-0.5754,  0.2058], grad_fn=<SliceBackward0>)\n",
      "iter 62800, loss: 44.647274017333984\n",
      "tensor(0.0122, grad_fn=<SelectBackward0>) tensor(-0.0716, grad_fn=<SelectBackward0>) tensor([-0.9489,  0.4934], grad_fn=<SliceBackward0>) tensor([-0.2125, -1.8167], grad_fn=<SliceBackward0>)\n",
      "iter 62900, loss: 59.63932418823242\n",
      "tensor(-0.5260, grad_fn=<SelectBackward0>) tensor(0.3784, grad_fn=<SelectBackward0>) tensor([-1.4056,  0.1609], grad_fn=<SliceBackward0>) tensor([1.1613, 0.8393], grad_fn=<SliceBackward0>)\n",
      "iter 63000, loss: 17.914520263671875\n",
      "tensor(0.3843, grad_fn=<SelectBackward0>) tensor(0.7370, grad_fn=<SelectBackward0>) tensor([ 0.6288, -0.0201], grad_fn=<SliceBackward0>) tensor([-0.1366, -0.9700], grad_fn=<SliceBackward0>)\n",
      "iter 63100, loss: 6.808554649353027\n",
      "tensor(-0.8984, grad_fn=<SelectBackward0>) tensor(2.9293, grad_fn=<SelectBackward0>) tensor([-0.0216, -0.5199], grad_fn=<SliceBackward0>) tensor([-0.2416, -1.0118], grad_fn=<SliceBackward0>)\n",
      "iter 63200, loss: 26.269086837768555\n",
      "tensor(-1.0875, grad_fn=<SelectBackward0>) tensor(1.1264, grad_fn=<SelectBackward0>) tensor([1.1535, 0.5834], grad_fn=<SliceBackward0>) tensor([ 0.8367, -1.0001], grad_fn=<SliceBackward0>)\n",
      "iter 63300, loss: 11.924518585205078\n",
      "tensor(0.2116, grad_fn=<SelectBackward0>) tensor(0.6867, grad_fn=<SelectBackward0>) tensor([ 1.6137, -0.3145], grad_fn=<SliceBackward0>) tensor([0.7168, 0.4615], grad_fn=<SliceBackward0>)\n",
      "iter 63400, loss: 36.58277893066406\n",
      "tensor(-0.8378, grad_fn=<SelectBackward0>) tensor(2.3535, grad_fn=<SelectBackward0>) tensor([1.4977, 0.2470], grad_fn=<SliceBackward0>) tensor([-1.5911, -0.6707], grad_fn=<SliceBackward0>)\n",
      "iter 63500, loss: 29.235734939575195\n",
      "tensor(-1.3913, grad_fn=<SelectBackward0>) tensor(1.8871, grad_fn=<SelectBackward0>) tensor([-0.7496,  0.4084], grad_fn=<SliceBackward0>) tensor([-0.1769, -1.3034], grad_fn=<SliceBackward0>)\n",
      "iter 63600, loss: 18.821008682250977\n",
      "tensor(-1.5752, grad_fn=<SelectBackward0>) tensor(1.3704, grad_fn=<SelectBackward0>) tensor([-0.4963, -0.5151], grad_fn=<SliceBackward0>) tensor([ 0.7016, -1.1358], grad_fn=<SliceBackward0>)\n",
      "iter 63700, loss: 9.738967895507812\n",
      "tensor(0.1648, grad_fn=<SelectBackward0>) tensor(0.3616, grad_fn=<SelectBackward0>) tensor([-2.2177, -1.1879], grad_fn=<SliceBackward0>) tensor([-0.4426, -0.7767], grad_fn=<SliceBackward0>)\n",
      "iter 63800, loss: 14.556041717529297\n",
      "tensor(0.8525, grad_fn=<SelectBackward0>) tensor(0.7650, grad_fn=<SelectBackward0>) tensor([0.8947, 0.0496], grad_fn=<SliceBackward0>) tensor([-0.2378,  0.5854], grad_fn=<SliceBackward0>)\n",
      "iter 63900, loss: 35.93529510498047\n",
      "tensor(-0.0578, grad_fn=<SelectBackward0>) tensor(1.7232, grad_fn=<SelectBackward0>) tensor([-0.5612,  0.9833], grad_fn=<SliceBackward0>) tensor([ 1.3513, -1.7976], grad_fn=<SliceBackward0>)\n",
      "iter 64000, loss: 33.072296142578125\n",
      "tensor(-0.0567, grad_fn=<SelectBackward0>) tensor(-0.1735, grad_fn=<SelectBackward0>) tensor([-0.6908,  0.0871], grad_fn=<SliceBackward0>) tensor([ 0.1327, -0.7554], grad_fn=<SliceBackward0>)\n",
      "iter 64100, loss: 55.61406707763672\n",
      "tensor(-9.1369e-05, grad_fn=<SelectBackward0>) tensor(-1.4197, grad_fn=<SelectBackward0>) tensor([ 1.1930, -1.6579], grad_fn=<SliceBackward0>) tensor([-0.3150, -0.1886], grad_fn=<SliceBackward0>)\n",
      "iter 64200, loss: 39.870391845703125\n",
      "tensor(-0.6324, grad_fn=<SelectBackward0>) tensor(-0.0749, grad_fn=<SelectBackward0>) tensor([-0.4069, -0.6376], grad_fn=<SliceBackward0>) tensor([ 0.5965, -0.0321], grad_fn=<SliceBackward0>)\n",
      "iter 64300, loss: 21.668838500976562\n",
      "tensor(-0.0544, grad_fn=<SelectBackward0>) tensor(1.4375, grad_fn=<SelectBackward0>) tensor([0.5974, 0.2986], grad_fn=<SliceBackward0>) tensor([-0.0258, -1.6978], grad_fn=<SliceBackward0>)\n",
      "iter 64400, loss: 23.272411346435547\n",
      "tensor(0.6571, grad_fn=<SelectBackward0>) tensor(-0.2251, grad_fn=<SelectBackward0>) tensor([-0.1096,  0.0807], grad_fn=<SliceBackward0>) tensor([ 0.2884, -0.2006], grad_fn=<SliceBackward0>)\n",
      "iter 64500, loss: 7.775367736816406\n",
      "tensor(1.3424, grad_fn=<SelectBackward0>) tensor(1.4995, grad_fn=<SelectBackward0>) tensor([ 0.6563, -1.8408], grad_fn=<SliceBackward0>) tensor([1.0655, 0.5014], grad_fn=<SliceBackward0>)\n",
      "iter 64600, loss: 30.82903480529785\n",
      "tensor(-1.5765, grad_fn=<SelectBackward0>) tensor(-0.0156, grad_fn=<SelectBackward0>) tensor([-0.2756,  1.6477], grad_fn=<SliceBackward0>) tensor([-0.0276, -1.3064], grad_fn=<SliceBackward0>)\n",
      "iter 64700, loss: 33.77938461303711\n",
      "tensor(-1.3744, grad_fn=<SelectBackward0>) tensor(0.8001, grad_fn=<SelectBackward0>) tensor([-0.0714,  0.0634], grad_fn=<SliceBackward0>) tensor([0.1448, 0.2781], grad_fn=<SliceBackward0>)\n",
      "iter 64800, loss: 13.003783226013184\n",
      "tensor(-2.1515, grad_fn=<SelectBackward0>) tensor(1.8020, grad_fn=<SelectBackward0>) tensor([-2.1080,  0.9511], grad_fn=<SliceBackward0>) tensor([-0.0447,  1.3641], grad_fn=<SliceBackward0>)\n",
      "iter 64900, loss: 35.97398376464844\n",
      "tensor(0.3113, grad_fn=<SelectBackward0>) tensor(0.5104, grad_fn=<SelectBackward0>) tensor([-0.7908, -0.8731], grad_fn=<SliceBackward0>) tensor([0.7722, 0.6982], grad_fn=<SliceBackward0>)\n",
      "iter 65000, loss: 2.599231004714966\n",
      "tensor(0.8952, grad_fn=<SelectBackward0>) tensor(2.5462, grad_fn=<SelectBackward0>) tensor([-0.0683, -0.1355], grad_fn=<SliceBackward0>) tensor([-0.5665,  0.1117], grad_fn=<SliceBackward0>)\n",
      "iter 65100, loss: 11.207447052001953\n",
      "tensor(0.2701, grad_fn=<SelectBackward0>) tensor(-0.2721, grad_fn=<SelectBackward0>) tensor([ 0.2340, -0.3122], grad_fn=<SliceBackward0>) tensor([-1.2455, -0.7479], grad_fn=<SliceBackward0>)\n",
      "iter 65200, loss: 2.5427634716033936\n",
      "tensor(1.9835, grad_fn=<SelectBackward0>) tensor(0.8154, grad_fn=<SelectBackward0>) tensor([-0.4858, -1.3705], grad_fn=<SliceBackward0>) tensor([ 1.0304, -0.9488], grad_fn=<SliceBackward0>)\n",
      "iter 65300, loss: 35.80933380126953\n",
      "tensor(1.2052, grad_fn=<SelectBackward0>) tensor(-0.4268, grad_fn=<SelectBackward0>) tensor([ 0.0558, -1.5505], grad_fn=<SliceBackward0>) tensor([0.1352, 0.7214], grad_fn=<SliceBackward0>)\n",
      "iter 65400, loss: 21.4498291015625\n",
      "tensor(-1.1022, grad_fn=<SelectBackward0>) tensor(1.4958, grad_fn=<SelectBackward0>) tensor([0.2069, 0.0742], grad_fn=<SliceBackward0>) tensor([-1.9475, -0.5138], grad_fn=<SliceBackward0>)\n",
      "iter 65500, loss: 7.581916809082031\n",
      "tensor(2.1461, grad_fn=<SelectBackward0>) tensor(0.9246, grad_fn=<SelectBackward0>) tensor([-0.7270,  1.0044], grad_fn=<SliceBackward0>) tensor([-0.0027,  1.3630], grad_fn=<SliceBackward0>)\n",
      "iter 65600, loss: 21.273773193359375\n",
      "tensor(-0.6149, grad_fn=<SelectBackward0>) tensor(0.1595, grad_fn=<SelectBackward0>) tensor([-1.0900,  0.1678], grad_fn=<SliceBackward0>) tensor([-1.1206,  1.7955], grad_fn=<SliceBackward0>)\n",
      "iter 65700, loss: 48.4938850402832\n",
      "tensor(1.3714, grad_fn=<SelectBackward0>) tensor(-0.0558, grad_fn=<SelectBackward0>) tensor([-1.4156, -2.1610], grad_fn=<SliceBackward0>) tensor([1.0636, 0.1187], grad_fn=<SliceBackward0>)\n",
      "iter 65800, loss: 3.5917463302612305\n",
      "tensor(0.5825, grad_fn=<SelectBackward0>) tensor(0.3018, grad_fn=<SelectBackward0>) tensor([1.7711, 0.4011], grad_fn=<SliceBackward0>) tensor([1.3768, 0.1146], grad_fn=<SliceBackward0>)\n",
      "iter 65900, loss: 2.572049856185913\n",
      "tensor(0.8985, grad_fn=<SelectBackward0>) tensor(1.5783, grad_fn=<SelectBackward0>) tensor([ 0.5774, -0.5131], grad_fn=<SliceBackward0>) tensor([ 1.1750, -0.7500], grad_fn=<SliceBackward0>)\n",
      "iter 66000, loss: 8.533050537109375\n",
      "tensor(0.1183, grad_fn=<SelectBackward0>) tensor(4.0797, grad_fn=<SelectBackward0>) tensor([-1.6984,  0.6362], grad_fn=<SliceBackward0>) tensor([ 0.3442, -0.0071], grad_fn=<SliceBackward0>)\n",
      "iter 66100, loss: 42.390342712402344\n",
      "tensor(-1.0170, grad_fn=<SelectBackward0>) tensor(0.0855, grad_fn=<SelectBackward0>) tensor([ 0.5138, -0.4588], grad_fn=<SliceBackward0>) tensor([0.3498, 0.7348], grad_fn=<SliceBackward0>)\n",
      "iter 66200, loss: 11.735204696655273\n",
      "tensor(0.2092, grad_fn=<SelectBackward0>) tensor(1.4617, grad_fn=<SelectBackward0>) tensor([0.1202, 0.0076], grad_fn=<SliceBackward0>) tensor([0.7992, 0.4672], grad_fn=<SliceBackward0>)\n",
      "iter 66300, loss: 38.192771911621094\n",
      "tensor(0.3656, grad_fn=<SelectBackward0>) tensor(-1.7285, grad_fn=<SelectBackward0>) tensor([ 0.8252, -0.9920], grad_fn=<SliceBackward0>) tensor([2.1947, 0.5754], grad_fn=<SliceBackward0>)\n",
      "iter 66400, loss: 2.64282488822937\n",
      "tensor(0.6015, grad_fn=<SelectBackward0>) tensor(-0.3861, grad_fn=<SelectBackward0>) tensor([ 1.6086, -1.1961], grad_fn=<SliceBackward0>) tensor([0.3361, 0.9607], grad_fn=<SliceBackward0>)\n",
      "iter 66500, loss: 4.382983684539795\n",
      "tensor(0.4261, grad_fn=<SelectBackward0>) tensor(2.1270, grad_fn=<SelectBackward0>) tensor([0.9432, 1.4620], grad_fn=<SliceBackward0>) tensor([-0.1724, -0.1828], grad_fn=<SliceBackward0>)\n",
      "iter 66600, loss: 28.09457015991211\n",
      "tensor(0.6351, grad_fn=<SelectBackward0>) tensor(0.9614, grad_fn=<SelectBackward0>) tensor([-1.1704,  0.0702], grad_fn=<SliceBackward0>) tensor([ 1.0572, -0.8279], grad_fn=<SliceBackward0>)\n",
      "iter 66700, loss: 22.19512939453125\n",
      "tensor(-0.8721, grad_fn=<SelectBackward0>) tensor(0.3960, grad_fn=<SelectBackward0>) tensor([ 1.0139, -2.2897], grad_fn=<SliceBackward0>) tensor([ 1.4601, -0.1021], grad_fn=<SliceBackward0>)\n",
      "iter 66800, loss: 30.83606719970703\n",
      "tensor(0.6391, grad_fn=<SelectBackward0>) tensor(1.6884, grad_fn=<SelectBackward0>) tensor([1.3544, 0.5775], grad_fn=<SliceBackward0>) tensor([-0.7043, -1.7171], grad_fn=<SliceBackward0>)\n",
      "iter 66900, loss: 33.306148529052734\n",
      "tensor(0.1642, grad_fn=<SelectBackward0>) tensor(-1.3774, grad_fn=<SelectBackward0>) tensor([-0.0905,  0.3668], grad_fn=<SliceBackward0>) tensor([-1.5460, -0.4012], grad_fn=<SliceBackward0>)\n",
      "iter 67000, loss: 42.39414596557617\n",
      "tensor(-0.3670, grad_fn=<SelectBackward0>) tensor(-0.0875, grad_fn=<SelectBackward0>) tensor([-1.1396, -0.3998], grad_fn=<SliceBackward0>) tensor([-0.1425,  1.2907], grad_fn=<SliceBackward0>)\n",
      "iter 67100, loss: 30.243770599365234\n",
      "tensor(0.7506, grad_fn=<SelectBackward0>) tensor(-0.0922, grad_fn=<SelectBackward0>) tensor([-0.1776,  0.9511], grad_fn=<SliceBackward0>) tensor([ 0.0497, -0.7669], grad_fn=<SliceBackward0>)\n",
      "iter 67200, loss: 22.215879440307617\n",
      "tensor(1.3159, grad_fn=<SelectBackward0>) tensor(-0.9821, grad_fn=<SelectBackward0>) tensor([ 0.7372, -0.7844], grad_fn=<SliceBackward0>) tensor([0.3590, 0.0084], grad_fn=<SliceBackward0>)\n",
      "iter 67300, loss: 47.729087829589844\n",
      "tensor(-0.8008, grad_fn=<SelectBackward0>) tensor(0.3608, grad_fn=<SelectBackward0>) tensor([-1.0607,  1.1545], grad_fn=<SliceBackward0>) tensor([ 0.5643, -0.8612], grad_fn=<SliceBackward0>)\n",
      "iter 67400, loss: 37.815189361572266\n",
      "tensor(0.1600, grad_fn=<SelectBackward0>) tensor(-1.3383, grad_fn=<SelectBackward0>) tensor([-0.5761, -0.6161], grad_fn=<SliceBackward0>) tensor([0.4949, 0.4363], grad_fn=<SliceBackward0>)\n",
      "iter 67500, loss: 8.180233001708984\n",
      "tensor(0.5242, grad_fn=<SelectBackward0>) tensor(-2.0787, grad_fn=<SelectBackward0>) tensor([-1.2661, -0.6254], grad_fn=<SliceBackward0>) tensor([-1.3703, -2.6832], grad_fn=<SliceBackward0>)\n",
      "iter 67600, loss: 18.50098419189453\n",
      "tensor(2.0855, grad_fn=<SelectBackward0>) tensor(0.2654, grad_fn=<SelectBackward0>) tensor([ 1.1431, -1.8163], grad_fn=<SliceBackward0>) tensor([-1.4035, -0.4034], grad_fn=<SliceBackward0>)\n",
      "iter 67700, loss: 5.906444072723389\n",
      "tensor(-0.0796, grad_fn=<SelectBackward0>) tensor(1.2945, grad_fn=<SelectBackward0>) tensor([-0.4999,  1.6665], grad_fn=<SliceBackward0>) tensor([0.5386, 0.5362], grad_fn=<SliceBackward0>)\n",
      "iter 67800, loss: 14.474251747131348\n",
      "tensor(-0.3078, grad_fn=<SelectBackward0>) tensor(-0.3106, grad_fn=<SelectBackward0>) tensor([-1.0745,  0.7449], grad_fn=<SliceBackward0>) tensor([-0.3267,  1.1141], grad_fn=<SliceBackward0>)\n",
      "iter 67900, loss: 8.926094055175781\n",
      "tensor(1.2959, grad_fn=<SelectBackward0>) tensor(0.2630, grad_fn=<SelectBackward0>) tensor([ 1.3816, -0.2034], grad_fn=<SliceBackward0>) tensor([-0.1003,  0.6829], grad_fn=<SliceBackward0>)\n",
      "iter 68000, loss: 23.181203842163086\n",
      "tensor(1.5186, grad_fn=<SelectBackward0>) tensor(-0.4932, grad_fn=<SelectBackward0>) tensor([ 0.3464, -1.1107], grad_fn=<SliceBackward0>) tensor([0.1443, 1.2377], grad_fn=<SliceBackward0>)\n",
      "iter 68100, loss: 0.28558218479156494\n",
      "tensor(1.0279, grad_fn=<SelectBackward0>) tensor(3.7398, grad_fn=<SelectBackward0>) tensor([-1.0255, -1.7482], grad_fn=<SliceBackward0>) tensor([-0.1007,  0.1909], grad_fn=<SliceBackward0>)\n",
      "iter 68200, loss: 10.66300106048584\n",
      "tensor(-1.3380, grad_fn=<SelectBackward0>) tensor(1.1441, grad_fn=<SelectBackward0>) tensor([-0.2664, -0.7779], grad_fn=<SliceBackward0>) tensor([ 0.2154, -0.2130], grad_fn=<SliceBackward0>)\n",
      "iter 68300, loss: 28.8131160736084\n",
      "tensor(-0.7672, grad_fn=<SelectBackward0>) tensor(0.0415, grad_fn=<SelectBackward0>) tensor([-1.6616,  0.6067], grad_fn=<SliceBackward0>) tensor([-0.5420,  0.0262], grad_fn=<SliceBackward0>)\n",
      "iter 68400, loss: 53.002201080322266\n",
      "tensor(-0.6399, grad_fn=<SelectBackward0>) tensor(1.4120, grad_fn=<SelectBackward0>) tensor([-0.6346, -1.6833], grad_fn=<SliceBackward0>) tensor([-0.1784,  1.2060], grad_fn=<SliceBackward0>)\n",
      "iter 68500, loss: 11.792237281799316\n",
      "tensor(1.0626, grad_fn=<SelectBackward0>) tensor(-0.9179, grad_fn=<SelectBackward0>) tensor([-0.8084, -0.6538], grad_fn=<SliceBackward0>) tensor([-1.1672, -1.3554], grad_fn=<SliceBackward0>)\n",
      "iter 68600, loss: 25.6732120513916\n",
      "tensor(-1.2508, grad_fn=<SelectBackward0>) tensor(0.2475, grad_fn=<SelectBackward0>) tensor([ 0.8161, -1.8570], grad_fn=<SliceBackward0>) tensor([ 0.6791, -0.0214], grad_fn=<SliceBackward0>)\n",
      "iter 68700, loss: 0.14344154298305511\n",
      "tensor(0.7814, grad_fn=<SelectBackward0>) tensor(2.4423, grad_fn=<SelectBackward0>) tensor([0.9410, 1.2441], grad_fn=<SliceBackward0>) tensor([1.3799, 0.6411], grad_fn=<SliceBackward0>)\n",
      "iter 68800, loss: 19.2239933013916\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>) tensor(-0.7861, grad_fn=<SelectBackward0>) tensor([-0.5980, -2.3752], grad_fn=<SliceBackward0>) tensor([ 0.0734, -0.5099], grad_fn=<SliceBackward0>)\n",
      "iter 68900, loss: 10.222494125366211\n",
      "tensor(1.3887, grad_fn=<SelectBackward0>) tensor(0.7119, grad_fn=<SelectBackward0>) tensor([-0.8579, -0.3647], grad_fn=<SliceBackward0>) tensor([ 1.4616, -0.9555], grad_fn=<SliceBackward0>)\n",
      "iter 69000, loss: 19.876928329467773\n",
      "tensor(0.4977, grad_fn=<SelectBackward0>) tensor(-0.6295, grad_fn=<SelectBackward0>) tensor([0.0165, 1.2310], grad_fn=<SliceBackward0>) tensor([1.4505, 0.9865], grad_fn=<SliceBackward0>)\n",
      "iter 69100, loss: 28.159982681274414\n",
      "tensor(0.7928, grad_fn=<SelectBackward0>) tensor(-0.5715, grad_fn=<SelectBackward0>) tensor([-0.0617,  0.1814], grad_fn=<SliceBackward0>) tensor([-0.1516, -1.0549], grad_fn=<SliceBackward0>)\n",
      "iter 69200, loss: 44.86241912841797\n",
      "tensor(0.9734, grad_fn=<SelectBackward0>) tensor(1.0351, grad_fn=<SelectBackward0>) tensor([1.8206, 0.0163], grad_fn=<SliceBackward0>) tensor([-1.3690,  0.8549], grad_fn=<SliceBackward0>)\n",
      "iter 69300, loss: 0.16390396654605865\n",
      "tensor(1.3975, grad_fn=<SelectBackward0>) tensor(1.2188, grad_fn=<SelectBackward0>) tensor([2.5839, 0.8413], grad_fn=<SliceBackward0>) tensor([ 1.0444, -0.0021], grad_fn=<SliceBackward0>)\n",
      "iter 69400, loss: 4.124464988708496\n",
      "tensor(0.1092, grad_fn=<SelectBackward0>) tensor(2.6297, grad_fn=<SelectBackward0>) tensor([ 0.2025, -0.8484], grad_fn=<SliceBackward0>) tensor([-0.6391, -0.5916], grad_fn=<SliceBackward0>)\n",
      "iter 69500, loss: 8.782179832458496\n",
      "tensor(-0.5550, grad_fn=<SelectBackward0>) tensor(1.0002, grad_fn=<SelectBackward0>) tensor([ 0.5688, -0.2692], grad_fn=<SliceBackward0>) tensor([1.9385, 0.5156], grad_fn=<SliceBackward0>)\n",
      "iter 69600, loss: 1.9543262720108032\n",
      "tensor(1.6365, grad_fn=<SelectBackward0>) tensor(1.5407, grad_fn=<SelectBackward0>) tensor([ 1.7577, -0.6176], grad_fn=<SliceBackward0>) tensor([ 0.3110, -0.0555], grad_fn=<SliceBackward0>)\n",
      "iter 69700, loss: 64.84593963623047\n",
      "tensor(-1.1514, grad_fn=<SelectBackward0>) tensor(0.1106, grad_fn=<SelectBackward0>) tensor([-0.6880,  0.4048], grad_fn=<SliceBackward0>) tensor([-0.9839, -2.4954], grad_fn=<SliceBackward0>)\n",
      "iter 69800, loss: 18.561704635620117\n",
      "tensor(-0.1050, grad_fn=<SelectBackward0>) tensor(0.0061, grad_fn=<SelectBackward0>) tensor([ 0.6617, -0.7923], grad_fn=<SliceBackward0>) tensor([ 0.5074, -1.0201], grad_fn=<SliceBackward0>)\n",
      "iter 69900, loss: 17.905433654785156\n",
      "tensor(-0.2281, grad_fn=<SelectBackward0>) tensor(0.9097, grad_fn=<SelectBackward0>) tensor([1.3647, 1.0448], grad_fn=<SliceBackward0>) tensor([-0.6486,  0.4375], grad_fn=<SliceBackward0>)\n",
      "iter 70000, loss: 21.67959976196289\n",
      "tensor(0.4663, grad_fn=<SelectBackward0>) tensor(0.0785, grad_fn=<SelectBackward0>) tensor([-0.1089, -0.0682], grad_fn=<SliceBackward0>) tensor([-0.1479, -1.0227], grad_fn=<SliceBackward0>)\n",
      "iter 70100, loss: 39.52198028564453\n",
      "tensor(-0.8844, grad_fn=<SelectBackward0>) tensor(1.8286, grad_fn=<SelectBackward0>) tensor([ 1.8080, -2.4542], grad_fn=<SliceBackward0>) tensor([-0.6492, -0.2012], grad_fn=<SliceBackward0>)\n",
      "iter 70200, loss: 18.108577728271484\n",
      "tensor(2.5239, grad_fn=<SelectBackward0>) tensor(-0.5667, grad_fn=<SelectBackward0>) tensor([-0.0942, -1.3743], grad_fn=<SliceBackward0>) tensor([0.5676, 0.5480], grad_fn=<SliceBackward0>)\n",
      "iter 70300, loss: 17.41112518310547\n",
      "tensor(-0.5361, grad_fn=<SelectBackward0>) tensor(0.5862, grad_fn=<SelectBackward0>) tensor([-0.6999, -1.0076], grad_fn=<SliceBackward0>) tensor([-0.1564, -1.0207], grad_fn=<SliceBackward0>)\n",
      "iter 70400, loss: 51.46986389160156\n",
      "tensor(0.1943, grad_fn=<SelectBackward0>) tensor(-0.1434, grad_fn=<SelectBackward0>) tensor([1.2960, 0.3619], grad_fn=<SliceBackward0>) tensor([-1.0115, -0.2797], grad_fn=<SliceBackward0>)\n",
      "iter 70500, loss: 3.510589838027954\n",
      "tensor(0.2145, grad_fn=<SelectBackward0>) tensor(0.9584, grad_fn=<SelectBackward0>) tensor([1.7299, 0.6892], grad_fn=<SliceBackward0>) tensor([ 0.7407, -0.1528], grad_fn=<SliceBackward0>)\n",
      "iter 70600, loss: 6.176914215087891\n",
      "tensor(0.0844, grad_fn=<SelectBackward0>) tensor(1.2478, grad_fn=<SelectBackward0>) tensor([-1.3131, -1.0530], grad_fn=<SliceBackward0>) tensor([ 1.0825, -0.9004], grad_fn=<SliceBackward0>)\n",
      "iter 70700, loss: 21.198314666748047\n",
      "tensor(0.4931, grad_fn=<SelectBackward0>) tensor(0.7034, grad_fn=<SelectBackward0>) tensor([ 1.6908, -0.4271], grad_fn=<SliceBackward0>) tensor([-0.2501, -0.2621], grad_fn=<SliceBackward0>)\n",
      "iter 70800, loss: 24.469440460205078\n",
      "tensor(-0.8338, grad_fn=<SelectBackward0>) tensor(1.5787, grad_fn=<SelectBackward0>) tensor([0.5893, 0.9793], grad_fn=<SliceBackward0>) tensor([-0.5149, -0.0222], grad_fn=<SliceBackward0>)\n",
      "iter 70900, loss: 18.10314178466797\n",
      "tensor(-0.1746, grad_fn=<SelectBackward0>) tensor(0.6607, grad_fn=<SelectBackward0>) tensor([-0.5575, -0.2623], grad_fn=<SliceBackward0>) tensor([0.6097, 0.5070], grad_fn=<SliceBackward0>)\n",
      "iter 71000, loss: 21.21312713623047\n",
      "tensor(0.4229, grad_fn=<SelectBackward0>) tensor(-0.0542, grad_fn=<SelectBackward0>) tensor([0.5582, 0.5865], grad_fn=<SliceBackward0>) tensor([ 0.5339, -0.0128], grad_fn=<SliceBackward0>)\n",
      "iter 71100, loss: 0.3424617648124695\n",
      "tensor(0.9469, grad_fn=<SelectBackward0>) tensor(1.8686, grad_fn=<SelectBackward0>) tensor([-0.5200,  1.1093], grad_fn=<SliceBackward0>) tensor([0.6622, 0.9492], grad_fn=<SliceBackward0>)\n",
      "iter 71200, loss: 31.85919189453125\n",
      "tensor(0.3496, grad_fn=<SelectBackward0>) tensor(-0.4053, grad_fn=<SelectBackward0>) tensor([-1.0235, -1.6090], grad_fn=<SliceBackward0>) tensor([-0.8047,  0.4198], grad_fn=<SliceBackward0>)\n",
      "iter 71300, loss: 4.097192287445068\n",
      "tensor(-0.8669, grad_fn=<SelectBackward0>) tensor(1.5890, grad_fn=<SelectBackward0>) tensor([-0.0535, -0.9846], grad_fn=<SliceBackward0>) tensor([-0.6082, -0.3663], grad_fn=<SliceBackward0>)\n",
      "iter 71400, loss: 46.43428039550781\n",
      "tensor(0.6868, grad_fn=<SelectBackward0>) tensor(-0.1581, grad_fn=<SelectBackward0>) tensor([-0.0426, -0.4461], grad_fn=<SliceBackward0>) tensor([0.1680, 2.4714], grad_fn=<SliceBackward0>)\n",
      "iter 71500, loss: 38.40645980834961\n",
      "tensor(-0.2652, grad_fn=<SelectBackward0>) tensor(-0.0046, grad_fn=<SelectBackward0>) tensor([-1.0401,  2.0136], grad_fn=<SliceBackward0>) tensor([ 1.3268, -0.1654], grad_fn=<SliceBackward0>)\n",
      "iter 71600, loss: 2.2296268939971924\n",
      "tensor(0.3031, grad_fn=<SelectBackward0>) tensor(1.4140, grad_fn=<SelectBackward0>) tensor([0.9635, 0.1549], grad_fn=<SliceBackward0>) tensor([0.9327, 0.0258], grad_fn=<SliceBackward0>)\n",
      "iter 71700, loss: 17.049041748046875\n",
      "tensor(-0.1360, grad_fn=<SelectBackward0>) tensor(-0.0101, grad_fn=<SelectBackward0>) tensor([-0.4907, -0.3774], grad_fn=<SliceBackward0>) tensor([ 0.1117, -0.8685], grad_fn=<SliceBackward0>)\n",
      "iter 71800, loss: 35.27162170410156\n",
      "tensor(-0.8536, grad_fn=<SelectBackward0>) tensor(0.4442, grad_fn=<SelectBackward0>) tensor([-0.1614, -0.1010], grad_fn=<SliceBackward0>) tensor([-0.8089,  1.3005], grad_fn=<SliceBackward0>)\n",
      "iter 71900, loss: 11.654128074645996\n",
      "tensor(1.3041, grad_fn=<SelectBackward0>) tensor(0.3621, grad_fn=<SelectBackward0>) tensor([0.5202, 1.8003], grad_fn=<SliceBackward0>) tensor([ 1.5559, -0.1930], grad_fn=<SliceBackward0>)\n",
      "iter 72000, loss: 18.855161666870117\n",
      "tensor(1.2134, grad_fn=<SelectBackward0>) tensor(0.6113, grad_fn=<SelectBackward0>) tensor([1.0748, 0.3413], grad_fn=<SliceBackward0>) tensor([-0.1798, -1.4309], grad_fn=<SliceBackward0>)\n",
      "iter 72100, loss: 32.96796798706055\n",
      "tensor(-0.3467, grad_fn=<SelectBackward0>) tensor(1.5867, grad_fn=<SelectBackward0>) tensor([-1.4658,  0.1910], grad_fn=<SliceBackward0>) tensor([ 0.3316, -2.1543], grad_fn=<SliceBackward0>)\n",
      "iter 72200, loss: 19.056533813476562\n",
      "tensor(0.3008, grad_fn=<SelectBackward0>) tensor(0.4314, grad_fn=<SelectBackward0>) tensor([ 0.0143, -0.7529], grad_fn=<SliceBackward0>) tensor([0.4583, 1.0016], grad_fn=<SliceBackward0>)\n",
      "iter 72300, loss: 28.19224739074707\n",
      "tensor(0.8454, grad_fn=<SelectBackward0>) tensor(0.8036, grad_fn=<SelectBackward0>) tensor([-1.2224,  0.2685], grad_fn=<SliceBackward0>) tensor([ 1.1293, -0.0326], grad_fn=<SliceBackward0>)\n",
      "iter 72400, loss: 34.46466827392578\n",
      "tensor(-0.2204, grad_fn=<SelectBackward0>) tensor(0.3955, grad_fn=<SelectBackward0>) tensor([-1.1414, -0.5791], grad_fn=<SliceBackward0>) tensor([0.4487, 0.0894], grad_fn=<SliceBackward0>)\n",
      "iter 72500, loss: 19.870792388916016\n",
      "tensor(1.7128, grad_fn=<SelectBackward0>) tensor(-1.7026, grad_fn=<SelectBackward0>) tensor([0.6915, 0.0296], grad_fn=<SliceBackward0>) tensor([-0.3347,  0.2908], grad_fn=<SliceBackward0>)\n",
      "iter 72600, loss: 97.8291015625\n",
      "tensor(-1.6481, grad_fn=<SelectBackward0>) tensor(-1.0361, grad_fn=<SelectBackward0>) tensor([ 0.8547, -0.8595], grad_fn=<SliceBackward0>) tensor([-0.1971,  1.0825], grad_fn=<SliceBackward0>)\n",
      "iter 72700, loss: 3.9247710704803467\n",
      "tensor(1.5699, grad_fn=<SelectBackward0>) tensor(0.7263, grad_fn=<SelectBackward0>) tensor([-1.2155,  1.5238], grad_fn=<SliceBackward0>) tensor([0.6676, 0.5211], grad_fn=<SliceBackward0>)\n",
      "iter 72800, loss: 67.55611419677734\n",
      "tensor(-1.0007, grad_fn=<SelectBackward0>) tensor(-1.1296, grad_fn=<SelectBackward0>) tensor([0.4636, 0.0574], grad_fn=<SliceBackward0>) tensor([-1.3084,  2.2885], grad_fn=<SliceBackward0>)\n",
      "iter 72900, loss: 8.82423210144043\n",
      "tensor(1.4741, grad_fn=<SelectBackward0>) tensor(1.9258, grad_fn=<SelectBackward0>) tensor([ 1.7057, -1.8279], grad_fn=<SliceBackward0>) tensor([-0.4129,  0.0835], grad_fn=<SliceBackward0>)\n",
      "iter 73000, loss: 20.6458740234375\n",
      "tensor(0.7131, grad_fn=<SelectBackward0>) tensor(0.7352, grad_fn=<SelectBackward0>) tensor([-0.8841, -0.1399], grad_fn=<SliceBackward0>) tensor([ 0.7798, -0.2183], grad_fn=<SliceBackward0>)\n",
      "iter 73100, loss: 7.764462947845459\n",
      "tensor(0.7497, grad_fn=<SelectBackward0>) tensor(1.1829, grad_fn=<SelectBackward0>) tensor([-0.3312,  0.5257], grad_fn=<SliceBackward0>) tensor([-0.8306,  0.3432], grad_fn=<SliceBackward0>)\n",
      "iter 73200, loss: 3.2072246074676514\n",
      "tensor(1.2284, grad_fn=<SelectBackward0>) tensor(1.5959, grad_fn=<SelectBackward0>) tensor([-0.5474, -0.2367], grad_fn=<SliceBackward0>) tensor([0.7401, 0.4091], grad_fn=<SliceBackward0>)\n",
      "iter 73300, loss: 9.820329666137695\n",
      "tensor(0.6119, grad_fn=<SelectBackward0>) tensor(0.9968, grad_fn=<SelectBackward0>) tensor([ 0.0091, -0.8785], grad_fn=<SliceBackward0>) tensor([ 0.3431, -0.5093], grad_fn=<SliceBackward0>)\n",
      "iter 73400, loss: 1.2483991384506226\n",
      "tensor(1.4434, grad_fn=<SelectBackward0>) tensor(3.7770, grad_fn=<SelectBackward0>) tensor([ 0.5279, -0.6310], grad_fn=<SliceBackward0>) tensor([-0.1079,  0.1732], grad_fn=<SliceBackward0>)\n",
      "iter 73500, loss: 0.4036031663417816\n",
      "tensor(1.7893, grad_fn=<SelectBackward0>) tensor(1.4337, grad_fn=<SelectBackward0>) tensor([-0.6698, -2.4489], grad_fn=<SliceBackward0>) tensor([-0.8416, -0.7025], grad_fn=<SliceBackward0>)\n",
      "iter 73600, loss: 18.681610107421875\n",
      "tensor(1.3321, grad_fn=<SelectBackward0>) tensor(-0.5288, grad_fn=<SelectBackward0>) tensor([1.0481, 0.7546], grad_fn=<SliceBackward0>) tensor([-0.3368,  0.8061], grad_fn=<SliceBackward0>)\n",
      "iter 73700, loss: 16.49598503112793\n",
      "tensor(0.3955, grad_fn=<SelectBackward0>) tensor(0.3749, grad_fn=<SelectBackward0>) tensor([-0.4756, -0.9406], grad_fn=<SliceBackward0>) tensor([ 1.1243, -0.0752], grad_fn=<SliceBackward0>)\n",
      "iter 73800, loss: 12.779627799987793\n",
      "tensor(0.2271, grad_fn=<SelectBackward0>) tensor(0.9818, grad_fn=<SelectBackward0>) tensor([-1.4329,  0.9140], grad_fn=<SliceBackward0>) tensor([-0.4664, -0.1013], grad_fn=<SliceBackward0>)\n",
      "iter 73900, loss: 2.576733112335205\n",
      "tensor(1.2211, grad_fn=<SelectBackward0>) tensor(1.2998, grad_fn=<SelectBackward0>) tensor([-0.1174,  1.1950], grad_fn=<SliceBackward0>) tensor([0.7288, 0.9316], grad_fn=<SliceBackward0>)\n",
      "iter 74000, loss: 31.409912109375\n",
      "tensor(0.7564, grad_fn=<SelectBackward0>) tensor(0.2386, grad_fn=<SelectBackward0>) tensor([-0.3302,  0.9981], grad_fn=<SliceBackward0>) tensor([ 2.8548, -0.3096], grad_fn=<SliceBackward0>)\n",
      "iter 74100, loss: 21.025741577148438\n",
      "tensor(0.1443, grad_fn=<SelectBackward0>) tensor(0.9543, grad_fn=<SelectBackward0>) tensor([-0.6047, -0.2454], grad_fn=<SliceBackward0>) tensor([ 0.7146, -0.1257], grad_fn=<SliceBackward0>)\n",
      "iter 74200, loss: 2.5323400497436523\n",
      "tensor(1.8533, grad_fn=<SelectBackward0>) tensor(1.0386, grad_fn=<SelectBackward0>) tensor([ 1.7934, -0.3892], grad_fn=<SliceBackward0>) tensor([ 1.2095, -0.7355], grad_fn=<SliceBackward0>)\n",
      "iter 74300, loss: 23.456043243408203\n",
      "tensor(-0.1354, grad_fn=<SelectBackward0>) tensor(-0.7213, grad_fn=<SelectBackward0>) tensor([-0.2814,  2.0595], grad_fn=<SliceBackward0>) tensor([0.2328, 0.8384], grad_fn=<SliceBackward0>)\n",
      "iter 74400, loss: 16.37097930908203\n",
      "tensor(0.5578, grad_fn=<SelectBackward0>) tensor(0.1331, grad_fn=<SelectBackward0>) tensor([-0.3151,  0.8973], grad_fn=<SliceBackward0>) tensor([0.9976, 1.0919], grad_fn=<SliceBackward0>)\n",
      "iter 74500, loss: 86.76970672607422\n",
      "tensor(-0.5052, grad_fn=<SelectBackward0>) tensor(-2.4891, grad_fn=<SelectBackward0>) tensor([-1.2361,  0.2662], grad_fn=<SliceBackward0>) tensor([0.4114, 1.5739], grad_fn=<SliceBackward0>)\n",
      "iter 74600, loss: 22.222688674926758\n",
      "tensor(0.8205, grad_fn=<SelectBackward0>) tensor(-0.4331, grad_fn=<SelectBackward0>) tensor([0.2559, 0.5520], grad_fn=<SliceBackward0>) tensor([ 1.0586, -0.0833], grad_fn=<SliceBackward0>)\n",
      "iter 74700, loss: 5.634711742401123\n",
      "tensor(1.6413, grad_fn=<SelectBackward0>) tensor(-0.1445, grad_fn=<SelectBackward0>) tensor([-0.0505,  1.3370], grad_fn=<SliceBackward0>) tensor([-1.2995,  0.2436], grad_fn=<SliceBackward0>)\n",
      "iter 74800, loss: 20.202421188354492\n",
      "tensor(-0.3015, grad_fn=<SelectBackward0>) tensor(0.9989, grad_fn=<SelectBackward0>) tensor([-0.3825, -0.3885], grad_fn=<SliceBackward0>) tensor([ 0.4410, -0.5991], grad_fn=<SliceBackward0>)\n",
      "iter 74900, loss: 24.026857376098633\n",
      "tensor(-0.8459, grad_fn=<SelectBackward0>) tensor(2.0206, grad_fn=<SelectBackward0>) tensor([-0.5077, -0.8361], grad_fn=<SliceBackward0>) tensor([0.3011, 0.6665], grad_fn=<SliceBackward0>)\n",
      "iter 75000, loss: 19.218042373657227\n",
      "tensor(-1.5469, grad_fn=<SelectBackward0>) tensor(1.4816, grad_fn=<SelectBackward0>) tensor([ 2.2679, -0.3348], grad_fn=<SliceBackward0>) tensor([ 0.5154, -0.5137], grad_fn=<SliceBackward0>)\n",
      "iter 75100, loss: 12.588150978088379\n",
      "tensor(1.9099, grad_fn=<SelectBackward0>) tensor(-0.3127, grad_fn=<SelectBackward0>) tensor([0.6409, 1.0017], grad_fn=<SliceBackward0>) tensor([ 0.4557, -0.1778], grad_fn=<SliceBackward0>)\n",
      "iter 75200, loss: 19.17417335510254\n",
      "tensor(-0.9303, grad_fn=<SelectBackward0>) tensor(0.9547, grad_fn=<SelectBackward0>) tensor([1.3447, 1.7053], grad_fn=<SliceBackward0>) tensor([-0.5616,  0.5862], grad_fn=<SliceBackward0>)\n",
      "iter 75300, loss: 1.440017819404602\n",
      "tensor(-0.2862, grad_fn=<SelectBackward0>) tensor(1.4712, grad_fn=<SelectBackward0>) tensor([2.1073, 1.5796], grad_fn=<SliceBackward0>) tensor([-0.6121,  2.0432], grad_fn=<SliceBackward0>)\n",
      "iter 75400, loss: 28.54018211364746\n",
      "tensor(-0.4571, grad_fn=<SelectBackward0>) tensor(-1.6415, grad_fn=<SelectBackward0>) tensor([ 1.3991, -0.5340], grad_fn=<SliceBackward0>) tensor([-0.0097, -0.4560], grad_fn=<SliceBackward0>)\n",
      "iter 75500, loss: 45.40985107421875\n",
      "tensor(0.4942, grad_fn=<SelectBackward0>) tensor(-0.7481, grad_fn=<SelectBackward0>) tensor([ 0.4782, -1.2637], grad_fn=<SliceBackward0>) tensor([1.0008, 0.9068], grad_fn=<SliceBackward0>)\n",
      "iter 75600, loss: 49.380428314208984\n",
      "tensor(-0.1640, grad_fn=<SelectBackward0>) tensor(-0.3441, grad_fn=<SelectBackward0>) tensor([ 0.1588, -1.3014], grad_fn=<SliceBackward0>) tensor([0.5777, 0.6978], grad_fn=<SliceBackward0>)\n",
      "iter 75700, loss: 22.194122314453125\n",
      "tensor(-0.0151, grad_fn=<SelectBackward0>) tensor(1.3676, grad_fn=<SelectBackward0>) tensor([-0.8100,  0.1481], grad_fn=<SliceBackward0>) tensor([ 0.2316, -1.8546], grad_fn=<SliceBackward0>)\n",
      "iter 75800, loss: 28.300840377807617\n",
      "tensor(-0.1669, grad_fn=<SelectBackward0>) tensor(-0.7275, grad_fn=<SelectBackward0>) tensor([ 0.4933, -0.3734], grad_fn=<SliceBackward0>) tensor([-0.4246, -0.1780], grad_fn=<SliceBackward0>)\n",
      "iter 75900, loss: 11.006847381591797\n",
      "tensor(-0.7835, grad_fn=<SelectBackward0>) tensor(2.4620, grad_fn=<SelectBackward0>) tensor([-0.3719,  0.3929], grad_fn=<SliceBackward0>) tensor([0.1682, 0.6224], grad_fn=<SliceBackward0>)\n",
      "iter 76000, loss: 1.4737305641174316\n",
      "tensor(0.7805, grad_fn=<SelectBackward0>) tensor(0.6871, grad_fn=<SelectBackward0>) tensor([ 0.6117, -2.4464], grad_fn=<SliceBackward0>) tensor([ 0.7570, -0.8532], grad_fn=<SliceBackward0>)\n",
      "iter 76100, loss: 26.849946975708008\n",
      "tensor(1.1030, grad_fn=<SelectBackward0>) tensor(-0.1918, grad_fn=<SelectBackward0>) tensor([ 0.9321, -2.0708], grad_fn=<SliceBackward0>) tensor([0.8979, 0.5100], grad_fn=<SliceBackward0>)\n",
      "iter 76200, loss: 33.20125961303711\n",
      "tensor(0.3274, grad_fn=<SelectBackward0>) tensor(-0.9971, grad_fn=<SelectBackward0>) tensor([1.2436, 0.0784], grad_fn=<SliceBackward0>) tensor([-0.4541, -0.4769], grad_fn=<SliceBackward0>)\n",
      "iter 76300, loss: 6.659954071044922\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>) tensor(1.5342, grad_fn=<SelectBackward0>) tensor([1.2587, 0.1644], grad_fn=<SliceBackward0>) tensor([0.8749, 0.4326], grad_fn=<SliceBackward0>)\n",
      "iter 76400, loss: 31.84217643737793\n",
      "tensor(-0.2725, grad_fn=<SelectBackward0>) tensor(0.1067, grad_fn=<SelectBackward0>) tensor([-0.8723, -1.1528], grad_fn=<SliceBackward0>) tensor([-0.0775,  0.8334], grad_fn=<SliceBackward0>)\n",
      "iter 76500, loss: 15.055542945861816\n",
      "tensor(0.7564, grad_fn=<SelectBackward0>) tensor(0.2621, grad_fn=<SelectBackward0>) tensor([ 1.1162, -0.4201], grad_fn=<SliceBackward0>) tensor([0.6064, 0.6131], grad_fn=<SliceBackward0>)\n",
      "iter 76600, loss: 42.73704147338867\n",
      "tensor(1.1408, grad_fn=<SelectBackward0>) tensor(-1.1544, grad_fn=<SelectBackward0>) tensor([ 1.5760, -1.2061], grad_fn=<SliceBackward0>) tensor([-1.1449, -1.2203], grad_fn=<SliceBackward0>)\n",
      "iter 76700, loss: 0.9653631448745728\n",
      "tensor(1.3070, grad_fn=<SelectBackward0>) tensor(2.6914, grad_fn=<SelectBackward0>) tensor([-0.9473,  0.0640], grad_fn=<SliceBackward0>) tensor([-0.1050, -0.2971], grad_fn=<SliceBackward0>)\n",
      "iter 76800, loss: 21.277748107910156\n",
      "tensor(-0.1296, grad_fn=<SelectBackward0>) tensor(0.3790, grad_fn=<SelectBackward0>) tensor([ 0.2691, -0.5468], grad_fn=<SliceBackward0>) tensor([ 0.6427, -0.4191], grad_fn=<SliceBackward0>)\n",
      "iter 76900, loss: 26.710704803466797\n",
      "tensor(0.7520, grad_fn=<SelectBackward0>) tensor(-0.9148, grad_fn=<SelectBackward0>) tensor([-0.4353, -0.3471], grad_fn=<SliceBackward0>) tensor([-0.3469, -0.2758], grad_fn=<SliceBackward0>)\n",
      "iter 77000, loss: 10.557836532592773\n",
      "tensor(-1.7001, grad_fn=<SelectBackward0>) tensor(3.4707, grad_fn=<SelectBackward0>) tensor([-0.7826, -1.4992], grad_fn=<SliceBackward0>) tensor([-0.1126, -0.1389], grad_fn=<SliceBackward0>)\n",
      "iter 77100, loss: 42.21575927734375\n",
      "tensor(-0.0794, grad_fn=<SelectBackward0>) tensor(-1.2302, grad_fn=<SelectBackward0>) tensor([0.2316, 0.6019], grad_fn=<SliceBackward0>) tensor([0.3034, 0.1073], grad_fn=<SliceBackward0>)\n",
      "iter 77200, loss: 3.117083787918091\n",
      "tensor(0.7225, grad_fn=<SelectBackward0>) tensor(0.5993, grad_fn=<SelectBackward0>) tensor([ 0.3562, -1.2842], grad_fn=<SliceBackward0>) tensor([ 0.5508, -0.6805], grad_fn=<SliceBackward0>)\n",
      "iter 77300, loss: 15.362667083740234\n",
      "tensor(0.9662, grad_fn=<SelectBackward0>) tensor(-0.1688, grad_fn=<SelectBackward0>) tensor([ 0.3099, -1.8330], grad_fn=<SliceBackward0>) tensor([1.0445, 0.2798], grad_fn=<SliceBackward0>)\n",
      "iter 77400, loss: 13.967491149902344\n",
      "tensor(1.3726, grad_fn=<SelectBackward0>) tensor(0.8680, grad_fn=<SelectBackward0>) tensor([-0.5162, -0.6330], grad_fn=<SliceBackward0>) tensor([0.5729, 0.6522], grad_fn=<SliceBackward0>)\n",
      "iter 77500, loss: 15.833393096923828\n",
      "tensor(-0.2391, grad_fn=<SelectBackward0>) tensor(0.6450, grad_fn=<SelectBackward0>) tensor([-0.0993, -2.1471], grad_fn=<SliceBackward0>) tensor([ 0.9391, -0.6139], grad_fn=<SliceBackward0>)\n",
      "iter 77600, loss: 5.019197463989258\n",
      "tensor(0.4334, grad_fn=<SelectBackward0>) tensor(1.5931, grad_fn=<SelectBackward0>) tensor([1.2339, 0.0277], grad_fn=<SliceBackward0>) tensor([ 0.7447, -0.2016], grad_fn=<SliceBackward0>)\n",
      "iter 77700, loss: 5.2032151222229\n",
      "tensor(1.6260, grad_fn=<SelectBackward0>) tensor(1.1405, grad_fn=<SelectBackward0>) tensor([0.6876, 0.4584], grad_fn=<SliceBackward0>) tensor([-1.4036,  0.3070], grad_fn=<SliceBackward0>)\n",
      "iter 77800, loss: 14.792619705200195\n",
      "tensor(0.8230, grad_fn=<SelectBackward0>) tensor(1.0066, grad_fn=<SelectBackward0>) tensor([-0.3333,  0.5545], grad_fn=<SliceBackward0>) tensor([1.8867, 0.8614], grad_fn=<SliceBackward0>)\n",
      "iter 77900, loss: 0.471032053232193\n",
      "tensor(1.4324, grad_fn=<SelectBackward0>) tensor(0.9519, grad_fn=<SelectBackward0>) tensor([2.0820, 1.2577], grad_fn=<SliceBackward0>) tensor([1.2304, 0.4788], grad_fn=<SliceBackward0>)\n",
      "iter 78000, loss: 8.063661575317383\n",
      "tensor(0.7774, grad_fn=<SelectBackward0>) tensor(0.6846, grad_fn=<SelectBackward0>) tensor([0.2214, 0.6518], grad_fn=<SliceBackward0>) tensor([-1.0214,  2.0942], grad_fn=<SliceBackward0>)\n",
      "iter 78100, loss: 39.42948913574219\n",
      "tensor(0.6909, grad_fn=<SelectBackward0>) tensor(-0.7778, grad_fn=<SelectBackward0>) tensor([-1.6659, -0.2512], grad_fn=<SliceBackward0>) tensor([1.3187, 0.1555], grad_fn=<SliceBackward0>)\n",
      "iter 78200, loss: 7.439580917358398\n",
      "tensor(0.9621, grad_fn=<SelectBackward0>) tensor(1.4857, grad_fn=<SelectBackward0>) tensor([-1.1579, -0.1787], grad_fn=<SliceBackward0>) tensor([ 0.0427, -0.3735], grad_fn=<SliceBackward0>)\n",
      "iter 78300, loss: 16.174776077270508\n",
      "tensor(-0.5972, grad_fn=<SelectBackward0>) tensor(1.7147, grad_fn=<SelectBackward0>) tensor([ 1.6232, -2.2754], grad_fn=<SliceBackward0>) tensor([ 0.3521, -0.0370], grad_fn=<SliceBackward0>)\n",
      "iter 78400, loss: 2.84914231300354\n",
      "tensor(1.7052, grad_fn=<SelectBackward0>) tensor(1.2610, grad_fn=<SelectBackward0>) tensor([1.1194, 0.0101], grad_fn=<SliceBackward0>) tensor([0.5121, 0.7450], grad_fn=<SliceBackward0>)\n",
      "iter 78500, loss: 0.08266101777553558\n",
      "tensor(1.2530, grad_fn=<SelectBackward0>) tensor(1.0963, grad_fn=<SelectBackward0>) tensor([-1.1435, -0.2803], grad_fn=<SliceBackward0>) tensor([ 0.3831, -1.2123], grad_fn=<SliceBackward0>)\n",
      "iter 78600, loss: 11.503435134887695\n",
      "tensor(1.6874, grad_fn=<SelectBackward0>) tensor(0.5906, grad_fn=<SelectBackward0>) tensor([ 0.0078, -0.2107], grad_fn=<SliceBackward0>) tensor([-1.2119,  1.3675], grad_fn=<SliceBackward0>)\n",
      "iter 78700, loss: 39.516845703125\n",
      "tensor(-1.0731, grad_fn=<SelectBackward0>) tensor(-0.5957, grad_fn=<SelectBackward0>) tensor([0.0170, 0.0841], grad_fn=<SliceBackward0>) tensor([-0.7823, -1.1467], grad_fn=<SliceBackward0>)\n",
      "iter 78800, loss: 5.326210975646973\n",
      "tensor(1.4066, grad_fn=<SelectBackward0>) tensor(1.4024, grad_fn=<SelectBackward0>) tensor([ 0.0482, -0.0211], grad_fn=<SliceBackward0>) tensor([ 0.6217, -1.1376], grad_fn=<SliceBackward0>)\n",
      "iter 78900, loss: 2.0578155517578125\n",
      "tensor(1.6691, grad_fn=<SelectBackward0>) tensor(2.7978, grad_fn=<SelectBackward0>) tensor([1.6123, 1.4257], grad_fn=<SliceBackward0>) tensor([-0.0535, -0.4316], grad_fn=<SliceBackward0>)\n",
      "iter 79000, loss: 33.953041076660156\n",
      "tensor(0.7258, grad_fn=<SelectBackward0>) tensor(-1.8619, grad_fn=<SelectBackward0>) tensor([-1.2178,  0.8065], grad_fn=<SliceBackward0>) tensor([-0.4135,  0.3691], grad_fn=<SliceBackward0>)\n",
      "iter 79100, loss: 19.38446807861328\n",
      "tensor(-0.2236, grad_fn=<SelectBackward0>) tensor(-0.1229, grad_fn=<SelectBackward0>) tensor([-1.0030, -1.3301], grad_fn=<SliceBackward0>) tensor([ 0.6132, -0.0231], grad_fn=<SliceBackward0>)\n",
      "iter 79200, loss: 6.836885452270508\n",
      "tensor(-0.8575, grad_fn=<SelectBackward0>) tensor(0.4301, grad_fn=<SelectBackward0>) tensor([ 0.1910, -0.4860], grad_fn=<SliceBackward0>) tensor([0.6568, 0.3390], grad_fn=<SliceBackward0>)\n",
      "iter 79300, loss: 5.777091979980469\n",
      "tensor(1.1803, grad_fn=<SelectBackward0>) tensor(1.9866, grad_fn=<SelectBackward0>) tensor([-1.1260, -0.2242], grad_fn=<SliceBackward0>) tensor([0.3482, 0.0399], grad_fn=<SliceBackward0>)\n",
      "iter 79400, loss: 14.832143783569336\n",
      "tensor(-0.8857, grad_fn=<SelectBackward0>) tensor(2.0376, grad_fn=<SelectBackward0>) tensor([ 0.0429, -0.4188], grad_fn=<SliceBackward0>) tensor([-0.6214, -0.5835], grad_fn=<SliceBackward0>)\n",
      "iter 79500, loss: 10.741104125976562\n",
      "tensor(0.9084, grad_fn=<SelectBackward0>) tensor(2.1233, grad_fn=<SelectBackward0>) tensor([-2.1682,  0.9090], grad_fn=<SliceBackward0>) tensor([ 0.2563, -0.2606], grad_fn=<SliceBackward0>)\n",
      "iter 79600, loss: 6.462998390197754\n",
      "tensor(1.7193, grad_fn=<SelectBackward0>) tensor(-0.6710, grad_fn=<SelectBackward0>) tensor([1.6715, 0.3212], grad_fn=<SliceBackward0>) tensor([0.9197, 0.5172], grad_fn=<SliceBackward0>)\n",
      "iter 79700, loss: 2.6055166721343994\n",
      "tensor(1.6672, grad_fn=<SelectBackward0>) tensor(2.0261, grad_fn=<SelectBackward0>) tensor([-1.4380, -1.1969], grad_fn=<SliceBackward0>) tensor([-0.4988,  0.6865], grad_fn=<SliceBackward0>)\n",
      "iter 79800, loss: 9.320656776428223\n",
      "tensor(1.1252, grad_fn=<SelectBackward0>) tensor(1.2870, grad_fn=<SelectBackward0>) tensor([ 0.8153, -1.1603], grad_fn=<SliceBackward0>) tensor([-0.9711, -0.5620], grad_fn=<SliceBackward0>)\n",
      "iter 79900, loss: 5.495608329772949\n",
      "tensor(0.0793, grad_fn=<SelectBackward0>) tensor(0.1076, grad_fn=<SelectBackward0>) tensor([ 0.4838, -1.2349], grad_fn=<SliceBackward0>) tensor([2.4455, 0.2102], grad_fn=<SliceBackward0>)\n",
      "iter 80000, loss: 10.937141418457031\n",
      "tensor(1.5152, grad_fn=<SelectBackward0>) tensor(0.0813, grad_fn=<SelectBackward0>) tensor([-0.7752,  0.5194], grad_fn=<SliceBackward0>) tensor([-0.0539, -1.2396], grad_fn=<SliceBackward0>)\n",
      "iter 80100, loss: 109.51286315917969\n",
      "tensor(-0.1529, grad_fn=<SelectBackward0>) tensor(-0.5152, grad_fn=<SelectBackward0>) tensor([-0.5997,  1.1322], grad_fn=<SliceBackward0>) tensor([ 0.0343, -2.2117], grad_fn=<SliceBackward0>)\n",
      "iter 80200, loss: 6.439081192016602\n",
      "tensor(-1.0753, grad_fn=<SelectBackward0>) tensor(3.1940, grad_fn=<SelectBackward0>) tensor([0.3695, 0.5146], grad_fn=<SliceBackward0>) tensor([-0.0946, -0.8834], grad_fn=<SliceBackward0>)\n",
      "iter 80300, loss: 12.895508766174316\n",
      "tensor(0.8691, grad_fn=<SelectBackward0>) tensor(-0.3072, grad_fn=<SelectBackward0>) tensor([ 0.8592, -0.7702], grad_fn=<SliceBackward0>) tensor([0.8724, 0.7399], grad_fn=<SliceBackward0>)\n",
      "iter 80400, loss: 18.954504013061523\n",
      "tensor(0.4913, grad_fn=<SelectBackward0>) tensor(0.5247, grad_fn=<SelectBackward0>) tensor([ 1.5220, -0.7587], grad_fn=<SliceBackward0>) tensor([-0.2444,  0.6631], grad_fn=<SliceBackward0>)\n",
      "iter 80500, loss: 7.992562294006348\n",
      "tensor(0.1146, grad_fn=<SelectBackward0>) tensor(2.0431, grad_fn=<SelectBackward0>) tensor([ 0.5876, -1.7207], grad_fn=<SliceBackward0>) tensor([ 0.3803, -0.0575], grad_fn=<SliceBackward0>)\n",
      "iter 80600, loss: 0.16007868945598602\n",
      "tensor(0.1113, grad_fn=<SelectBackward0>) tensor(4.4126, grad_fn=<SelectBackward0>) tensor([1.1364, 0.0909], grad_fn=<SliceBackward0>) tensor([ 0.1099, -0.1685], grad_fn=<SliceBackward0>)\n",
      "iter 80700, loss: 5.9714765548706055\n",
      "tensor(-0.4638, grad_fn=<SelectBackward0>) tensor(1.0524, grad_fn=<SelectBackward0>) tensor([-0.5946, -0.1155], grad_fn=<SliceBackward0>) tensor([-0.1418,  0.0019], grad_fn=<SliceBackward0>)\n",
      "iter 80800, loss: 6.713008403778076\n",
      "tensor(-0.8788, grad_fn=<SelectBackward0>) tensor(1.3070, grad_fn=<SelectBackward0>) tensor([ 0.8315, -0.2509], grad_fn=<SliceBackward0>) tensor([ 0.0522, -0.3422], grad_fn=<SliceBackward0>)\n",
      "iter 80900, loss: 4.669043064117432\n",
      "tensor(0.7281, grad_fn=<SelectBackward0>) tensor(-0.3561, grad_fn=<SelectBackward0>) tensor([-0.1413, -1.4918], grad_fn=<SliceBackward0>) tensor([ 0.6026, -1.9445], grad_fn=<SliceBackward0>)\n",
      "iter 81000, loss: 13.694865226745605\n",
      "tensor(-0.7644, grad_fn=<SelectBackward0>) tensor(0.7534, grad_fn=<SelectBackward0>) tensor([-1.5072, -1.6687], grad_fn=<SliceBackward0>) tensor([-0.6406, -0.5350], grad_fn=<SliceBackward0>)\n",
      "iter 81100, loss: 29.19806480407715\n",
      "tensor(-0.2923, grad_fn=<SelectBackward0>) tensor(2.3576, grad_fn=<SelectBackward0>) tensor([-1.1873, -1.6749], grad_fn=<SliceBackward0>) tensor([0.8611, 0.3634], grad_fn=<SliceBackward0>)\n",
      "iter 81200, loss: 4.491637706756592\n",
      "tensor(-0.8665, grad_fn=<SelectBackward0>) tensor(4.1231, grad_fn=<SelectBackward0>) tensor([0.7788, 1.0777], grad_fn=<SliceBackward0>) tensor([-0.3433,  0.0545], grad_fn=<SliceBackward0>)\n",
      "iter 81300, loss: 8.881136894226074\n",
      "tensor(0.9267, grad_fn=<SelectBackward0>) tensor(0.1605, grad_fn=<SelectBackward0>) tensor([ 0.0991, -2.3021], grad_fn=<SliceBackward0>) tensor([ 0.6191, -2.5673], grad_fn=<SliceBackward0>)\n",
      "iter 81400, loss: 15.131440162658691\n",
      "tensor(2.3601, grad_fn=<SelectBackward0>) tensor(0.4413, grad_fn=<SelectBackward0>) tensor([-0.6363,  0.6167], grad_fn=<SliceBackward0>) tensor([ 0.0168, -1.8836], grad_fn=<SliceBackward0>)\n",
      "iter 81500, loss: 18.66246795654297\n",
      "tensor(0.5041, grad_fn=<SelectBackward0>) tensor(0.5204, grad_fn=<SelectBackward0>) tensor([-0.6953, -1.7443], grad_fn=<SliceBackward0>) tensor([ 0.6749, -0.3756], grad_fn=<SliceBackward0>)\n",
      "iter 81600, loss: 11.690162658691406\n",
      "tensor(0.5256, grad_fn=<SelectBackward0>) tensor(0.6653, grad_fn=<SelectBackward0>) tensor([-0.4038,  0.2624], grad_fn=<SliceBackward0>) tensor([1.3081, 0.9984], grad_fn=<SliceBackward0>)\n",
      "iter 81700, loss: 11.2066650390625\n",
      "tensor(1.0472, grad_fn=<SelectBackward0>) tensor(1.0440, grad_fn=<SelectBackward0>) tensor([ 1.8602, -0.3190], grad_fn=<SliceBackward0>) tensor([-0.0805, -0.2911], grad_fn=<SliceBackward0>)\n",
      "iter 81800, loss: 46.02320098876953\n",
      "tensor(0.7151, grad_fn=<SelectBackward0>) tensor(0.9064, grad_fn=<SelectBackward0>) tensor([-1.4567,  0.1605], grad_fn=<SliceBackward0>) tensor([1.6267, 0.4099], grad_fn=<SliceBackward0>)\n",
      "iter 81900, loss: 22.310104370117188\n",
      "tensor(-0.1889, grad_fn=<SelectBackward0>) tensor(0.7494, grad_fn=<SelectBackward0>) tensor([ 0.1501, -0.6677], grad_fn=<SliceBackward0>) tensor([-0.5972, -0.1135], grad_fn=<SliceBackward0>)\n",
      "iter 82000, loss: 4.5494842529296875\n",
      "tensor(0.1317, grad_fn=<SelectBackward0>) tensor(0.5729, grad_fn=<SelectBackward0>) tensor([-0.7684,  1.3155], grad_fn=<SliceBackward0>) tensor([-0.9370,  1.3119], grad_fn=<SliceBackward0>)\n",
      "iter 82100, loss: 0.886561930179596\n",
      "tensor(1.0440, grad_fn=<SelectBackward0>) tensor(1.5271, grad_fn=<SelectBackward0>) tensor([ 1.7714, -0.7397], grad_fn=<SliceBackward0>) tensor([2.3407, 1.3908], grad_fn=<SliceBackward0>)\n",
      "iter 82200, loss: 24.50737762451172\n",
      "tensor(-0.4063, grad_fn=<SelectBackward0>) tensor(0.7722, grad_fn=<SelectBackward0>) tensor([0.2030, 0.1144], grad_fn=<SliceBackward0>) tensor([1.8407, 1.9537], grad_fn=<SliceBackward0>)\n",
      "iter 82300, loss: 16.680984497070312\n",
      "tensor(1.9216, grad_fn=<SelectBackward0>) tensor(-0.8650, grad_fn=<SelectBackward0>) tensor([-0.8236,  0.6119], grad_fn=<SliceBackward0>) tensor([0.2321, 0.5334], grad_fn=<SliceBackward0>)\n",
      "iter 82400, loss: 2.1228973865509033\n",
      "tensor(1.0503, grad_fn=<SelectBackward0>) tensor(2.5335, grad_fn=<SelectBackward0>) tensor([0.6869, 0.3555], grad_fn=<SliceBackward0>) tensor([-0.0671,  0.2364], grad_fn=<SliceBackward0>)\n",
      "iter 82500, loss: 3.554152727127075\n",
      "tensor(0.3858, grad_fn=<SelectBackward0>) tensor(1.7330, grad_fn=<SelectBackward0>) tensor([-1.0147, -0.4726], grad_fn=<SliceBackward0>) tensor([ 0.4931, -1.5127], grad_fn=<SliceBackward0>)\n",
      "iter 82600, loss: 15.165120124816895\n",
      "tensor(-0.8282, grad_fn=<SelectBackward0>) tensor(1.4615, grad_fn=<SelectBackward0>) tensor([-0.1785,  0.6735], grad_fn=<SliceBackward0>) tensor([0.2605, 1.2202], grad_fn=<SliceBackward0>)\n",
      "iter 82700, loss: 14.116837501525879\n",
      "tensor(0.1829, grad_fn=<SelectBackward0>) tensor(0.6520, grad_fn=<SelectBackward0>) tensor([-0.7267, -0.3557], grad_fn=<SliceBackward0>) tensor([-0.2882, -1.7636], grad_fn=<SliceBackward0>)\n",
      "iter 82800, loss: 21.221426010131836\n",
      "tensor(-0.7704, grad_fn=<SelectBackward0>) tensor(-0.1257, grad_fn=<SelectBackward0>) tensor([-2.3097,  2.2892], grad_fn=<SliceBackward0>) tensor([-1.0803, -0.4128], grad_fn=<SliceBackward0>)\n",
      "iter 82900, loss: 58.60154724121094\n",
      "tensor(-1.9225, grad_fn=<SelectBackward0>) tensor(-0.1822, grad_fn=<SelectBackward0>) tensor([-0.0767, -0.2303], grad_fn=<SliceBackward0>) tensor([0.6108, 0.4005], grad_fn=<SliceBackward0>)\n",
      "iter 83000, loss: 1.4910529851913452\n",
      "tensor(0.4312, grad_fn=<SelectBackward0>) tensor(0.4578, grad_fn=<SelectBackward0>) tensor([1.4367, 0.6225], grad_fn=<SliceBackward0>) tensor([0.5906, 0.2563], grad_fn=<SliceBackward0>)\n",
      "iter 83100, loss: 49.72372055053711\n",
      "tensor(0.9650, grad_fn=<SelectBackward0>) tensor(-0.1796, grad_fn=<SelectBackward0>) tensor([-1.3260, -0.3794], grad_fn=<SliceBackward0>) tensor([1.1820, 0.7842], grad_fn=<SliceBackward0>)\n",
      "iter 83200, loss: 1.6605172157287598\n",
      "tensor(1.3766, grad_fn=<SelectBackward0>) tensor(1.4923, grad_fn=<SelectBackward0>) tensor([-0.1150,  0.6316], grad_fn=<SliceBackward0>) tensor([-1.5558, -0.3281], grad_fn=<SliceBackward0>)\n",
      "iter 83300, loss: 2.948805809020996\n",
      "tensor(-0.0739, grad_fn=<SelectBackward0>) tensor(2.5460, grad_fn=<SelectBackward0>) tensor([0.8983, 0.8856], grad_fn=<SliceBackward0>) tensor([-0.3266,  0.2653], grad_fn=<SliceBackward0>)\n",
      "iter 83400, loss: 0.007530665025115013\n",
      "tensor(0.9533, grad_fn=<SelectBackward0>) tensor(1.1065, grad_fn=<SelectBackward0>) tensor([-0.7188, -0.6903], grad_fn=<SliceBackward0>) tensor([-1.5072, -1.1774], grad_fn=<SliceBackward0>)\n",
      "iter 83500, loss: 23.059112548828125\n",
      "tensor(1.3211, grad_fn=<SelectBackward0>) tensor(-0.8770, grad_fn=<SelectBackward0>) tensor([-0.1133, -0.8477], grad_fn=<SliceBackward0>) tensor([-0.2497,  0.0060], grad_fn=<SliceBackward0>)\n",
      "iter 83600, loss: 0.08102694898843765\n",
      "tensor(1.9050, grad_fn=<SelectBackward0>) tensor(2.5895, grad_fn=<SelectBackward0>) tensor([-0.0073,  0.5954], grad_fn=<SliceBackward0>) tensor([-0.2805, -1.2560], grad_fn=<SliceBackward0>)\n",
      "iter 83700, loss: 6.2110514640808105\n",
      "tensor(0.9922, grad_fn=<SelectBackward0>) tensor(-0.2255, grad_fn=<SelectBackward0>) tensor([-1.5394,  1.3348], grad_fn=<SliceBackward0>) tensor([-0.9216,  0.5020], grad_fn=<SliceBackward0>)\n",
      "iter 83800, loss: 20.339632034301758\n",
      "tensor(-0.6039, grad_fn=<SelectBackward0>) tensor(-1.2912, grad_fn=<SelectBackward0>) tensor([-0.9815,  0.1231], grad_fn=<SliceBackward0>) tensor([ 0.2963, -0.2584], grad_fn=<SliceBackward0>)\n",
      "iter 83900, loss: 10.746939659118652\n",
      "tensor(0.7823, grad_fn=<SelectBackward0>) tensor(0.4731, grad_fn=<SelectBackward0>) tensor([-0.8729, -0.8105], grad_fn=<SliceBackward0>) tensor([-1.8830,  0.8425], grad_fn=<SliceBackward0>)\n",
      "iter 84000, loss: 23.288522720336914\n",
      "tensor(0.0907, grad_fn=<SelectBackward0>) tensor(0.2833, grad_fn=<SelectBackward0>) tensor([-0.1587, -0.1204], grad_fn=<SliceBackward0>) tensor([-0.9738,  0.4158], grad_fn=<SliceBackward0>)\n",
      "iter 84100, loss: 5.071320056915283\n",
      "tensor(0.7241, grad_fn=<SelectBackward0>) tensor(0.6784, grad_fn=<SelectBackward0>) tensor([ 1.0574, -1.3059], grad_fn=<SliceBackward0>) tensor([2.1643, 0.3953], grad_fn=<SliceBackward0>)\n",
      "iter 84200, loss: 29.385332107543945\n",
      "tensor(0.0312, grad_fn=<SelectBackward0>) tensor(0.2301, grad_fn=<SelectBackward0>) tensor([-0.4993, -1.6402], grad_fn=<SliceBackward0>) tensor([ 1.1710, -0.3735], grad_fn=<SliceBackward0>)\n",
      "iter 84300, loss: 18.428892135620117\n",
      "tensor(-0.0787, grad_fn=<SelectBackward0>) tensor(0.8735, grad_fn=<SelectBackward0>) tensor([ 0.6111, -0.3228], grad_fn=<SliceBackward0>) tensor([0.8464, 0.8437], grad_fn=<SliceBackward0>)\n",
      "iter 84400, loss: 57.60346221923828\n",
      "tensor(-1.0360, grad_fn=<SelectBackward0>) tensor(0.2807, grad_fn=<SelectBackward0>) tensor([-1.2392,  0.5534], grad_fn=<SliceBackward0>) tensor([ 0.4918, -0.7641], grad_fn=<SliceBackward0>)\n",
      "iter 84500, loss: 17.813261032104492\n",
      "tensor(0.6960, grad_fn=<SelectBackward0>) tensor(0.3878, grad_fn=<SelectBackward0>) tensor([-0.8292, -0.7673], grad_fn=<SliceBackward0>) tensor([-0.2162,  0.2545], grad_fn=<SliceBackward0>)\n",
      "iter 84600, loss: 33.809932708740234\n",
      "tensor(0.9310, grad_fn=<SelectBackward0>) tensor(-0.5534, grad_fn=<SelectBackward0>) tensor([0.3130, 0.8110], grad_fn=<SliceBackward0>) tensor([ 0.5075, -1.0364], grad_fn=<SliceBackward0>)\n",
      "iter 84700, loss: 19.866493225097656\n",
      "tensor(-0.7687, grad_fn=<SelectBackward0>) tensor(2.3542, grad_fn=<SelectBackward0>) tensor([-0.0371, -0.6305], grad_fn=<SliceBackward0>) tensor([0.7192, 1.0210], grad_fn=<SliceBackward0>)\n",
      "iter 84800, loss: 2.3335633277893066\n",
      "tensor(1.2708, grad_fn=<SelectBackward0>) tensor(-0.5576, grad_fn=<SelectBackward0>) tensor([-0.0752, -0.6430], grad_fn=<SliceBackward0>) tensor([-0.1874,  0.2746], grad_fn=<SliceBackward0>)\n",
      "iter 84900, loss: 18.794572830200195\n",
      "tensor(0.7053, grad_fn=<SelectBackward0>) tensor(-0.0829, grad_fn=<SelectBackward0>) tensor([-0.4650,  0.9009], grad_fn=<SliceBackward0>) tensor([-0.1773,  0.2500], grad_fn=<SliceBackward0>)\n",
      "iter 85000, loss: 9.01078987121582\n",
      "tensor(0.5207, grad_fn=<SelectBackward0>) tensor(0.2963, grad_fn=<SelectBackward0>) tensor([ 0.0070, -1.1745], grad_fn=<SliceBackward0>) tensor([-0.1040, -0.3309], grad_fn=<SliceBackward0>)\n",
      "iter 85100, loss: 19.266111373901367\n",
      "tensor(-0.7173, grad_fn=<SelectBackward0>) tensor(0.7537, grad_fn=<SelectBackward0>) tensor([0.9970, 0.0077], grad_fn=<SliceBackward0>) tensor([0.9822, 0.9776], grad_fn=<SliceBackward0>)\n",
      "iter 85200, loss: 82.17935943603516\n",
      "tensor(-0.1778, grad_fn=<SelectBackward0>) tensor(-1.8989, grad_fn=<SelectBackward0>) tensor([ 2.5741, -0.4270], grad_fn=<SliceBackward0>) tensor([-0.1937, -1.6419], grad_fn=<SliceBackward0>)\n",
      "iter 85300, loss: 5.476858615875244\n",
      "tensor(1.5093, grad_fn=<SelectBackward0>) tensor(1.3045, grad_fn=<SelectBackward0>) tensor([-1.3803,  0.8006], grad_fn=<SliceBackward0>) tensor([0.8191, 0.2901], grad_fn=<SliceBackward0>)\n",
      "iter 85400, loss: 71.990234375\n",
      "tensor(0.8371, grad_fn=<SelectBackward0>) tensor(1.0739, grad_fn=<SelectBackward0>) tensor([-1.6099, -1.9197], grad_fn=<SliceBackward0>) tensor([ 1.8851, -0.0109], grad_fn=<SliceBackward0>)\n",
      "iter 85500, loss: 36.91081237792969\n",
      "tensor(-0.1503, grad_fn=<SelectBackward0>) tensor(0.6076, grad_fn=<SelectBackward0>) tensor([-0.8944, -0.3259], grad_fn=<SliceBackward0>) tensor([0.8504, 0.6817], grad_fn=<SliceBackward0>)\n",
      "iter 85600, loss: 59.949493408203125\n",
      "tensor(-1.5931, grad_fn=<SelectBackward0>) tensor(0.9184, grad_fn=<SelectBackward0>) tensor([0.4637, 1.4796], grad_fn=<SliceBackward0>) tensor([-0.3353, -0.6939], grad_fn=<SliceBackward0>)\n",
      "iter 85700, loss: 23.153244018554688\n",
      "tensor(-0.1965, grad_fn=<SelectBackward0>) tensor(0.5048, grad_fn=<SelectBackward0>) tensor([-0.8492, -0.0908], grad_fn=<SliceBackward0>) tensor([-0.2704,  0.5694], grad_fn=<SliceBackward0>)\n",
      "iter 85800, loss: 15.590194702148438\n",
      "tensor(1.0433, grad_fn=<SelectBackward0>) tensor(-0.2700, grad_fn=<SelectBackward0>) tensor([ 0.2751, -0.3115], grad_fn=<SliceBackward0>) tensor([ 1.2772, -0.9108], grad_fn=<SliceBackward0>)\n",
      "iter 85900, loss: 57.24512481689453\n",
      "tensor(0.0446, grad_fn=<SelectBackward0>) tensor(-1.1343, grad_fn=<SelectBackward0>) tensor([-0.2915, -0.2854], grad_fn=<SliceBackward0>) tensor([0.0183, 1.8870], grad_fn=<SliceBackward0>)\n",
      "iter 86000, loss: 8.05172061920166\n",
      "tensor(-1.4427, grad_fn=<SelectBackward0>) tensor(3.6901, grad_fn=<SelectBackward0>) tensor([-1.0406, -1.3769], grad_fn=<SliceBackward0>) tensor([0.2987, 0.3416], grad_fn=<SliceBackward0>)\n",
      "iter 86100, loss: 6.0699334144592285\n",
      "tensor(0.9318, grad_fn=<SelectBackward0>) tensor(0.5272, grad_fn=<SelectBackward0>) tensor([-0.0141,  1.5957], grad_fn=<SliceBackward0>) tensor([2.5608, 1.0704], grad_fn=<SliceBackward0>)\n",
      "iter 86200, loss: 3.6189920902252197\n",
      "tensor(1.5569, grad_fn=<SelectBackward0>) tensor(-0.4955, grad_fn=<SelectBackward0>) tensor([0.2065, 1.2946], grad_fn=<SliceBackward0>) tensor([1.7654, 1.5567], grad_fn=<SliceBackward0>)\n",
      "iter 86300, loss: 23.872392654418945\n",
      "tensor(0.1661, grad_fn=<SelectBackward0>) tensor(-0.3663, grad_fn=<SelectBackward0>) tensor([ 0.2657, -0.6818], grad_fn=<SliceBackward0>) tensor([ 2.7722, -0.9386], grad_fn=<SliceBackward0>)\n",
      "iter 86400, loss: 33.800254821777344\n",
      "tensor(-0.8371, grad_fn=<SelectBackward0>) tensor(-0.6342, grad_fn=<SelectBackward0>) tensor([-0.5867, -1.0079], grad_fn=<SliceBackward0>) tensor([-0.0963, -1.0805], grad_fn=<SliceBackward0>)\n",
      "iter 86500, loss: 0.48252159357070923\n",
      "tensor(1.0093, grad_fn=<SelectBackward0>) tensor(1.7330, grad_fn=<SelectBackward0>) tensor([1.2920, 0.5830], grad_fn=<SliceBackward0>) tensor([1.1897, 0.1788], grad_fn=<SliceBackward0>)\n",
      "iter 86600, loss: 11.418912887573242\n",
      "tensor(0.1359, grad_fn=<SelectBackward0>) tensor(0.8261, grad_fn=<SelectBackward0>) tensor([-0.3877, -1.4989], grad_fn=<SliceBackward0>) tensor([-0.3042,  0.1019], grad_fn=<SliceBackward0>)\n",
      "iter 86700, loss: 41.966392517089844\n",
      "tensor(0.4827, grad_fn=<SelectBackward0>) tensor(-0.8499, grad_fn=<SelectBackward0>) tensor([-0.7658, -0.6996], grad_fn=<SliceBackward0>) tensor([-0.0753,  0.8965], grad_fn=<SliceBackward0>)\n",
      "iter 86800, loss: 36.19255065917969\n",
      "tensor(-0.1338, grad_fn=<SelectBackward0>) tensor(-0.6364, grad_fn=<SelectBackward0>) tensor([0.0114, 0.1224], grad_fn=<SliceBackward0>) tensor([ 0.1004, -0.0255], grad_fn=<SliceBackward0>)\n",
      "iter 86900, loss: 5.56293249130249\n",
      "tensor(0.0389, grad_fn=<SelectBackward0>) tensor(0.1953, grad_fn=<SelectBackward0>) tensor([-0.2380, -1.5990], grad_fn=<SliceBackward0>) tensor([-1.5468, -2.5547], grad_fn=<SliceBackward0>)\n",
      "iter 87000, loss: 21.94180679321289\n",
      "tensor(-0.6359, grad_fn=<SelectBackward0>) tensor(0.7509, grad_fn=<SelectBackward0>) tensor([0.6647, 0.5119], grad_fn=<SliceBackward0>) tensor([0.5969, 0.1608], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = train(b_lfm,0.01,0.001,interactions,users,business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_set,users,items):\n",
    "    predictions=[]\n",
    "    labels = []\n",
    "    loss_tot = []\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for idx, (u,i,r) in enumerate(test_set):\n",
    "            if u in users.keys() and i not in items.keys():\n",
    "                beta_u = model.beta_user[users[u]]\n",
    "                beta_i = model.beta_item[items[i]]\n",
    "                gamma_u = model.gamma_user[users[u],:]\n",
    "                gamma_i = model.gamma_item[items[i],:]\n",
    "                pred = model.forward(beta_u,beta_i,gamma_u,gamma_i)\n",
    "            else:\n",
    "                pred = mean_rating   \n",
    "            # print(beta_u,beta_i,gamma_u,gamma_i)\n",
    "            y = torch.tensor([float(r)])\n",
    "            \n",
    "            #loss = (pred-y)**2+lam*(torch.sum(model.beta_user)+\\\n",
    "            #       torch.sum(model.beta_item)+ torch.sum(torch.norm(model.gamma_user))+torch.sum(torch.norm(model.gamma_item)))\n",
    "            labels.append((y))\n",
    "            predictions.append((u,i,pred))\n",
    "            loss = (pred-y)**2\n",
    "            \n",
    "            loss_tot.append(loss)\n",
    "            if idx % 100 == 0:\n",
    "                #print(\"iter {}, loss: {}\".format(idx, loss.item()))\n",
    "                #print(model.beta_user[users[u]],model.beta_item[items[i]],model.gamma_user[users[u],:],model.gamma_item[items[i],:])\n",
    "                losses.append(torch.mean(torch.tensor(loss_tot)).item())\n",
    "                loss_tot = []\n",
    "    return losses, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_users = {}\n",
    "# val_business = {}\n",
    "val_interactions = []\n",
    "\n",
    "for d in val_dataset:\n",
    "    val_interactions.append((d[\"user_id\"], d[\"business_id\"], d[\"rating\"]))\n",
    "    \n",
    "len(val_interactions)\n",
    "\n",
    "test_users = {}\n",
    "test_business = {}\n",
    "test_interactions = []\n",
    "\n",
    "for d in test_dataset:\n",
    "    if d[\"user_id\"] not in test_users.keys(): test_users[d[\"user_id\"]] = len(test_users)\n",
    "    if d[\"business_id\"] not in test_business.keys(): test_business[d[\"business_id\"]] = len(test_business)\n",
    "    test_interactions.append((d[\"user_id\"], d[\"business_id\"], d[\"rating\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing the data\n",
    "test_losses, test_precitions = test(b_lfm,test_interactions,users,business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ab2bce9ac0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## plot training losses\n",
    "plt.plot(np.arange(len(loss)),loss,c=\"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MRR(predictions,users,items,k=3):\n",
    "    userRanks = defaultdict(list)\n",
    "    \n",
    "    for (u,i,p) in predictions:\n",
    "        userRanks[u].append((p,i))\n",
    "        \n",
    "    for u in userRanks:\n",
    "        userRanks[u].sort(reverse=True)\n",
    "        \n",
    "    totalMRR = 0\n",
    "    for u,preds in userRanks.items():\n",
    "        rank = 0\n",
    "        for i, (r,b) in enumerate(preds[:k]):\n",
    "            if b in items and r >= 3:\n",
    "                rank = i+1\n",
    "                break\n",
    "            \n",
    "        if rank > 0:\n",
    "            totalMRR += 1/rank\n",
    "    \n",
    "    return totalMRR/len(userRanks) if len(userRanks) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reciproal_rank = MRR(test_precitions,users,test_business)\n",
    "mean_reciproal_rank\n",
    "metrics[\"MRR\"] = mean_reciproal_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_MSE =  sum(test_losses)/len(test_losses)\n",
    "mean_MSE\n",
    "metrics[\"average MSE\"] = mean_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG(predictions,labels,users,items,k=3):\n",
    "    userRanks = defaultdict(list)\n",
    "    labelRanks = defaultdict(list)\n",
    "    \n",
    "    for (u,i,p) in predictions:\n",
    "        userRanks[u].append((p,i))\n",
    "        \n",
    "    for (u,i,p) in labels:\n",
    "        labelRanks[u].append((p,i))\n",
    "        \n",
    "    for u in userRanks:\n",
    "        userRanks[u].sort(reverse=True)\n",
    "    \n",
    "    for u in labelRanks:\n",
    "        labelRanks[u].sort(reverse=True)\n",
    "        \n",
    "    totalDCG = 0\n",
    "    for u,preds in userRanks.items():\n",
    "        rank = 0\n",
    "        rating = 0\n",
    "        for i, (r,b) in enumerate(preds[:k]):\n",
    "            if b in items and r >= 3:\n",
    "                rank = i+1\n",
    "                rating = r\n",
    "                # break\n",
    "                totalDCG += rating/np.log2(rank+1)\n",
    "    \n",
    "    totalIDCG = 0\n",
    "    for u,preds in labelRanks.items():\n",
    "        rank = 0\n",
    "        rating = 0\n",
    "        for i, (r,b) in enumerate(preds[:k]):\n",
    "            if b in items and r >= 3:\n",
    "                rank = i+1\n",
    "                rating = r\n",
    "                # break\n",
    "                totalIDCG += rating/np.log2(rank+1)\n",
    "\n",
    "    return totalDCG, totalDCG/totalIDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCG3, NDCG3 = NDCG(test_precitions, test_interactions, test_users, test_business)\n",
    "DCG3, NDCG3\n",
    "\n",
    "metrics[\"NDCG\"] = NDCG3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(predictions,labels,users,items,k=3):\n",
    "    userRanks = defaultdict(list)\n",
    "    labelRanks = defaultdict(list)\n",
    "    \n",
    "    for (u,i,p) in predictions:\n",
    "        userRanks[u].append((p,i))\n",
    "        \n",
    "    for (u,i,p) in labels:\n",
    "        labelRanks[u].append((p,i))\n",
    "        \n",
    "    for u in userRanks:\n",
    "        userRanks[u].sort(reverse=True)\n",
    "    \n",
    "    for u in labelRanks:\n",
    "        labelRanks[u].sort(reverse=True)\n",
    "        \n",
    "    totalPreKU = 0\n",
    "    for u, preds in labelRanks.items():\n",
    "        relevance = 0\n",
    "        ps = [p[1] for p in userRanks[u][:k]]\n",
    "        for i, (r,b) in enumerate(preds):\n",
    "            if b in items and b in ps:\n",
    "                relevance+=1\n",
    "        totalPreKU += relevance/k\n",
    "\n",
    "    return totalPreKU/len(users)\n",
    "\n",
    "def Recall(predictions,labels,users,items,k=3):\n",
    "    userRanks = defaultdict(list)\n",
    "    labelRanks = defaultdict(list)\n",
    "    \n",
    "    for (u,i,p) in predictions:\n",
    "        userRanks[u].append((p,i))\n",
    "        \n",
    "    for (u,i,p) in labels:\n",
    "        labelRanks[u].append((p,i))\n",
    "        \n",
    "    for u in userRanks:\n",
    "        userRanks[u].sort(reverse=True)\n",
    "    \n",
    "    for u in labelRanks:\n",
    "        labelRanks[u].sort(reverse=True)\n",
    "        \n",
    "    totalRKU = 0\n",
    "    for u, preds in labelRanks.items():\n",
    "        relevance = 0\n",
    "        ps = [p[1] for p in userRanks[u][:k]]\n",
    "        for i, (r,b) in enumerate(preds):\n",
    "            if b in items and b in ps:\n",
    "                relevance+=1\n",
    "        totalRKU += relevance/len(preds)\n",
    "\n",
    "    return totalRKU/len(users)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "P3 = Precision(test_precitions,test_interactions,test_users,test_business)\n",
    "P3\n",
    "metrics[\"precision\"] = P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "R3 = Recall(test_precitions,test_interactions, test_users, test_business)\n",
    "R3\n",
    "metrics[\"recall\"] = R3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MRR': 1.0,\n",
       " 'average MSE': 0.6785635481009612,\n",
       " 'NDCG': 0.9698569094340085,\n",
       " 'precision': 0.7966666666666425,\n",
       " 'recall': 0.9159855047592548}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
